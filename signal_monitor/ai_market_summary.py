#!/usr/bin/env python3
"""
AI å¸‚åœºå®è§‚åˆ†ææ¨¡å—

åŠŸèƒ½ï¼š
1. æ”¶é›† BTC/ETH OHLCV Kçº¿æ•°æ®
2. æ”¶é›†å¸‚åœºå¿«ç…§æ•°æ®ï¼ˆä»·æ ¼/æˆäº¤é¢/å¸‚å€¼ï¼‰
3. æ”¶é›† OI æ’è¡Œæ•°æ®
4. æ”¶é›†åŠ å¯†è´§å¸æ–°é—»
5. æ”¶é›† ValueScan ä¿¡å·æ•°æ®
6. ä½¿ç”¨ AI ç»¼åˆåˆ†æå¸‚åœºå®è§‚èµ°å‘
7. ç”Ÿæˆä¸“ä¸šå¸‚åœºåˆ†ææŠ¥å‘Š
8. å®šæ—¶å‘é€åˆ° Telegram
"""

import json
import logging
import os
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import requests

from market_data_sources import fetch_market_snapshot, fetch_news, fetch_trending

logger = logging.getLogger(__name__)

# åŒ—äº¬æ—¶åŒº
BEIJING_TZ = timezone(timedelta(hours=8))

# é…ç½®
AI_SUMMARY_ENABLED = os.getenv("VALUESCAN_AI_SUMMARY_ENABLED", "0") == "1"
AI_SUMMARY_INTERVAL_HOURS = float(os.getenv("VALUESCAN_AI_SUMMARY_INTERVAL_HOURS", "1"))
AI_SUMMARY_API_KEY = os.getenv("VALUESCAN_AI_SUMMARY_API_KEY", "sk-chat2api").strip()
AI_SUMMARY_API_URL = os.getenv(
    "VALUESCAN_AI_SUMMARY_API_URL",
    "https://chat.cornna.xyz/chatgpt/v1/chat/completions"
).strip()
AI_SUMMARY_MODEL = os.getenv("VALUESCAN_AI_SUMMARY_MODEL", "gpt-5.2").strip()

# æ•°æ®æ”¶é›†æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰- æ”¹ä¸º2å¤©ï¼ˆ48å°æ—¶ï¼‰
SIGNAL_LOOKBACK_HOURS = float(os.getenv("VALUESCAN_SIGNAL_LOOKBACK_HOURS", "48"))
def _read_int_env_or_config(env_key: str, config_key: str, default: int) -> int:
    raw = os.getenv(env_key)
    if raw is not None and str(raw).strip() != "":
        try:
            return int(float(raw))
        except Exception:
            return default
    try:
        import config as signal_config
        value = getattr(signal_config, config_key, None)
        if value is None:
            return default
        return int(float(value))
    except Exception:
        return default


def _extract_valuescan_list(payload: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not isinstance(payload, dict):
        return []
    data = payload.get("data")
    if isinstance(data, list):
        return [item for item in data if isinstance(item, dict)]
    if isinstance(data, dict):
        for key in ("list", "records", "items", "data"):
            items = data.get(key)
            if isinstance(items, list):
                return [item for item in items if isinstance(item, dict)]
    return []


def _normalize_flow_period(value: Any) -> str:
    if value is None:
        return ""
    key = str(value).strip().lower().replace(" ", "")
    aliases = {
        "h1": "1h",
        "h4": "4h",
        "h12": "12h",
        "h24": "24h",
        "1d": "24h",
        "d1": "24h",
        "d": "24h",
        "m15": "15m",
    }
    return aliases.get(key, key)


def _first_float(item: Dict[str, Any], keys: Tuple[str, ...]) -> Optional[float]:
    for key in keys:
        value = item.get(key)
        if value is None:
            continue
        try:
            return float(value)
        except Exception:
            continue
    return None


def _extract_flow_items(data: Any) -> List[Dict[str, Any]]:
    if isinstance(data, list):
        return [item for item in data if isinstance(item, dict)]
    if isinstance(data, dict):
        for key in ("list", "records", "items"):
            items = data.get(key)
            if isinstance(items, list):
                return [item for item in items if isinstance(item, dict)]
        items: List[Dict[str, Any]] = []
        for key, value in data.items():
            if isinstance(value, dict):
                item = dict(value)
                item.setdefault("timeType", key)
                items.append(item)
        return items
    return []


def _normalize_exchange_flow_detail(resp: Optional[Dict[str, Any]]) -> Dict[str, Dict[str, float]]:
    if not isinstance(resp, dict) or resp.get("code") != 200:
        return {}
    items = _extract_flow_items(resp.get("data"))
    result: Dict[str, Dict[str, float]] = {}
    for item in items:
        period = _normalize_flow_period(
            item.get("timeType")
            or item.get("period")
            or item.get("time")
            or item.get("timeParticle")
        )
        if not period:
            continue
        in_val = _first_float(item, ("inFlowValue", "inFlow", "tradeIn", "stopTradeIn", "contractTradeIn"))
        out_val = _first_float(item, ("outFlowValue", "outFlow", "tradeOut", "stopTradeOut", "contractTradeOut"))
        net_val = _first_float(
            item,
            ("netFlowValue", "netFlow", "tradeInflow", "stopTradeInflow", "contractTradeInflow"),
        )
        if net_val is None and in_val is not None and out_val is not None:
            net_val = in_val - out_val
        if in_val is None and out_val is None and net_val is None:
            continue
        total = (in_val or 0.0) + (out_val or 0.0)
        ratio = (in_val or 0.0) / total if total > 0 else 0.5
        result[period] = {
            "in": float(in_val or 0.0),
            "out": float(out_val or 0.0),
            "net": float(net_val or 0.0),
            "ratio": float(ratio),
        }
    return result


def _compact_valuescan_history(resp: Optional[Dict[str, Any]], limit: int = 30) -> List[Dict[str, Any]]:
    items = _extract_valuescan_list(resp)
    if not items:
        return []
    return items[:limit]


def _compact_holder_items(resp: Optional[Dict[str, Any]], limit: int = 3) -> List[Dict[str, Any]]:
    items = _extract_valuescan_list(resp)
    if not items:
        return []
    trimmed: List[Dict[str, Any]] = []
    for item in items[:limit]:
        trimmed.append({
            "address": item.get("address"),
            "balance": item.get("balance"),
            "balancePercent": item.get("balancePercent"),
            "chainName": item.get("chainName"),
        })
    return trimmed


def _compact_chain_items(resp: Optional[Dict[str, Any]], limit: int = 5) -> List[Dict[str, Any]]:
    items = _extract_valuescan_list(resp)
    if not items:
        return []
    trimmed: List[Dict[str, Any]] = []
    for item in items[:limit]:
        trimmed.append({
            "chainName": item.get("chainName"),
            "contractAddress": item.get("contractAddress"),
            "coinKey": item.get("coinKey"),
        })
    return trimmed


BULL_BEAR_SIGNAL_TTL_SECONDS = _read_int_env_or_config(
    "VALUESCAN_BULL_BEAR_SIGNAL_TTL_SECONDS",
    "BULL_BEAR_SIGNAL_TTL_SECONDS",
    86400,
)
_BULLISH_SIGNAL_TYPES = {108, 110, 111, 100, 101}
_BEARISH_SIGNAL_TYPES = {109, 112, 102, 103}


def _get_language() -> str:
    lang = (os.getenv("VALUESCAN_LANGUAGE") or os.getenv("LANGUAGE") or "").strip().lower()
    if not lang:
        try:
            import config as signal_config
            lang = getattr(signal_config, "LANGUAGE", "").strip().lower()
        except Exception:
            lang = ""
    if lang not in ("zh", "en"):
        lang = "zh"
    return lang

# Binance Futures API
BINANCE_FUTURES_BASE = "https://fapi.binance.com"

# ä»£ç†é…ç½® - Clash ä»£ç†åœ¨ 7890 ç«¯å£
PROXY_URL = os.getenv("VALUESCAN_PROXY") or os.getenv("HTTP_PROXY") or "http://127.0.0.1:7890"

def _get_proxies():
    """è·å–ä»£ç†é…ç½®"""
    if PROXY_URL:
        return {"http": PROXY_URL, "https": PROXY_URL}
    return None

# åŠ å¯†æ–°é—» APIï¼ˆå¯é€‰ï¼‰
CRYPTO_NEWS_API_KEY = os.getenv("CRYPTO_NEWS_API_KEY", "").strip()

# ä¸»è¦åˆ†æå¸ç§
MAJOR_COINS = ["BTC", "ETH"]

# ä¸Šæ¬¡æ€»ç»“æ—¶é—´
_last_summary_time: float = 0.0


def _load_config() -> Dict[str, Any]:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½ AI æ€»ç»“é…ç½®ï¼ˆAIç®€è¯„ä¸“ç”¨ï¼‰"""
    config_path = Path(__file__).parent / "ai_summary_config.json"
    if config_path.exists():
        try:
            return json.loads(config_path.read_text(encoding="utf-8"))
        except Exception:
            pass
    return {}


def _load_market_config() -> Dict[str, Any]:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½ AI å¸‚åœºåˆ†æé…ç½®"""
    config_path = Path(__file__).parent / "ai_market_summary_config.json"
    if config_path.exists():
        try:
            return json.loads(config_path.read_text(encoding="utf-8"))
        except Exception:
            pass
    # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•ä»æ—§é…ç½®è¿ç§»
    return _load_config()


def _save_config(config: Dict[str, Any]) -> bool:
    """ä¿å­˜ AI æ€»ç»“é…ç½®ï¼ˆAIç®€è¯„ä¸“ç”¨ï¼‰"""
    config_path = Path(__file__).parent / "ai_summary_config.json"
    try:
        config_path.write_text(json.dumps(config, ensure_ascii=False, indent=2), encoding="utf-8")
        return True
    except Exception as e:
        logger.error("ä¿å­˜ AI æ€»ç»“é…ç½®å¤±è´¥: %s", e)
        return False


def _save_market_config(config: Dict[str, Any]) -> bool:
    """ä¿å­˜ AI å¸‚åœºåˆ†æé…ç½®"""
    config_path = Path(__file__).parent / "ai_market_summary_config.json"
    try:
        config_path.write_text(json.dumps(config, ensure_ascii=False, indent=2), encoding="utf-8")
        return True
    except Exception as e:
        logger.error("ä¿å­˜ AI å¸‚åœºåˆ†æé…ç½®å¤±è´¥: %s", e)
        return False


def get_ai_summary_config() -> Dict[str, Any]:
    """è·å– AI æ€»ç»“é…ç½®ï¼ˆAIç®€è¯„ä¸“ç”¨ï¼‰"""
    file_config = _load_config()
    return {
        "enabled": file_config.get("enabled", AI_SUMMARY_ENABLED),
        "interval_hours": file_config.get("interval_hours", AI_SUMMARY_INTERVAL_HOURS),
        "api_key": file_config.get("api_key", AI_SUMMARY_API_KEY),
        "api_url": file_config.get("api_url", AI_SUMMARY_API_URL),
        "model": file_config.get("model", AI_SUMMARY_MODEL),
        "lookback_hours": file_config.get("lookback_hours", SIGNAL_LOOKBACK_HOURS),
    }


def get_ai_market_config() -> Dict[str, Any]:
    """è·å– AI å¸‚åœºåˆ†æé…ç½®"""
    file_config = _load_market_config()
    return {
        "enabled": file_config.get("enabled", AI_SUMMARY_ENABLED),
        "interval_hours": file_config.get("interval_hours", AI_SUMMARY_INTERVAL_HOURS),
        "api_key": file_config.get("api_key", AI_SUMMARY_API_KEY),
        "api_url": file_config.get("api_url", AI_SUMMARY_API_URL),
        "model": file_config.get("model", AI_SUMMARY_MODEL),
        "lookback_hours": file_config.get("lookback_hours", SIGNAL_LOOKBACK_HOURS),
    }


def _load_overlays_config() -> Dict[str, Any]:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½ AI Overlays é…ç½®"""
    config_path = Path(__file__).parent / "ai_overlays_config.json"
    if config_path.exists():
        try:
            return json.loads(config_path.read_text(encoding="utf-8"))
        except Exception:
            pass
    # å¦‚æœä¸å­˜åœ¨ï¼Œå›é€€åˆ° ai_summary_config.json
    return _load_config()


def get_ai_overlays_config() -> Dict[str, Any]:
    """è·å– AI Overlaysï¼ˆç”»çº¿ï¼‰é…ç½®"""
    file_config = _load_overlays_config()
    return {
        "enabled": file_config.get("enabled", AI_SUMMARY_ENABLED),
        "api_key": file_config.get("api_key", AI_SUMMARY_API_KEY),
        "api_url": file_config.get("api_url", AI_SUMMARY_API_URL),
        "model": file_config.get("model", AI_SUMMARY_MODEL),
    }



def update_ai_summary_config(config: Dict[str, Any]) -> bool:
    """æ›´æ–° AI æ€»ç»“é…ç½®ï¼ˆAIç®€è¯„ä¸“ç”¨ï¼‰"""
    return _save_config(config)


def update_ai_market_config(config: Dict[str, Any]) -> bool:
    """æ›´æ–° AI å¸‚åœºåˆ†æé…ç½®"""
    return _save_market_config(config)


def _collect_recent_signals(lookback_hours: float = 48.0) -> Dict[str, Any]:
    """
    æ”¶é›†æœ€è¿‘çš„ ValueScan ä¿¡å·æ•°æ®ï¼ˆé»˜è®¤2å¤©ï¼‰

    Returns:
        åŒ…å«å„ç±»ä¿¡å·å’Œå¸ç§æ¨èçš„å­—å…¸
    """
    from database import MessageDatabase

    cutoff_time = time.time() - (lookback_hours * 3600)
    cutoff_ms = int(cutoff_time * 1000)

    def _normalize_timestamp_ms(value: Any) -> int:
        try:
            ts = float(value)
        except (TypeError, ValueError):
            return 0
        if ts <= 0:
            return 0
        if ts > 1e11:
            return int(ts)
        return int(ts * 1000)

    try:
        db = MessageDatabase()
        messages = db.get_recent_messages_for_ai(limit=500, since_timestamp_ms=cutoff_ms)
    except Exception as e:
        logger.warning("è·å–æœ€è¿‘æ¶ˆæ¯å¤±è´¥: %s", e)
        messages = []

    # åˆ†ç±»ä¿¡å·
    bullish_signals = []  # çœ‹æ¶¨ä¿¡å·
    bearish_signals = []  # çœ‹è·Œä¿¡å·
    arbitrage_signals = []  # å¥—åˆ©æœºä¼š
    whale_signals = []  # å¤§æˆ·åŠ¨å‘
    other_signals = []  # å…¶ä»–ä¿¡å·

    # å¸ç§ä¿¡å·ç»Ÿè®¡ {symbol: {"bullish": count, "bearish": count, "whale": count, "latest_time": timestamp}}
    coin_signal_stats = {}

    now_ms = int(time.time() * 1000)
    for msg in messages:
        msg_type = msg.get("type") or msg.get("messageType")
        symbol_raw = msg.get("symbol") or ""
        symbol = symbol_raw.upper().replace("USDT", "").replace("PERP", "") if symbol_raw else ""
        content = msg.get("content", "") or msg.get("message", "")
        msg_time = msg.get("createTime") or msg.get("timestamp") or 0
        msg_time_ms = _normalize_timestamp_ms(msg_time)

        if msg_type in _BULLISH_SIGNAL_TYPES or msg_type in _BEARISH_SIGNAL_TYPES:
            if BULL_BEAR_SIGNAL_TTL_SECONDS > 0 and msg_time_ms:
                if now_ms - msg_time_ms > BULL_BEAR_SIGNAL_TTL_SECONDS * 1000:
                    continue

        if not symbol:
            continue

        signal_info = {
            "symbol": symbol,
            "type": msg_type,
            "content": content[:200] if content else "",
            "time": msg_time_ms or msg_time,
        }

        # åˆå§‹åŒ–å¸ç§ç»Ÿè®¡
        if symbol not in coin_signal_stats:
            coin_signal_stats[symbol] = {
                "bullish": 0,
                "bearish": 0,
                "whale": 0,
                "arbitrage": 0,
                "latest_time": 0,
                "signals": []
            }

        # æ›´æ–°æœ€æ–°æ—¶é—´
        if msg_time_ms > coin_signal_stats[symbol]["latest_time"]:
            coin_signal_stats[symbol]["latest_time"] = msg_time_ms

        # æ ¹æ®ç±»å‹åˆ†ç±»å¹¶ç»Ÿè®¡
        if msg_type in _BULLISH_SIGNAL_TYPES:  # å¤§å•ä¹°å…¥ã€èµ„é‡‘æµå…¥ã€çœ‹æ¶¨ä¿¡å·ç­‰
            bullish_signals.append(signal_info)
            coin_signal_stats[symbol]["bullish"] += 1
            coin_signal_stats[symbol]["signals"].append({"type": "bullish", "time": msg_time_ms})
        elif msg_type in _BEARISH_SIGNAL_TYPES:  # å¤§å•å–å‡ºã€èµ„é‡‘æµå‡ºã€çœ‹è·Œä¿¡å·ç­‰
            bearish_signals.append(signal_info)
            coin_signal_stats[symbol]["bearish"] += 1
            coin_signal_stats[symbol]["signals"].append({"type": "bearish", "time": msg_time_ms})
        elif msg_type in (113, 114):  # å¥—åˆ©ç›¸å…³
            arbitrage_signals.append(signal_info)
            coin_signal_stats[symbol]["arbitrage"] += 1
        elif msg_type in (115, 116):  # å¤§æˆ·åŠ¨å‘
            whale_signals.append(signal_info)
            coin_signal_stats[symbol]["whale"] += 1
            coin_signal_stats[symbol]["signals"].append({"type": "whale", "time": msg_time})
        else:
            other_signals.append(signal_info)

    # ç”Ÿæˆå¸ç§æ¨è
    bullish_coins = []  # çœ‹æ¶¨å¸ç§
    bearish_coins = []  # çœ‹è·Œå¸ç§
    opportunity_coins = []  # æœºä¼šå¸ç§ï¼ˆæœ‰å·¨é²¸æ´»åŠ¨æˆ–å¥—åˆ©æœºä¼šï¼‰

    for symbol, stats in coin_signal_stats.items():
        total_signals = stats["bullish"] + stats["bearish"] + stats["whale"] + stats["arbitrage"]
        if total_signals < 2:  # è‡³å°‘2ä¸ªä¿¡å·æ‰è€ƒè™‘
            continue

        bullish_score = stats["bullish"] * 1.0 + stats["whale"] * 0.5
        bearish_score = stats["bearish"] * 1.0

        coin_info = {
            "symbol": symbol,
            "bullish_count": stats["bullish"],
            "bearish_count": stats["bearish"],
            "whale_count": stats["whale"],
            "arbitrage_count": stats["arbitrage"],
            "total_signals": total_signals,
            "score": bullish_score - bearish_score,
            "latest_time": stats["latest_time"]
        }

        # çœ‹æ¶¨å¸ç§ï¼šçœ‹æ¶¨ä¿¡å·æ˜æ˜¾å¤šäºçœ‹è·Œä¿¡å·
        if bullish_score >= bearish_score * 1.5 and stats["bullish"] >= 2:
            bullish_coins.append(coin_info)

        # çœ‹è·Œå¸ç§ï¼šçœ‹è·Œä¿¡å·æ˜æ˜¾å¤šäºçœ‹æ¶¨ä¿¡å·
        elif bearish_score >= bullish_score * 1.5 and stats["bearish"] >= 2:
            bearish_coins.append(coin_info)

        # æœºä¼šå¸ç§ï¼šæœ‰å·¨é²¸æ´»åŠ¨æˆ–å¥—åˆ©æœºä¼š
        if stats["whale"] >= 2 or stats["arbitrage"] >= 2:
            opportunity_coins.append(coin_info)

    # æŒ‰ä¿¡å·æ•°é‡å’Œå¾—åˆ†æ’åº
    bullish_coins.sort(key=lambda x: (x["total_signals"], x["score"]), reverse=True)
    bearish_coins.sort(key=lambda x: (x["total_signals"], -x["score"]), reverse=True)
    opportunity_coins.sort(key=lambda x: (x["whale_count"] + x["arbitrage_count"], x["total_signals"]), reverse=True)

    return {
        "bullish": bullish_signals,
        "bearish": bearish_signals,
        "arbitrage": arbitrage_signals,
        "whale": whale_signals,
        "other": other_signals,
        "total_count": len(messages),
        "lookback_hours": lookback_hours,
        # å¸ç§æ¨è
        "recommended_bullish": bullish_coins[:5],  # å‰5ä¸ªçœ‹æ¶¨å¸ç§
        "recommended_bearish": bearish_coins[:5],  # å‰5ä¸ªçœ‹è·Œå¸ç§
        "recommended_opportunity": opportunity_coins[:5],  # å‰5ä¸ªæœºä¼šå¸ç§
    }


def _collect_movement_data() -> Dict[str, Any]:
    """æ”¶é›†å¼‚åŠ¨æ¦œå•æ•°æ®"""
    try:
        from movement_list_cache import get_movement_list_cache
        cache = get_movement_list_cache()
        
        alpha_symbols = cache.get_symbols_with_alpha()
        fomo_symbols = cache.get_symbols_with_fomo()
        
        return {
            "alpha_coins": list(alpha_symbols)[:20],
            "fomo_coins": list(fomo_symbols)[:20],
        }
    except Exception as e:
        logger.warning("è·å–å¼‚åŠ¨æ¦œå•å¤±è´¥: %s", e)
        return {"alpha_coins": [], "fomo_coins": []}


def _fetch_binance_klines(symbol: str, interval: str = "1h", limit: int = 24) -> List[Dict[str, Any]]:
    """
    ä» Binance Futures API è·å– K çº¿æ•°æ®
    
    Args:
        symbol: å¸ç§ç¬¦å·ï¼ˆå¦‚ BTCUSDTï¼‰
        interval: Kçº¿å‘¨æœŸï¼ˆ1m, 5m, 15m, 1h, 4h, 1dï¼‰
        limit: è·å–æ•°é‡
    
    Returns:
        Kçº¿æ•°æ®åˆ—è¡¨
    """
    if not symbol.endswith("USDT"):
        symbol = f"{symbol}USDT"
    
    url = f"{BINANCE_FUTURES_BASE}/fapi/v1/klines"
    params = {
        "symbol": symbol.upper(),
        "interval": interval,
        "limit": limit,
    }
    
    try:
        proxies = _get_proxies()
        resp = requests.get(url, params=params, timeout=15, proxies=proxies)
        if resp.status_code == 200:
            data = resp.json()
            klines = []
            for k in data:
                klines.append({
                    "open_time": k[0],
                    "open": float(k[1]),
                    "high": float(k[2]),
                    "low": float(k[3]),
                    "close": float(k[4]),
                    "volume": float(k[5]),
                    "close_time": k[6],
                    "quote_volume": float(k[7]),
                    "trades": int(k[8]),
                })
            return klines
        else:
            logger.debug("Binance API è¿”å› %d: %s", resp.status_code, symbol)
            return []
    except Exception as e:
        logger.debug("Binance API è¯·æ±‚å¤±è´¥ (%s): %s", symbol, e)
        return []


def _analyze_klines(klines: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    åˆ†æ K çº¿æ•°æ®ï¼Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    
    Returns:
        åŒ…å«è¶‹åŠ¿ã€æ³¢åŠ¨ç‡ç­‰åˆ†æç»“æœ
    """
    if not klines or len(klines) < 2:
        return {}
    
    closes = [k["close"] for k in klines]
    highs = [k["high"] for k in klines]
    lows = [k["low"] for k in klines]
    volumes = [k["volume"] for k in klines]
    
    # ä»·æ ¼å˜åŒ–
    latest_close = closes[-1]
    first_close = closes[0]
    price_change_pct = ((latest_close - first_close) / first_close) * 100
    
    # æœ€é«˜æœ€ä½ä»·
    period_high = max(highs)
    period_low = min(lows)
    price_range_pct = ((period_high - period_low) / period_low) * 100
    
    # å¹³å‡æˆäº¤é‡
    avg_volume = sum(volumes) / len(volumes)
    latest_volume = volumes[-1]
    volume_ratio = latest_volume / avg_volume if avg_volume > 0 else 1
    
    # ç®€å•è¶‹åŠ¿åˆ¤æ–­ï¼ˆåŸºäºæ”¶ç›˜ä»·ï¼‰
    up_candles = sum(1 for i in range(1, len(closes)) if closes[i] > closes[i-1])
    down_candles = len(closes) - 1 - up_candles
    
    # MA5 å’Œ MA10
    ma5 = sum(closes[-5:]) / 5 if len(closes) >= 5 else latest_close
    ma10 = sum(closes[-10:]) / 10 if len(closes) >= 10 else latest_close
    
    trend = "bullish" if ma5 > ma10 and price_change_pct > 0 else "bearish" if ma5 < ma10 and price_change_pct < 0 else "neutral"
    
    return {
        "latest_price": latest_close,
        "price_change_pct": round(price_change_pct, 2),
        "period_high": period_high,
        "period_low": period_low,
        "price_range_pct": round(price_range_pct, 2),
        "avg_volume": avg_volume,
        "volume_ratio": round(volume_ratio, 2),
        "up_candles": up_candles,
        "down_candles": down_candles,
        "ma5": round(ma5, 2),
        "ma10": round(ma10, 2),
        "trend": trend,
    }


def _fetch_binance_open_interest(symbol: str) -> Optional[float]:
    base = symbol.upper().replace("$", "")
    if not base.endswith("USDT"):
        base = f"{base}USDT"
    url = f"{BINANCE_FUTURES_BASE}/fapi/v1/openInterest"
    try:
        resp = requests.get(url, params={"symbol": base}, timeout=10)
        if resp.status_code == 200:
            data = resp.json()
            return float(data.get("openInterest", 0) or 0)
    except Exception as e:
        logger.debug("è·å– OI å¤±è´¥: %s", e)
    return None


def _collect_major_coin_data() -> Dict[str, Dict[str, Any]]:
    """
    æ”¶é›† BTC å’Œ ETH çš„ç»¼åˆæ•°æ®
    
    Returns:
        åŒ…å« Kçº¿åˆ†æã€é‡åŒ–æ•°æ®çš„å­—å…¸
    """
    result = {}
    
    for symbol in MAJOR_COINS:
        logger.info(f"æ”¶é›† {symbol} æ•°æ®...")
        coin_data = {
            "symbol": symbol,
            "klines_1h": {},
            "klines_4h": {},
            "klines_1d": {},
            "market": {},
            "open_interest": None,
        }

        # æ”¶é›†ä¸åŒå‘¨æœŸKçº¿æ•°æ®
        for interval, key in [("1h", "klines_1h"), ("4h", "klines_4h"), ("1d", "klines_1d")]:
            klines = _fetch_binance_klines(symbol, interval, limit=24)
            if klines:
                coin_data[key] = _analyze_klines(klines)

        # å¸‚åœºæ•°æ®ï¼ˆCMC/CG/CC æ•°æ®æºï¼‰
        market = fetch_market_snapshot(symbol)
        if market:
            coin_data["market"] = market

        # Binance OI
        coin_data["open_interest"] = _fetch_binance_open_interest(symbol)

        result[symbol] = coin_data
    
    return result


def _collect_valuescan_macro_data(symbols: List[str]) -> Dict[str, Dict[str, Any]]:
    result: Dict[str, Dict[str, Any]] = {}
    try:
        import sys
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if base_dir not in sys.path:
            sys.path.insert(0, base_dir)
        from valuescan_api import (
            get_main_force,
            get_hold_cost,
            get_inflow,
            get_detailed_inflow,
            get_token_flow,
            get_whale_flow,
            get_opportunity_signals,
            get_risk_signals,
            get_exchange_flow_detail,
            get_fund_trade_history_total,
            get_holder_page,
            get_chain_page,
        )
    except Exception as exc:
        logger.debug("ValuScan macro data import failed: %s", exc)
        return result

    for symbol in symbols:
        clean_symbol = symbol.upper().replace("USDT", "").replace("$", "").strip()
        item: Dict[str, Any] = {"symbol": clean_symbol}

        try:
            mf = get_main_force(clean_symbol, 15)
            if mf.get("code") == 200:
                mf_data = mf.get("data", [])
                if mf_data:
                    item["main_force"] = float(mf_data[-1]["price"])
        except Exception:
            pass

        try:
            hc = get_hold_cost(clean_symbol, 14)
            if hc.get("code") == 200:
                hc_data = hc.get("data", {}).get("holdingPrice", [])
                if hc_data:
                    item["main_cost"] = float(hc_data[-1]["val"])
        except Exception:
            pass

        try:
            inflow = get_inflow(clean_symbol)
            if inflow.get("code") == 200:
                item["trade_inflow"] = inflow.get("data", {})
        except Exception:
            pass

        try:
            detailed = get_detailed_inflow(clean_symbol)
            if detailed.get("code") == 200:
                item["detailed_inflow"] = detailed.get("data", {})
        except Exception:
            pass

        try:
            tf = get_token_flow("H12", 1, 20)
            if tf.get("code") == 200:
                item["token_flow"] = tf.get("data", {})
        except Exception:
            pass

        try:
            wf = get_whale_flow(1, "m5", 1, 20)
            if wf.get("code") == 200:
                item["whale_flow"] = wf.get("data", {})
        except Exception:
            pass

        try:
            os_data = get_opportunity_signals(1, 10)
            if os_data.get("code") == 200:
                item["opportunity_signals"] = os_data.get("data", {})
        except Exception:
            pass

        try:
            rs_data = get_risk_signals(1, 10)
            if rs_data.get("code") == 200:
                item["risk_signals"] = rs_data.get("data", {})
        except Exception:
            pass

        try:
            flow_detail = _normalize_exchange_flow_detail(get_exchange_flow_detail(clean_symbol))
            if flow_detail:
                item["exchange_flow_detail"] = flow_detail
        except Exception:
            pass

        try:
            flow_history = _compact_valuescan_history(
                get_fund_trade_history_total(
                    clean_symbol,
                    time_particle="12h",
                    limit_size=30,
                    flow=True,
                    trade_type=2,
                ),
                limit=30,
            )
            if flow_history:
                item["fund_flow_history"] = flow_history
        except Exception:
            pass

        try:
            volume_history = _compact_valuescan_history(
                get_fund_trade_history_total(
                    clean_symbol,
                    time_particle="12h",
                    limit_size=30,
                    flow=False,
                    trade_type=2,
                ),
                limit=30,
            )
            if volume_history:
                item["fund_volume_history"] = volume_history
        except Exception:
            pass

        try:
            holders = _compact_holder_items(get_holder_page(clean_symbol, page=1, page_size=5), limit=3)
            if holders:
                item["holders_top"] = holders
        except Exception:
            pass

        try:
            chains = _compact_chain_items(get_chain_page(clean_symbol, page=1, page_size=5), limit=5)
            if chains:
                item["chains"] = chains
        except Exception:
            pass

        if len(item) > 1:
            result[clean_symbol] = item

    return result


def _collect_quantitative_data(symbols: List[str]) -> Dict[str, Any]:
    """
    Collect quantitative snapshot data for a set of symbols.

    Args:
        symbols: symbols to query

    Returns:
        Aggregated quantitative data
    """
    if not symbols:
        return {"coins": [], "summary": {}}

    symbols_to_fetch = list(set(symbols))[:10]

    coin_data = []
    bullish_coins = []
    bearish_coins = []
    high_volume_coins = []

    for sym in symbols_to_fetch:
        data = fetch_market_snapshot(sym)
        if not data:
            continue

        coin_info = {
            "symbol": sym,
            "price": data.get("price"),
            "price_change_24h": data.get("price_change_percent"),
            "volume_24h": data.get("volume_24h"),
            "market_cap": data.get("market_cap"),
        }
        coin_data.append(coin_info)

        change = data.get("price_change_percent")
        if isinstance(change, (int, float)):
            if change >= 2:
                bullish_coins.append(sym)
            elif change <= -2:
                bearish_coins.append(sym)

        vol = data.get("volume_24h")
        if isinstance(vol, (int, float)) and vol >= 1e8:
            high_volume_coins.append(sym)

    return {
        "coins": coin_data,
        "summary": {
            "bullish_price": bullish_coins,
            "bearish_price": bearish_coins,
            "high_volume": high_volume_coins,
        },
    }


def _fetch_crypto_news() -> List[Dict[str, Any]]:
    """Fetch market news and trending coins."""
    news = []
    try:
        news = fetch_news(limit=5)
    except Exception as e:
        logger.debug("fetch_news failed: %s", e)

    trending = []
    try:
        trending = fetch_trending(limit=5)
    except Exception as e:
        logger.debug("fetch_trending failed: %s", e)

    if trending:
        news.append({
            "title": "Trending Coins",
            "source": "Market",
            "coins": trending,
        })
    return news


def _build_macro_analysis_prompt(
    major_coin_data: Dict[str, Dict[str, Any]],
    oi_ranking: List[Dict[str, Any]],
    signals: Dict[str, Any],
    valuescan_data: Optional[Dict[str, Dict[str, Any]]] = None,
    news: Optional[List[Dict[str, Any]]] = None,
    language: str = "zh",
) -> str:
    """Build macro summary prompt."""
    now = datetime.now(BEIJING_TZ)
    lines: List[str] = []
    sep = "\n"
    def _fmt_value(value):
        return f"{value:.2f}" if isinstance(value, (int, float)) else "N/A"

    def _compact_value(value, max_keys=4):
        if isinstance(value, dict):
            out = {}
            for idx, (key, val) in enumerate(value.items()):
                if idx >= max_keys:
                    break
                out[key] = val
            return out
        return value

    def _fmt_json(value):
        if value is None:
            return "N/A"
        return json.dumps(_compact_value(value), ensure_ascii=False)


    if language == "en":
        lines.append("You are a top crypto macro analyst. Produce a concise macro report based on the data.")
        lines.append("Priority: If ValuScan data exists, treat it as the highest-priority source; other data is supplementary.")
        lines.append(f"**Analysis Time**: {now.strftime('%Y-%m-%d %H:%M')} (Beijing Time)")
        lines.append("")
        lines.append("BTC/ETH Core Data:")
        for symbol in MAJOR_COINS:
            data = major_coin_data.get(symbol, {})
            lines.append("")
            lines.append(f"### {symbol}")
            for tf, key in [("1h", "klines_1h"), ("4h", "klines_4h"), ("1d", "klines_1d")]:
                kl = data.get(key, {})
                if kl:
                    lines.append(
                        f"{tf}: trend={kl.get('trend','N/A')}, price={kl.get('latest_price',0):.2f}, "
                        f"change={kl.get('price_change_pct',0):.2f}%, range={kl.get('price_range_pct',0):.2f}%, "
                        f"volume={kl.get('volume_ratio',1):.2f}x, MA5={kl.get('ma5',0):.2f}, MA10={kl.get('ma10',0):.2f}"
                    )
            market = data.get("market", {})
            if market:
                lines.append(
                    f"Market: price=${market.get('price',0):.2f}, change_24h={market.get('price_change_percent',0):.2f}%, "
                    f"volume_24h={market.get('volume_24h',0):.2f}, mcap={market.get('market_cap',0):.2f}, source={market.get('source','')}"
                )
            oi = data.get("open_interest")
            if oi:
                lines.append(f"Open Interest: {oi:.2f}")
            vs = valuescan_data.get(symbol, {}) if valuescan_data else {}
            if vs:
                main_force = vs.get("main_force")
                main_cost = vs.get("main_cost")
                if main_force or main_cost:
                    lines.append(
                        f"ValuScan Levels: main_force={_fmt_value(main_force)}, main_cost={_fmt_value(main_cost)}"
                    )
                trade_inflow = vs.get("trade_inflow")
                detailed_inflow = vs.get("detailed_inflow")
                if trade_inflow or detailed_inflow:
                    lines.append(
                        f"ValuScan Flow: trade_inflow={_fmt_json(trade_inflow)}, detailed_inflow={_fmt_json(detailed_inflow)}"
                    )
                token_flow = vs.get("token_flow")
                whale_flow = vs.get("whale_flow")
                if token_flow or whale_flow:
                    lines.append(
                        f"ValuScan Macro Flow: token_flow={_fmt_json(token_flow)}, whale_flow={_fmt_json(whale_flow)}"
                    )
                opportunity_signals = vs.get("opportunity_signals")
                risk_signals = vs.get("risk_signals")
                if opportunity_signals or risk_signals:
                    lines.append(
                        f"ValuScan Signals: opportunity={_fmt_json(opportunity_signals)}, risk={_fmt_json(risk_signals)}"
                    )
                flow_detail = vs.get("exchange_flow_detail")
                if flow_detail:
                    lines.append(f"ValuScan Exchange Flow Detail: {_fmt_json(flow_detail)}")
                fund_flow_history = vs.get("fund_flow_history")
                fund_volume_history = vs.get("fund_volume_history")
                if fund_flow_history or fund_volume_history:
                    lines.append(f"ValuScan Fund History: flow={_fmt_json(fund_flow_history)}, volume={_fmt_json(fund_volume_history)}")
                holders_top = vs.get("holders_top")
                chains = vs.get("chains")
                if holders_top or chains:
                    lines.append(f"ValuScan Holders/Chains: holders={_fmt_json(holders_top)}, chains={_fmt_json(chains)}")
        lines.append("")
        lines.append("Signals Summary:")
        lines.append(
            f"bullish={len(signals.get('bullish', []))}, "
            f"bearish={len(signals.get('bearish', []))}, whale={len(signals.get('whale', []))}"
        )
        if news:
            lines.append("")
            lines.append("News/Trends:")
            for item in news[:5]:
                title = item.get("title") or ""
                lines.append(f"- {title}")
        lines.append("")
        lines.append("Return a short macro conclusion and risk bias.")
        return sep.join(lines)

    lines.append("ä½ æ˜¯é¡¶çº§åŠ å¯†è´§å¸é‡åŒ–åˆ†æå¸ˆå’Œå®è§‚ç­–ç•¥å¸ˆã€‚åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆä¸“ä¸šçš„å¸‚åœºåˆ†ææŠ¥å‘Šã€‚")
    lines.append("ä¼˜å…ˆçº§è¯´æ˜ï¼šè‹¥å­˜åœ¨ ValuScan æ•°æ®ï¼Œè¯·ä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§æ¥æºï¼Œå…¶ä»–æ•°æ®ä»…ä½œè¾…åŠ©ã€‚")
    lines.append(f"åˆ†ææ—¶é—´: {now.strftime('%Y-%m-%d %H:%M')} (åŒ—äº¬æ—¶é—´)")
    lines.append(f"æ•°æ®å‘¨æœŸ: æœ€è¿‘{int(signals.get('lookback_hours', 48))}å°æ—¶")
    lines.append("")
    lines.append("BTC/ETH æ ¸å¿ƒæ•°æ®:")
    for symbol in MAJOR_COINS:
        data = major_coin_data.get(symbol, {})
        lines.append("")
        lines.append(f"{symbol} æ•°æ®")
        for tf, key in [("1h", "klines_1h"), ("4h", "klines_4h"), ("1d", "klines_1d")]:
            kl = data.get(key, {})
            if kl:
                lines.append(
                    f"{tf}: è¶‹åŠ¿={kl.get('trend','N/A')}, ä»·æ ¼={kl.get('latest_price',0):.2f}, "
                    f"æ¶¨è·Œ={kl.get('price_change_pct',0):.2f}%, æ³¢å¹…={kl.get('price_range_pct',0):.2f}%, "
                    f"æˆäº¤é‡={kl.get('volume_ratio',1):.2f}x, MA5={kl.get('ma5',0):.2f}, MA10={kl.get('ma10',0):.2f}"
                )
        market = data.get("market", {})
        if market:
            lines.append(
                f"å¸‚åœºæ•°æ®: ä»·æ ¼=${market.get('price',0):.2f}, 24Hæ¶¨è·Œ={market.get('price_change_percent',0):.2f}%, "
                f"24Hæˆäº¤é‡={market.get('volume_24h',0):.2f}, å¸‚å€¼={market.get('market_cap',0):.2f}, æ•°æ®æº={market.get('source','')}"
            )
        oi = data.get("open_interest")
        if oi:
            lines.append(f"æŒä»“é‡(OI): {oi:.2f}")
        vs = valuescan_data.get(symbol, {}) if valuescan_data else {}
        if vs:
            main_force = vs.get("main_force")
            main_cost = vs.get("main_cost")
            if main_force or main_cost:
                lines.append(
                    f"ValuScan ä¸»åŠ›ä½: main_force={_fmt_value(main_force)}, main_cost={_fmt_value(main_cost)}"
                )
            trade_inflow = vs.get("trade_inflow")
            detailed_inflow = vs.get("detailed_inflow")
            if trade_inflow or detailed_inflow:
                lines.append(
                    f"ValuScan èµ„é‡‘æµ: trade_inflow={_fmt_json(trade_inflow)}, detailed_inflow={_fmt_json(detailed_inflow)}"
                )
            token_flow = vs.get("token_flow")
            whale_flow = vs.get("whale_flow")
            if token_flow or whale_flow:
                lines.append(
                    f"ValuScan ???? token_flow={_fmt_json(token_flow)}, whale_flow={_fmt_json(whale_flow)}"
                )
            opportunity_signals = vs.get("opportunity_signals")
            risk_signals = vs.get("risk_signals")
            if opportunity_signals or risk_signals:
                lines.append(
                    f"ValuScan ?? opportunity={_fmt_json(opportunity_signals)}, risk={_fmt_json(risk_signals)}"
                )
            flow_detail = vs.get("exchange_flow_detail")
            if flow_detail:
                lines.append(f"ValuScan ????????????: exchange_flow_detail={_fmt_json(flow_detail)}")
            fund_flow_history = vs.get("fund_flow_history")
            fund_volume_history = vs.get("fund_volume_history")
            if fund_flow_history or fund_volume_history:
                lines.append(f"ValuScan ????????????: flow={_fmt_json(fund_flow_history)}, volume={_fmt_json(fund_volume_history)}")
            holders_top = vs.get("holders_top")
            chains = vs.get("chains")
            if holders_top or chains:
                lines.append(f"ValuScan ??????/?????????: holders={_fmt_json(holders_top)}, chains={_fmt_json(chains)}")
    lines.append("")
    lines.append("ä¿¡å·æ±‡æ€»:")
    lines.append(f"çœ‹æ¶¨={len(signals.get('bullish', []))}ä¸ª, çœ‹è·Œ={len(signals.get('bearish', []))}ä¸ª, å·¨é²¸={len(signals.get('whale', []))}ä¸ª")

    # æ·»åŠ å¸ç§æ¨èæ•°æ®
    bullish_coins = signals.get("recommended_bullish", [])
    bearish_coins = signals.get("recommended_bearish", [])
    opportunity_coins = signals.get("recommended_opportunity", [])

    if bullish_coins:
        lines.append("")
        lines.append("çœ‹æ¶¨å¸ç§æ¨èï¼ˆæŒ‰ä¿¡å·å¼ºåº¦æ’åºï¼‰:")
        for coin in bullish_coins[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            lines.append(
                f"- {coin['symbol']}: çœ‹æ¶¨ä¿¡å·{coin['bullish_count']}ä¸ª, "
                f"çœ‹è·Œä¿¡å·{coin['bearish_count']}ä¸ª, å·¨é²¸{coin['whale_count']}ä¸ª"
            )

    if bearish_coins:
        lines.append("")
        lines.append("çœ‹è·Œå¸ç§æ¨èï¼ˆæŒ‰ä¿¡å·å¼ºåº¦æ’åºï¼‰:")
        for coin in bearish_coins[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            lines.append(
                f"- {coin['symbol']}: çœ‹è·Œä¿¡å·{coin['bearish_count']}ä¸ª, "
                f"çœ‹æ¶¨ä¿¡å·{coin['bullish_count']}ä¸ª"
            )

    if opportunity_coins:
        lines.append("")
        lines.append("æœºä¼šå¸ç§æ¨èï¼ˆå·¨é²¸æ´»åŠ¨/å¥—åˆ©æœºä¼šï¼‰:")
        for coin in opportunity_coins[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            lines.append(
                f"- {coin['symbol']}: å·¨é²¸{coin['whale_count']}ä¸ª, "
                f"å¥—åˆ©{coin['arbitrage_count']}ä¸ª, æ€»ä¿¡å·{coin['total_signals']}ä¸ª"
            )

    if news:
        lines.append("")
        lines.append("æ–°é—»/çƒ­ç‚¹:")
        for item in news[:5]:
            title = item.get("title") or ""
            lines.append(f"- {title}")
    lines.append("")
    lines.append("ã€åˆ†æè¦æ±‚ã€‘")
    lines.append("ç”Ÿæˆä¸€ä»½ç²¾ç‚¼çš„å¸‚åœºåˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹5ä¸ªéƒ¨åˆ†ï¼š")
    lines.append("")
    lines.append("1. å¸‚åœºæ¦‚å†µï¼ˆ60-80å­—ï¼‰")
    lines.append("   BTC/ETHä»·æ ¼ã€æ¶¨è·Œå¹…ã€æŒä»“é‡ï¼Œå¸‚åœºæƒ…ç»ª")
    lines.append("")
    lines.append("2. æŠ€æœ¯åˆ†æï¼ˆ80-100å­—ï¼‰")
    lines.append("   å¤šå‘¨æœŸè¶‹åŠ¿ï¼Œå…³é”®æ”¯æ’‘é˜»åŠ›ä½ï¼ˆæ ¼å¼ï¼šBTCæ”¯æ’‘85000/83500ï¼Œé˜»åŠ›90000/92500ï¼‰")
    lines.append("")
    lines.append("3. å¸ç§æ¨èï¼ˆ80-100å­—ï¼‰")
    lines.append("   åŸºäºä¿¡å·æ•°æ®ï¼Œæ¨è2-3ä¸ªçœ‹æ¶¨å¸ç§ã€2-3ä¸ªçœ‹è·Œå¸ç§ã€2-3ä¸ªæœºä¼šå¸ç§")
    lines.append("   æ ¼å¼ï¼šã€çœ‹æ¶¨ã€‘BTCã€ETHï¼ˆç†ç”±ï¼‰ã€çœ‹è·Œã€‘DOGEï¼ˆç†ç”±ï¼‰ã€æœºä¼šã€‘LINKï¼ˆç†ç”±ï¼‰")
    lines.append("")
    lines.append("4. è¶‹åŠ¿ç ”åˆ¤ï¼ˆ60-80å­—ï¼‰")
    lines.append("   çŸ­æœŸï¼ˆ1-3å¤©ï¼‰è¶‹åŠ¿ï¼šçœ‹å¤š/çœ‹ç©º/éœ‡è¡ï¼Œæ¦‚ç‡å’Œè§¦å‘æ¡ä»¶")
    lines.append("")
    lines.append("5. æ“ä½œç­–ç•¥ï¼ˆ60-80å­—ï¼‰")
    lines.append("   ä»“ä½å»ºè®®ã€å…¥åœºç‚¹ä½ã€æ­¢æŸä½ã€ç›®æ ‡ä½")
    lines.append("")
    lines.append("ã€æ ¼å¼è¦æ±‚ã€‘")
    lines.append("1. ä¸ä½¿ç”¨markdownç¬¦å·ï¼ˆä¸è¦*ã€#ã€-ã€>ç­‰ï¼‰")
    lines.append("2. çº¯æ–‡æœ¬æ ¼å¼ï¼Œæ®µè½é—´ç©ºè¡Œåˆ†éš”")
    lines.append("3. é‡ç‚¹ç”¨ã€ã€‘æ ‡æ³¨ï¼Œå¦‚ã€æ ¸å¿ƒè§‚ç‚¹ã€‘ã€é£é™©è­¦ç¤ºã€‘")
    lines.append("4. æ•°æ®ç²¾ç¡®å¼•ç”¨ï¼Œå¦‚ï¼šBTCä»·æ ¼87576ç¾å…ƒï¼Œæ¶¨å¹…0.69%")
    lines.append("5. æ€»å­—æ•°æ§åˆ¶åœ¨400-500å­—")
    lines.append("6. è¨€ç®€æ„èµ…ï¼Œä¸“ä¸šæ·±åº¦ï¼Œé¿å…åºŸè¯")
    return sep.join(lines)


def _call_ai_api(prompt: str, config: Dict[str, Any], language: str = "zh") -> Optional[str]:
    """è°ƒç”¨ AI API ç”Ÿæˆåˆ†æ"""
    api_key = config.get("api_key", "")
    api_url = config.get("api_url", AI_SUMMARY_API_URL)
    model = config.get("model", AI_SUMMARY_MODEL)

    if not api_key:
        logger.error("AI API Key æœªé…ç½®")
        return None

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }

    system_prompt = (
        "You are a professional crypto market analyst. Output plain text only, no markdown symbols."
        if language == "en"
        else "ä½ æ˜¯ä¸“ä¸šçš„åŠ å¯†è´§å¸å¸‚åœºåˆ†æå¸ˆã€‚åªè¾“å‡ºçº¯æ–‡æœ¬ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•markdownç¬¦å·ï¼ˆä¸è¦ç”¨*ã€#ã€-ã€>ç­‰ï¼‰ã€‚"
    )

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ],
        "max_tokens": 4000,  # å¢åŠ åˆ°4000ä»¥ç¡®ä¿å®Œæ•´è¾“å‡º
        "temperature": 0.7,
    }

    try:
        # æ˜¾å¼ç¦ç”¨ä»£ç†ç›´æ¥è¿æ¥ AI API
        logger.info(f"[AI Market] è°ƒç”¨ AI API: {api_url} (æ— ä»£ç†)")
        session = requests.Session()
        session.trust_env = False
        resp = session.post(api_url, headers=headers, json=payload, timeout=120)
        if resp.status_code != 200:
            logger.error("AI API è¿”å›é”™è¯¯: %s - %s", resp.status_code, resp.text[:200])
            return None
        data = resp.json()
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        logger.info(f"[AI Market] AI API è¿”å›æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(content) if content else 0}")
        return content.strip() if content else None
    except Exception as e:
        logger.error("AI API è°ƒç”¨å¤±è´¥: %s", e)
        return None


def _send_summary_to_telegram(summary: str, language: str = "zh") -> bool:
    """å‘é€æ€»ç»“åˆ° Telegram"""
    from telegram import send_telegram_message
    
    now = datetime.now(BEIJING_TZ)
    if language == "en":
        header = f"ğŸ“Š AI Market Summary\nâ° {now.strftime('%Y-%m-%d %H:%M')} (Beijing Time)\n\n"
    else:
        header = f"ğŸ“Š AI å¸‚åœºæ€»ç»“\nâ° {now.strftime('%Y-%m-%d %H:%M')} (åŒ—äº¬æ—¶é—´)\n\n"
    
    # æ¸…ç†æ¶ˆæ¯ï¼Œç§»é™¤ markdown æ ¼å¼ï¼Œä½¿ç”¨çº¯æ–‡æœ¬
    message = header + summary
    # ç§»é™¤ markdown æ ¼å¼ç¬¦å·
    message = message.replace("**", "")
    message = message.replace("###", "")
    message = message.replace("---", "")
    # ç§»é™¤å¯èƒ½å¯¼è‡´ HTML è§£æé”™è¯¯çš„æ ‡ç­¾
    message = message.replace("<b>", "").replace("</b>", "")
    message = message.replace("<i>", "").replace("</i>", "")
    
    # ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼å‘é€ï¼Œä¸ä½¿ç”¨ HTML è§£æ
    result = send_telegram_message(message, pin_message=False, parse_mode=None)
    return result is not None and result.get("success", False)


def generate_market_summary(force: bool = False) -> Optional[str]:
    """
    ç”Ÿæˆä¸“ä¸šçš„å®è§‚å¸‚åœºåˆ†ææŠ¥å‘Š

    Args:
        force: æ˜¯å¦å¼ºåˆ¶ç”Ÿæˆï¼ˆå¿½ç•¥æ—¶é—´é—´éš”ï¼‰

    Returns:
        ç”Ÿæˆçš„åˆ†ææ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    global _last_summary_time

    # ä½¿ç”¨AIå¸‚åœºåˆ†æçš„ç‹¬ç«‹é…ç½®
    config = get_ai_market_config()
    language = _get_language()

    if not config.get("enabled") and not force:
        logger.debug("AI å¸‚åœºæ€»ç»“åŠŸèƒ½æœªå¯ç”¨")
        return None

    # æ£€æŸ¥æ—¶é—´é—´éš”
    interval_seconds = config.get("interval_hours", 1) * 3600
    now = time.time()
    if not force and (now - _last_summary_time) < interval_seconds:
        logger.debug("è·ç¦»ä¸Šæ¬¡æ€»ç»“æ—¶é—´ä¸è¶³ï¼Œè·³è¿‡")
        return None

    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹ç”Ÿæˆ AI å®è§‚å¸‚åœºåˆ†æ...")
    logger.info("=" * 60)

    try:
        # 1. æ”¶é›† BTC/ETH æ ¸å¿ƒæ•°æ®ï¼ˆKçº¿ + é‡åŒ–æ•°æ®ï¼‰
        logger.info("ğŸ“Š [1/6] æ”¶é›† BTC/ETH æ ¸å¿ƒæ•°æ®...")
        major_coin_data = _collect_major_coin_data()
        logger.info(f"   âœ… æ”¶é›†åˆ° {len(major_coin_data)} ä¸ªä¸»æµå¸æ•°æ®")

        # 2. è·å– OI æ’è¡Œæ•°æ®
        logger.info("ğŸ“ˆ [2/6] è·å– OI æ’è¡Œæ•°æ®...")
        oi_ranking = []
        logger.info(f"   âœ… OI æ’è¡Œæ•°æ®: {len(oi_ranking)} æ¡")

        # 3. æ”¶é›† ValueScan ä¿¡å·æ•°æ®
        lookback = config.get("lookback_hours", 1)
        logger.info(f"ğŸ” [3/6] æ”¶é›†æœ€è¿‘ {lookback} å°æ—¶ä¿¡å·æ•°æ®...")
        signals = _collect_recent_signals(lookback)
        total_signals = signals.get("total_count", 0)
        valuescan_macro = _collect_valuescan_macro_data(MAJOR_COINS)
        if valuescan_macro:
            logger.info("   ValuScan macro data: %s symbols", len(valuescan_macro))
        else:
            logger.info("   ValuScan macro data not available")
        logger.info(f"   âœ… æ”¶é›†åˆ° {total_signals} ä¸ªä¿¡å·")

        # 4. è·å–æ–°é—»æ•°æ®
        logger.info("ğŸ“° [4/6] è·å–å¸‚åœºæ–°é—»...")
        news = _fetch_crypto_news()
        logger.info(f"   âœ… æ”¶é›†åˆ° {len(news) if news else 0} æ¡æ–°é—»")

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿæ•°æ®
        if not major_coin_data and not oi_ranking and total_signals == 0:
            logger.warning("âš ï¸  æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œè·³è¿‡æ€»ç»“")
            return None

        # 5. æ„å»ºä¸“ä¸šå®è§‚åˆ†æ prompt
        logger.info("ğŸ¤– [5/6] è°ƒç”¨ AI ç”Ÿæˆåˆ†æ...")
        prompt = _build_macro_analysis_prompt(major_coin_data, oi_ranking, signals, valuescan_macro, news, language=language)

        # è°ƒç”¨ AI
        summary = _call_ai_api(prompt, config, language=language)
        if not summary:
            logger.error("âŒ AI ç”Ÿæˆåˆ†æå¤±è´¥")
            return None

        logger.info(f"   âœ… AI åˆ†æç”ŸæˆæˆåŠŸ ({len(summary)} å­—ç¬¦)")
        _last_summary_time = now

        # 6. å‘é€åˆ° Telegram
        logger.info("ğŸ“¤ [6/6] å‘é€åˆ° Telegram...")
        if _send_summary_to_telegram(summary, language=language):
            logger.info("   âœ… å¸‚åœºåˆ†æå·²å‘é€åˆ° Telegram")
        else:
            logger.warning("   âš ï¸  å¸‚åœºåˆ†æå‘é€åˆ° Telegram å¤±è´¥")

        logger.info("=" * 60)
        logger.info("âœ… AI å®è§‚å¸‚åœºåˆ†æå®Œæˆï¼")
        logger.info("=" * 60)

        return summary

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¸‚åœºåˆ†ææ—¶å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def check_and_generate_summary() -> None:
    """
    æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“ï¼ˆç”± polling_monitor å®šæœŸè°ƒç”¨ï¼‰
    """
    # ä½¿ç”¨AIå¸‚åœºåˆ†æçš„ç‹¬ç«‹é…ç½®
    config = get_ai_market_config()
    if not config.get("enabled"):
        return

    interval_seconds = config.get("interval_hours", 1) * 3600
    now = time.time()

    if (now - _last_summary_time) >= interval_seconds:
        generate_market_summary()


def main():
    """æµ‹è¯•å…¥å£"""
    import argparse
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
    )
    
    parser = argparse.ArgumentParser(description="AI å¸‚åœºæ€»ç»“")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶ç”Ÿæˆæ€»ç»“")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•æ¨¡å¼ï¼ˆä¸å‘é€ Telegramï¼‰")
    args = parser.parse_args()
    
    if args.test:
        config = get_ai_summary_config()
        print("å½“å‰é…ç½®:", json.dumps(config, ensure_ascii=False, indent=2))
        
        signals = _collect_recent_signals()
        print(f"\nä¿¡å·ç»Ÿè®¡: {signals.get('total_count', 0)} æ¡")
        print(f"  çœ‹æ¶¨: {len(signals.get('bullish', []))}")
        print(f"  çœ‹è·Œ: {len(signals.get('bearish', []))}")
        
        movements = _collect_movement_data()
        print(f"\nAlpha å¸ç§: {len(movements.get('alpha_coins', []))}")
        print(f"FOMO å¸ç§: {len(movements.get('fomo_coins', []))}")
    else:
        summary = generate_market_summary(force=args.force)
        if summary:
            print("\nç”Ÿæˆçš„æ€»ç»“:\n")
            print(summary)
        else:
            print("ç”Ÿæˆæ€»ç»“å¤±è´¥")


if __name__ == "__main__":
    main()
