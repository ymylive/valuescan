#!/usr/bin/env python3
"""
ValueScan 配置管理 API 服务

Includes:
- Configuration management
- Service control
- AI Trading API routes
- WebSocket support for real-time updates
"""
import os
import sys
import json
import subprocess
import secrets
import time
import shutil
import hmac
import hashlib
import base64
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
from flask import Flask, jsonify, request, send_from_directory, Response, make_response
from flask_cors import CORS
from flask_socketio import SocketIO, emit, join_room, leave_room
import threading
from http.cookies import SimpleCookie

# Import config validator
try:
    from api.config_validator import validate_config
except ImportError:
    from config_validator import validate_config

# Import performance database
try:
    from api.performance_db import PerformanceDatabase
except ImportError:
    from performance_db import PerformanceDatabase

app = Flask(__name__, static_folder='../web/dist', static_url_path='')
CORS(app)

# Initialize SocketIO with CORS support
# Requirements: 4.2 - Real-time updates within 2 seconds
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Global cache for log monitoring threads
# Key: service_name, Value: {'process': subprocess.Popen, 'clients': int}
_log_monitors = {}
_log_monitors_lock = threading.Lock()

# One-time ValueScan browser import sessions now use a stateless, signed token
# to survive multi-worker Gunicorn deployments and proxy IP changes.
_login_secret_cache = None

# Initialize performance database
BASE_DIR = Path(__file__).resolve().parent.parent
DB_PATH = os.getenv('VALUESCAN_PERFORMANCE_DB_PATH', str(BASE_DIR / 'data' / 'performance.db'))
performance_db = PerformanceDatabase(DB_PATH)


def _valuescan_login_secret() -> bytes:
    """
    Resolve a stable secret for signing login nonces.
    Priority:
      1) VALUESCAN_LOGIN_NONCE_SECRET env
      2) ./valuescan_login_secret file (auto-created, chmod 600)
    """
    global _login_secret_cache
    if _login_secret_cache:
        return _login_secret_cache

    env_secret = (os.getenv("VALUESCAN_LOGIN_NONCE_SECRET") or "").strip()
    if env_secret:
        _login_secret_cache = env_secret.encode("utf-8")
        return _login_secret_cache

    secret_path = Path(__file__).resolve().parent / "valuescan_login_secret"
    if not secret_path.exists():
        try:
            secret_path.write_text(secrets.token_hex(32), encoding="utf-8")
            secret_path.chmod(0o600)
        except FileExistsError:
            pass
        except Exception:
            # Best effort; fall back to in-memory secret (per worker) to avoid crash
            _login_secret_cache = secrets.token_bytes(32)
            return _login_secret_cache

    try:
        _login_secret_cache = secret_path.read_text(encoding="utf-8").strip().encode("utf-8")
        if not _login_secret_cache:
            _login_secret_cache = secrets.token_bytes(32)
    except Exception:
        _login_secret_cache = secrets.token_bytes(32)
    return _login_secret_cache


def _client_ip() -> str:
    """Best-effort client IP (respects X-Forwarded-For)."""
    xff = request.headers.get("X-Forwarded-For", "")
    if xff:
        return xff.split(",")[0].strip()
    return request.remote_addr or ""


def _make_signed_nonce(ip: str, ttl_seconds: int) -> str:
    exp = int(time.time() + ttl_seconds)
    nonce = secrets.token_urlsafe(24)
    secret = _valuescan_login_secret()
    enforce_ip = os.getenv("VALUESCAN_LOGIN_ENFORCE_IP", "0") == "1"
    body = f"vsi1|{nonce}|{exp}|{ip if enforce_ip else ''}"
    sig = hmac.new(secret, body.encode("utf-8"), hashlib.sha256).digest()
    sig_b64 = base64.urlsafe_b64encode(sig).decode("ascii").rstrip("=")
    return f"vsi1.{nonce}.{exp}.{sig_b64}"


def _verify_signed_nonce(token: str, current_ip: str) -> tuple[bool, str]:
    """
    Validate signed nonce; returns (ok, error_message).
    Accepts tokens generated by _make_signed_nonce.
    """
    if not isinstance(token, str) or not token.startswith("vsi1."):
        return False, "Invalid or expired nonce"
    parts = token.split(".")
    if len(parts) != 4:
        return False, "Invalid or expired nonce"
    _, nonce, exp_str, sig_b64 = parts
    try:
        exp = int(exp_str)
    except Exception:
        return False, "Invalid or expired nonce"
    if exp < time.time():
        return False, "Invalid or expired nonce"

    enforce_ip = os.getenv("VALUESCAN_LOGIN_ENFORCE_IP", "0") == "1"
    secret = _valuescan_login_secret()
    body = f"vsi1|{nonce}|{exp}|{current_ip if enforce_ip else ''}"
    expected_sig = hmac.new(secret, body.encode("utf-8"), hashlib.sha256).digest()
    try:
        provided_sig = base64.urlsafe_b64decode(sig_b64 + "==")
    except Exception:
        return False, "Invalid or expired nonce"

    if not hmac.compare_digest(expected_sig, provided_sig):
        return False, "Invalid or expired nonce"
    return True, ""

def _monitor_logs(service_name, service_unit):
    """Background thread to monitor logs and emit to socketio"""
    print(f"[LogMonitor] Starting monitor for {service_name}")
    process = None
    try:
        # -n 0 means start reading from current end of file (follow only)
        process = subprocess.Popen(
            ['journalctl', '-u', service_unit, '-f', '-n', '0', '--output', 'short'],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1
        )
        
        with _log_monitors_lock:
            if service_name in _log_monitors:
                _log_monitors[service_name]['process'] = process

        # Read line by line
        for line in iter(process.stdout.readline, ''):
            if line:
                socketio.emit('log_update', {'service': service_name, 'line': line.strip()}, room=service_name)
            
            # Check if we should stop (no clients left)
            should_stop = False
            with _log_monitors_lock:
                if service_name not in _log_monitors or _log_monitors[service_name]['clients'] <= 0:
                    should_stop = True
            
            if should_stop:
                break
                
    except Exception as e:
        print(f"[LogMonitor] Error monitoring {service_name}: {e}")
    finally:
        if process:
            try:
                process.terminate()
                process.wait(timeout=1)
            except:
                pass
        
        with _log_monitors_lock:
            # Only delete if we are the current process (race condition check)
            if service_name in _log_monitors and _log_monitors[service_name].get('process') == process:
                # Double check clients count, if 0, remove. 
                # If clients > 0, it means we might have restarted or something weird, but here we break loop if clients <= 0
                if _log_monitors[service_name]['clients'] <= 0:
                    del _log_monitors[service_name]
                    
        print(f"[LogMonitor] Stopped monitor for {service_name}")

@socketio.on('join_log_stream')
def handle_join_log_stream(data):
    service = data.get('service')
    service_map = {
        'signal': 'valuescan-signal',
        'trader': 'valuescan-trader',
        'proxy': 'proxy-checker',
        'xray': 'xray'
    }
    
    if service not in service_map:
        return
    
    join_room(service)
    print(f"[LogMonitor] Client joined {service}")
    
    with _log_monitors_lock:
        if service not in _log_monitors:
            _log_monitors[service] = {'clients': 0, 'process': None}
            # Start background thread
            thread = threading.Thread(target=_monitor_logs, args=(service, service_map[service]))
            thread.daemon = True
            thread.start()
        
        _log_monitors[service]['clients'] += 1
    
    emit('log_stream_status', {'service': service, 'status': 'connected'})

@socketio.on('leave_log_stream')
def handle_leave_log_stream(data):
    service = data.get('service')
    if service:
        leave_room(service)
        print(f"[LogMonitor] Client left {service}")
        with _log_monitors_lock:
            if service in _log_monitors:
                _log_monitors[service]['clients'] = max(0, _log_monitors[service]['clients'] - 1)

# Add ai_trading to path for imports
BASE_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BASE_DIR))

# Register AI Trading blueprints
try:
    from ai_trading.api.routes import register_blueprints
    register_blueprints(app)
    AI_TRADING_AVAILABLE = True
except ImportError as e:
    print(f"AI Trading module not available: {e}")
    AI_TRADING_AVAILABLE = False

# Simulation module has been removed - SIMULATION_AVAILABLE is always False
SIMULATION_AVAILABLE = False

# Register Tuning blueprints
try:
    from ai_trading.tuning import tuning_bp
    app.register_blueprint(tuning_bp)
    TUNING_AVAILABLE = True
except ImportError as e:
    print(f"Tuning module not available: {e}")
    TUNING_AVAILABLE = False

# Register LLM blueprints
try:
    from ai_trading.llm import llm_bp
    app.register_blueprint(llm_bp)
    LLM_AVAILABLE = True
except ImportError as e:
    print(f"LLM module not available: {e}")
    LLM_AVAILABLE = False

# Register Exchange blueprints
try:
    from ai_trading.exchanges import exchange_bp
    app.register_blueprint(exchange_bp)
    EXCHANGES_AVAILABLE = True
except ImportError as e:
    print(f"Exchange module not available: {e}")
    EXCHANGES_AVAILABLE = False

SIGNAL_CONFIG = BASE_DIR / 'signal_monitor' / 'config.py'
TRADER_CONFIG = BASE_DIR / 'binance_trader' / 'config.py'
COPYTRADE_CONFIG = BASE_DIR / 'telegram_copytrade' / 'config.py'
SIGNAL_TEMPLATE = BASE_DIR / 'signal_monitor' / 'config.example.py'
TRADER_TEMPLATE = BASE_DIR / 'binance_trader' / 'config.example.py'
COPYTRADE_TEMPLATE = BASE_DIR / 'telegram_copytrade' / 'config.example.py'

# ValueScan login artifacts (can be overridden in tests via monkeypatch)
VALUESCAN_COOKIES_FILE = BASE_DIR / 'signal_monitor' / 'valuescan_cookies.json'
VALUESCAN_TOKEN_FILE = BASE_DIR / 'signal_monitor' / 'valuescan_localstorage.json'
VALUESCAN_SESSION_FILE = BASE_DIR / 'signal_monitor' / 'valuescan_sessionstorage.json'
VALUESCAN_CREDENTIALS_FILE = BASE_DIR / 'signal_monitor' / 'valuescan_credentials.json'
VALUESCAN_COINPOOL_CONFIG_FILE = BASE_DIR / 'config' / 'valuescan_coinpool.json'
KEEPALIVE_CONFIG_FILE = BASE_DIR / 'keepalive_config.json'
VALUESCAN_API_BASE = os.getenv("VALUESCAN_API_BASE", "https://api.valuescan.io").rstrip("/")
VALUESCAN_ACCESS_TICKET_FALLBACK = (os.getenv("VALUESCAN_ACCESS_TICKET_FALLBACK") or "LNe1VTyHk0bij3cyWB2gxg==").strip()
_VALUESCAN_DEFAULT_BASES = [
    "https://api.valuescan.io",
    "https://www.valuescan.io",
]
VALUESCAN_API_TIMEOUT = float(os.getenv("VALUESCAN_API_TIMEOUT", "15"))
VALUESCAN_WARN_PATH = os.getenv(
    "VALUESCAN_WARN_PATH", "/api/account/message/getWarnMessage"
).strip() or "/api/account/message/getWarnMessage"
VALUESCAN_AI_MESSAGE_PATH = os.getenv(
    "VALUESCAN_AI_MESSAGE_PATH", "/api/account/message/aiMessagePage"
).strip() or "/api/account/message/aiMessagePage"
VALUESCAN_MOVEMENT_LIST_PATH = os.getenv(
    "VALUESCAN_MOVEMENT_LIST_PATH", "/api/chance/getFundsMovementPage"
).strip() or "/api/chance/getFundsMovementPage"
VALUESCAN_MOVEMENT_UPDATE_PATH = os.getenv(
    "VALUESCAN_MOVEMENT_UPDATE_PATH", "/api/chance/getFundsMovementUpdate"
).strip() or "/api/chance/getFundsMovementUpdate"

_MAX_JSON_FILE_BYTES = 5 * 1024 * 1024

# Keepalive config validation constants
KEEPALIVE_MIN_CHECK_INTERVAL = 10
KEEPALIVE_MAX_CHECK_INTERVAL = 300
KEEPALIVE_DEFAULT_CHECK_INTERVAL = 60
KEEPALIVE_DEFAULT_RESTART_COOLDOWN = 300
SERVICE_ENV_DROPIN_DIR = Path("/etc/systemd/system")

# Services that should receive VALUESCAN_EMAIL / VALUESCAN_PASSWORD envs when provided
VALUESCAN_ENV_TARGET_SERVICES = [
    "valuescan-signal.service",
    "valuescan-monitor.service",
]
VALUESCAN_ENV_FILE = Path(
    os.getenv("VALUESCAN_ENV_FILE", str(BASE_DIR / "config" / "valuescan.env"))
)
VALUESCAN_ENV_ALLOWED_KEYS: List[str] = []
VALUESCAN_ENV_BOOL_KEYS: set[str] = set()
VALUESCAN_ENV_INT_KEYS: set[str] = set()


def _read_json_file(path: Path, default):
    try:
        if not path.exists():
            return default
        if path.stat().st_size > _MAX_JSON_FILE_BYTES:
            raise ValueError(f"File too large: {path.name}")
        return json.loads(path.read_text(encoding="utf-8", errors="ignore") or "null")
    except Exception:
        return default


def _write_json_file(path: Path, payload) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    content = json.dumps(payload, ensure_ascii=False, indent=2)
    if len(content.encode("utf-8")) > _MAX_JSON_FILE_BYTES:
        raise ValueError(f"Payload too large: {path.name}")
    path.write_text(content, encoding="utf-8")


def _parse_env_file(path: Path) -> Dict[str, str]:
    env: Dict[str, str] = {}
    if not path.exists():
        return env
    try:
        for raw_line in path.read_text(encoding="utf-8", errors="ignore").splitlines():
            line = raw_line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue
            key, value = line.split("=", 1)
            env[key.strip()] = value.strip()
    except Exception:
        return env
    return env


def _normalize_env_value(key: str, value) -> Optional[str]:
    if value is None:
        return None
    if isinstance(value, str):
        raw = value.strip()
        if raw == "":
            return None
    if key in VALUESCAN_ENV_BOOL_KEYS:
        if isinstance(value, bool):
            return "1" if value else "0"
        raw = str(value).strip().lower()
        return "1" if raw in {"1", "true", "yes", "on"} else "0"
    if key in VALUESCAN_ENV_INT_KEYS:
        try:
            return str(int(value))
        except Exception:
            return None
    return str(value).strip()


def _write_env_file(path: Path, values: Dict[str, str], extras: Dict[str, str]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    lines = ["# Generated by ValueScan API/UI. Edit with care."]
    for key in VALUESCAN_ENV_ALLOWED_KEYS:
        if key in values and values[key] is not None:
            lines.append(f"{key}={values[key]}")
    for key in sorted(extras):
        if key not in values and extras[key] is not None:
            lines.append(f"{key}={extras[key]}")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def _write_systemd_env_dropin(service_unit: str, env_path: Path) -> bool:
    try:
        dropin_dir = SERVICE_ENV_DROPIN_DIR / f"{service_unit}.d"
        dropin_dir.mkdir(parents=True, exist_ok=True)
        dropin_path = dropin_dir / "valuescan-env.conf"
        content = "[Service]\nEnvironmentFile={}\n".format(env_path)
        dropin_path.write_text(content, encoding="utf-8")
        return True
    except Exception:
        return False


def _external_origin_from_request() -> str:
    """
    Resolve the dashboard origin for bookmarklet redirects.

    Priority:
      1) VALUESCAN_DASHBOARD_ORIGIN env (e.g. https://cornna.abrdns.com)
      2) X-Forwarded-Proto + Host headers (typical reverse proxy)
      3) request.host_url (falls back to http://)
    """
    env_origin = (os.getenv("VALUESCAN_DASHBOARD_ORIGIN") or "").strip().rstrip("/")
    if env_origin:
        return env_origin

    forwarded_proto = request.headers.get("X-Forwarded-Proto", "").split(",")[0].strip()
    host = request.headers.get("X-Forwarded-Host", "").split(",")[0].strip() or request.headers.get("Host", "")
    if forwarded_proto and host:
        return f"{forwarded_proto}://{host}"

    return request.host_url.rstrip("/")

# 导入数据库模块
sys.path.insert(0, str(BASE_DIR / 'signal_monitor'))
sys.path.insert(0, str(BASE_DIR / 'api'))
try:
    from database import get_database
except ImportError:
    get_database = None

# 导入性能数据库模块
try:
    from performance_db import PerformanceDatabase, TradeRecord, get_performance_db
    from metrics_calculator import MetricsCalculator, TraderRanking, sort_rankings_by_pnl
    PERFORMANCE_DB_AVAILABLE = True
except ImportError as e:
    print(f"Performance DB module not available: {e}")
    PERFORMANCE_DB_AVAILABLE = False

# 币安客户端
_binance_client = None
_binance_client_mode = None
_public_tickers_cache = {
    'ts': 0.0,
    'data': None,
    'error': None,
}

def get_binance_client(use_testnet: Optional[bool] = None):
    """获取币安客户端（支持代理/测试网）"""
    global _binance_client
    global _binance_client_mode
    try:
        from binance.client import Client
        config = parse_config(TRADER_CONFIG)
        api_key = config.get('binance_api_key', '')
        api_secret = config.get('binance_api_secret', '')
        proxy = config.get('socks5_proxy', '')
        if use_testnet is None:
            use_testnet = bool(config.get('use_testnet', False))

        if _binance_client and _binance_client_mode == use_testnet:
            return _binance_client

        if api_key and api_secret:
            requests_params = {}
            if proxy and proxy.startswith('socks5://'):
                requests_params['proxies'] = {
                    'http': proxy,
                    'https': proxy
                }
            client = Client(api_key, api_secret, requests_params=requests_params)
            if use_testnet:
                client.FUTURES_URL = 'https://testnet.binancefuture.com/fapi'
            _binance_client = client
            _binance_client_mode = use_testnet
            return _binance_client
    except Exception as e:
        print(f"Binance client error: {e}")
    return None

def parse_config(filepath: Path) -> dict:
    """解析 Python 配置文件（KEY = 字面量），返回 key 小写的 dict。"""
    config: dict = {}
    if not filepath.exists():
        return config

    try:
        content = filepath.read_text(encoding='utf-8')
    except Exception:
        return config

    def _to_jsonable(value):
        if isinstance(value, tuple):
            return [_to_jsonable(v) for v in value]
        if isinstance(value, list):
            return [_to_jsonable(v) for v in value]
        if isinstance(value, dict):
            return {str(k): _to_jsonable(v) for k, v in value.items()}
        return value

    try:
        import ast

        def _extract(nodes):
            for node in nodes:
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                    continue

                if isinstance(node, ast.Assign):
                    try:
                        value = ast.literal_eval(node.value)
                    except Exception:
                        continue
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            config[target.id.lower()] = _to_jsonable(value)
                    continue

                if isinstance(node, ast.AnnAssign):
                    if isinstance(node.target, ast.Name) and node.value is not None:
                        try:
                            value = ast.literal_eval(node.value)
                        except Exception:
                            continue
                        config[node.target.id.lower()] = _to_jsonable(value)
                    continue

                if isinstance(node, ast.Try):
                    _extract(node.body)
                    for handler in node.handlers:
                        _extract(handler.body)
                    _extract(node.orelse)
                    _extract(node.finalbody)
                    continue

                if isinstance(node, ast.If):
                    _extract(node.body)
                    _extract(node.orelse)
                    continue

        tree = ast.parse(content)
        _extract(tree.body)
        return config
    except Exception:
        # fallback: 基础行解析（只支持简单类型）
        import re

        for line in content.splitlines():
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('"""') or line.startswith("'''"):
                continue

            match = re.match(r'^(\w+)\s*=\s*["\']([^"\']*)["\']', line)
            if match:
                config[match.group(1).lower()] = match.group(2)
                continue

            match = re.match(r'^(\w+)\s*=\s*(True|False)\b', line)
            if match:
                config[match.group(1).lower()] = match.group(2) == 'True'
                continue

            match = re.match(r'^(\w+)\s*=\s*None\b', line)
            if match:
                config[match.group(1).lower()] = None
                continue

            match = re.match(r'^(\w+)\s*=\s*(-?\d+\.?\d*)\s*(?:#|$)', line)
            if match:
                val = match.group(2)
                config[match.group(1).lower()] = float(val) if '.' in val else int(val)
                continue

        return config

def _normalize_coin_base_symbol(raw: str) -> str:
    import re
    s = str(raw or "").strip().upper()
    if not s:
        return ""
    # Remove separators like "BTC-USDT", "BTC/USDT", "BTC USDT"
    s = re.sub(r"[-_/\\s]+", "", s)
    for suffix in ("USDT", "BUSD", "USD", "PERP"):
        if s.endswith(suffix):
            s = s[: -len(suffix)]
            break
    return s

def generate_config(config: dict, template_path: Path) -> str:
    """生成配置文件内容"""
    if not template_path.exists():
        print(f"[API] Template not found: {template_path}")
        return ""
    
    with open(template_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    import re
    updated_keys = []
    skipped_keys = []

    def _python_literal(val, inline: bool = False) -> str:
        if isinstance(val, bool):
            return 'True' if val else 'False'
        if val is None:
            return 'None'
        if isinstance(val, (int, float)):
            return str(val)
        if isinstance(val, str):
            escaped = val.replace('\\', '\\\\').replace('"', '\\"')
            return f'"{escaped}"'
        if isinstance(val, tuple):
            # Tuples should be rendered inline as (a, b, c)
            items = ', '.join(_python_literal(item, inline=True) for item in val)
            return f'({items})'
        if isinstance(val, list):
            if not val:
                return '[]'
            # Check if this is a list of tuples/simple values (like pyramiding levels)
            # If so, render each item inline
            all_simple = all(
                isinstance(item, (int, float, str, bool, type(None))) or
                (isinstance(item, (list, tuple)) and len(item) <= 3 and 
                 all(isinstance(x, (int, float, str, bool, type(None))) for x in item))
                for item in val
            )
            if all_simple or inline:
                # Render as multi-line list with inline items
                lines = ['[']
                for item in val:
                    if isinstance(item, (list, tuple)):
                        # Convert list to tuple for cleaner syntax
                        items = ', '.join(_python_literal(x, inline=True) for x in item)
                        lines.append(f'    ({items}),')
                    else:
                        lines.append(f'    {_python_literal(item, inline=True)},')
                lines.append(']')
                return '\n'.join(lines)
            else:
                # Complex nested structure
                lines = ['[']
                for item in val:
                    lines.append(f'    {_python_literal(item, inline=True)},')
                lines.append(']')
                return '\n'.join(lines)
        if isinstance(val, dict):
            if not val:
                return '{}'
            lines = ['{']
            for k, v in val.items():
                key_str = _python_literal(str(k))
                lines.append(f'    {key_str}: {_python_literal(v)},')
            lines.append('}')
            return '\n'.join(lines)
        return _python_literal(str(val))

    def _replace_assignment(text: str, key_upper: str, literal: str) -> str:
        # Multiline list/dict: replace the whole block first to avoid leaving old lines behind.
        if '\n' in literal:
            if literal.lstrip().startswith('['):
                block_pat = rf'^{key_upper}\b\s*=\s*\[[\s\S]*?\]\s*(?:#.*)?$'
                if re.search(block_pat, text, flags=re.MULTILINE):
                    return re.sub(
                        block_pat,
                        lambda m: f'{key_upper} = {literal}',
                        text,
                        count=0,
                        flags=re.MULTILINE,
                    )
            if literal.lstrip().startswith('{'):
                block_pat = rf'^{key_upper}\b\s*=\s*\{{[\s\S]*?\}}\s*(?:#.*)?$'
                if re.search(block_pat, text, flags=re.MULTILINE):
                    return re.sub(
                        block_pat,
                        lambda m: f'{key_upper} = {literal}',
                        text,
                        count=0,
                        flags=re.MULTILINE,
                    )

        line_pat = rf'^({key_upper}\b\s*=\s*)(.*?)(\s*(#.*)?)$'

        def _repl(m):
            suffix = m.group(3) or ''
            return f'{m.group(1)}{literal}{suffix}'

        # Replace all occurrences to avoid duplicate-key bugs (e.g. TELEGRAM_BOT_TOKEN appears twice).
        return re.sub(line_pat, _repl, text, count=0, flags=re.MULTILINE)

    for key, value in (config or {}).items():
        upper_key = str(key).upper()
        original_content = content
        literal_value = _python_literal(value)
        content = _replace_assignment(content, upper_key, literal_value)

        if content != original_content:
            updated_keys.append(key)
        else:
            skipped_keys.append(key)
    
    if updated_keys:
        print(f"[API] Config keys updated: {updated_keys}")
    if skipped_keys:
        print(f"[API] Config keys skipped (not in template): {skipped_keys}")
    
    return content


def normalize_copytrade_config(payload: dict) -> dict:
    """Normalize copytrade config payload types coming from the frontend."""
    if not isinstance(payload, dict):
        return {}

    normalized = dict(payload)

    api_id = normalized.get('telegram_api_id')
    if isinstance(api_id, str):
        api_id_str = api_id.strip()
        if api_id_str.isdigit():
            normalized['telegram_api_id'] = int(api_id_str)

    group_ids = normalized.get('monitor_group_ids')
    if isinstance(group_ids, str):
        parsed_ids = []
        for part in group_ids.split(','):
            part = part.strip()
            if not part:
                continue
            try:
                parsed_ids.append(int(part))
            except Exception:
                continue
        normalized['monitor_group_ids'] = parsed_ids

    return normalized


def extract_pyramiding_exit_levels(filepath: Path):
    """
    从配置文件中提取 PYRAMIDING_EXIT_LEVELS 列表.

    Returns:
        List[Tuple[float, float]]: [(profit_percent, close_ratio), ...]
    """
    if not filepath.exists():
        return []

    try:
        text = filepath.read_text(encoding="utf-8")
    except Exception:
        return []

    import re

    m = re.search(
        r"PYRAMIDING_EXIT_LEVELS\s*=\s*\[(.*?)\]\s*",
        text,
        flags=re.S,
    )
    if not m:
        return []

    block = m.group(1)
    levels = []
    for tup in re.finditer(
        r"\(\s*([0-9]*\.?[0-9]+)\s*,\s*([0-9]*\.?[0-9]+)\s*\)",
        block,
    ):
        try:
            profit = float(tup.group(1))
            ratio = float(tup.group(2))
            levels.append((profit, ratio))
        except Exception:
            continue

    return levels


def _fmt_num(x: float) -> str:
    s = f"{x:.6f}".rstrip("0").rstrip(".")
    return s if s else "0"


def extract_major_coin_pyramiding_exit_levels(filepath: Path):
    """
    从配置文件中提取 MAJOR_COIN_PYRAMIDING_EXIT_LEVELS 列表.

    Returns:
        List[Tuple[float, float]]: [(profit_percent, close_ratio), ...]
    """
    if not filepath.exists():
        return []

    try:
        text = filepath.read_text(encoding="utf-8")
    except Exception:
        return []

    import re

    m = re.search(
        r"MAJOR_COIN_PYRAMIDING_EXIT_LEVELS\s*=\s*\[(.*?)\]\s*",
        text,
        flags=re.S,
    )
    if not m:
        return []

    block = m.group(1)
    levels = []
    for tup in re.finditer(
        r"\(\s*([0-9]*\.?[0-9]+)\s*,\s*([0-9]*\.?[0-9]+)\s*\)",
        block,
    ):
        try:
            profit = float(tup.group(1))
            ratio = float(tup.group(2))
            levels.append((profit, ratio))
        except Exception:
            continue

    return levels


def apply_pyramiding_exit_levels(content: str, trader_data: dict) -> str:
    """
    用前端的做多金字塔止盈配置更新 PYRAMIDING_EXIT_LEVELS 块。

    优先读取 `pyramiding_exit_levels`（支持 percent+ratio），否则回退到
    `take_profit_1/2/3_percent`（使用默认 ratio 0.5/0.5/1.0）。
    """
    # 优先使用前端传来的 levels: [[percent, ratio], ...]
    levels = trader_data.get("pyramiding_exit_levels")
    parsed: list[tuple[float, float]] = []
    if isinstance(levels, list) and levels:
        for item in levels:
            if not (isinstance(item, (list, tuple)) and len(item) >= 2):
                continue
            pct, ratio = item[0], item[1]
            if not isinstance(pct, (int, float)) or not isinstance(ratio, (int, float)):
                continue
            pct_f = float(pct)
            ratio_f = float(ratio)
            if pct_f <= 0 or ratio_f <= 0:
                continue
            parsed.append((pct_f, ratio_f))

    # 回退：从止盈 1/2/3 百分比生成 levels
    if not parsed:
        tp_keys = ["take_profit_1_percent", "take_profit_2_percent", "take_profit_3_percent"]
        profits = []
        for k in tp_keys:
            v = trader_data.get(k)
            if isinstance(v, (int, float)):
                profits.append(float(v))
            else:
                return content

        if len(profits) != 3:
            return content

        parsed = [
            (profits[0], 0.5),
            (profits[1], 0.5),
            (profits[2], 1.0),
        ]

    new_block_lines = [
        "PYRAMIDING_EXIT_LEVELS = [",
    ]
    for pct, ratio in parsed:
        new_block_lines.append(f"    ({_fmt_num(pct)}, {_fmt_num(ratio)}),")
    new_block_lines += [
        "]",
    ]
    new_block = "\n".join(new_block_lines)

    import re
    pattern = r"^PYRAMIDING_EXIT_LEVELS\s*=\s*\[[\s\S]*?\]\s*"
    if re.search(pattern, content, flags=re.MULTILINE):
        return re.sub(pattern, new_block + "\n", content, count=1, flags=re.MULTILINE)

    # Backward compatible insertion for older configs/templates without this block.
    newline = "\r\n" if "\r\n" in content else "\n"
    anchor_pat = r"^PYRAMIDING_EXIT_EXECUTION\b.*$"
    m = re.search(anchor_pat, content, flags=re.MULTILINE)
    if m:
        insert_at = m.end()
        return content[:insert_at] + (newline * 2) + new_block + newline + content[insert_at:]
    return content.rstrip() + (newline * 2) + new_block + newline


def apply_short_pyramiding_exit_levels(content: str, trader_data: dict) -> str:
    """用前端的做空金字塔止盈配置更新 SHORT_PYRAMIDING_EXIT_LEVELS 块."""
    import re
    
    # 检查是否启用做空金字塔退出
    short_enable = trader_data.get('short_enable_pyramiding_exit', False)
    
    # 更新 SHORT_ENABLE_PYRAMIDING_EXIT
    enable_pattern = r"^SHORT_ENABLE_PYRAMIDING_EXIT\s*=\s*\w+"
    enable_value = "True" if short_enable else "False"
    if re.search(enable_pattern, content, flags=re.MULTILINE):
        content = re.sub(enable_pattern, f"SHORT_ENABLE_PYRAMIDING_EXIT = {enable_value}", content, count=1, flags=re.MULTILINE)
    
    # 获取做空金字塔退出级别
    levels = trader_data.get('short_pyramiding_exit_levels', [])
    if not levels or len(levels) < 3:
        return content
    
    # 构建新的配置块
    new_block_lines = [
        "SHORT_PYRAMIDING_EXIT_LEVELS = [",
    ]
    for i, level in enumerate(levels[:3]):
        if isinstance(level, (list, tuple)) and len(level) >= 2:
            pct, ratio = level[0], level[1]
            new_block_lines.append(f"    ({_fmt_num(pct)}, {_fmt_num(ratio)}),")
    new_block_lines.append("]")
    new_block = "\n".join(new_block_lines)
    
    pattern = r"^SHORT_PYRAMIDING_EXIT_LEVELS\s*=\s*\[[\s\S]*?\]\s*"
    if re.search(pattern, content, flags=re.MULTILINE):
        return re.sub(pattern, new_block + "\n", content, count=1, flags=re.MULTILINE)
    
    # 如果配置块不存在，在 SHORT_ENABLE_PYRAMIDING_EXIT 后插入
    newline = "\r\n" if "\r\n" in content else "\n"
    anchor_pat = r"^SHORT_ENABLE_PYRAMIDING_EXIT\b.*$"
    m = re.search(anchor_pat, content, flags=re.MULTILINE)
    if m:
        insert_at = m.end()
        return content[:insert_at] + (newline * 2) + new_block + newline + content[insert_at:]
    
    return content


def apply_major_coin_pyramiding_exit_levels(content: str, trader_data: dict) -> str:
    """用前端的主流币金字塔止盈配置更新 MAJOR_COIN_PYRAMIDING_EXIT_LEVELS 块."""
    import re
    
    # 获取主流币金字塔退出级别
    levels = trader_data.get('major_coin_pyramiding_exit_levels', [])
    if not levels or len(levels) < 3:
        return content
    
    # 构建新的配置块
    new_block_lines = [
        "MAJOR_COIN_PYRAMIDING_EXIT_LEVELS = [",
    ]
    for i, level in enumerate(levels[:3]):
        if isinstance(level, (list, tuple)) and len(level) >= 2:
            pct, ratio = level[0], level[1]
            new_block_lines.append(f"    ({_fmt_num(pct)}, {_fmt_num(ratio)}),")
    new_block_lines.append("]")
    new_block = "\n".join(new_block_lines)
    
    pattern = r"^MAJOR_COIN_PYRAMIDING_EXIT_LEVELS\s*=\s*\[[\s\S]*?\]\s*"
    if re.search(pattern, content, flags=re.MULTILINE):
        return re.sub(pattern, new_block + "\n", content, count=1, flags=re.MULTILINE)
    
    # 如果配置块不存在，在 MAJOR_COIN_STOP_LOSS_PERCENT 后插入
    newline = "\r\n" if "\r\n" in content else "\n"
    anchor_pat = r"^MAJOR_COIN_STOP_LOSS_PERCENT\b.*$"
    m = re.search(anchor_pat, content, flags=re.MULTILINE)
    if m:
        insert_at = m.end()
        return content[:insert_at] + (newline * 2) + new_block + newline + content[insert_at:]
    
    return content


def _py_inline_literal(value) -> str:
    """Render a small subset of Python literals for config assignments."""
    if value is None:
        return "None"
    if isinstance(value, bool):
        return "True" if value else "False"
    if isinstance(value, (int, float)):
        return str(value)
    if isinstance(value, str):
        return json.dumps(value, ensure_ascii=False)
    if isinstance(value, (list, tuple)):
        inner = ", ".join(_py_inline_literal(v) for v in value)
        return f"[{inner}]"
    return json.dumps(str(value), ensure_ascii=False)


def ensure_major_coin_strategy_fields(content: str, trader_data: dict) -> str:
    """
    Back-compat: ensure major-coin strategy fields exist even when using an older
    config template that doesn't contain these assignments.
    """
    if not isinstance(trader_data, dict):
        return content

    mapping = {
        "major_coins": "MAJOR_COINS",
        "enable_major_coin_strategy": "ENABLE_MAJOR_COIN_STRATEGY",
        "major_coin_leverage": "MAJOR_COIN_LEVERAGE",
        "major_coin_max_position_percent": "MAJOR_COIN_MAX_POSITION_PERCENT",
        "major_coin_stop_loss_percent": "MAJOR_COIN_STOP_LOSS_PERCENT",
        "major_coin_enable_trailing_stop": "MAJOR_COIN_ENABLE_TRAILING_STOP",
        "major_coin_trailing_stop_activation": "MAJOR_COIN_TRAILING_STOP_ACTIVATION",
        "major_coin_trailing_stop_callback": "MAJOR_COIN_TRAILING_STOP_CALLBACK",
    }

    defaults = {
        "major_coins": ["BTC", "ETH", "BNB", "SOL", "XRP"],
        "enable_major_coin_strategy": False,
        "major_coin_leverage": None,
        "major_coin_max_position_percent": None,
        "major_coin_stop_loss_percent": 1.5,
        "major_coin_enable_trailing_stop": True,
        "major_coin_trailing_stop_activation": 1.0,
        "major_coin_trailing_stop_callback": 0.8,
    }

    import re

    to_add = []
    for payload_key, config_key in mapping.items():
        if re.search(rf"^{config_key}\b\s*=", content, flags=re.MULTILINE):
            continue
        value = trader_data.get(payload_key, defaults.get(payload_key))
        to_add.append(f"{config_key} = {_py_inline_literal(value)}")

    if not to_add:
        return content

    block = "\n".join(
        ["", "", "# ============ 主流币独立策略配置 (auto-added) ============"] + to_add + [""]
    )
    return content.rstrip() + block


def ensure_signal_chart_fields(content: str, signal_data: dict) -> str:
    """
    Back-compat: ensure signal chart fields exist even when using an older
    config template that doesn't contain these assignments.
    """
    if not isinstance(signal_data, dict):
        return content

    mapping = {
        "enable_pro_chart": "ENABLE_PRO_CHART",
        "enable_tradingview_chart": "ENABLE_TRADINGVIEW_CHART",
        "auto_delete_charts": "AUTO_DELETE_CHARTS",
        "chart_img_api_key": "CHART_IMG_API_KEY",
        "chart_img_layout_id": "CHART_IMG_LAYOUT_ID",
        "chart_img_width": "CHART_IMG_WIDTH",
        "chart_img_height": "CHART_IMG_HEIGHT",
        "chart_img_timeout": "CHART_IMG_TIMEOUT",
        "language": "LANGUAGE",
        "enable_ai_key_levels": "ENABLE_AI_KEY_LEVELS",
        "enable_ai_overlays": "ENABLE_AI_OVERLAYS",
        "enable_ai_signal_analysis": "ENABLE_AI_SIGNAL_ANALYSIS",
        "ai_brief_wait_timeout_seconds": "AI_BRIEF_WAIT_TIMEOUT_SECONDS",
        "bull_bear_signal_ttl_seconds": "BULL_BEAR_SIGNAL_TTL_SECONDS",
        "valuescan_key_levels_days": "VALUESCAN_KEY_LEVELS_DAYS",
        "valuescan_ai_analysis_days": "VALUESCAN_AI_ANALYSIS_DAYS",
    }

    defaults = {
        "enable_pro_chart": True,
        "enable_tradingview_chart": True,
        "auto_delete_charts": True,
        "chart_img_api_key": "",
        "chart_img_layout_id": "",
        "chart_img_width": 800,
        "chart_img_height": 600,
        "chart_img_timeout": 90,
        "language": "zh",
        "enable_ai_key_levels": False,
        "enable_ai_overlays": False,
        "enable_ai_signal_analysis": True,
        "ai_brief_wait_timeout_seconds": 90,
        "bull_bear_signal_ttl_seconds": 86400,
        "valuescan_key_levels_days": 7,
        "valuescan_ai_analysis_days": 15,
    }

    import re

    to_add = []
    for payload_key, config_key in mapping.items():
        if re.search(rf"^{config_key}\b\s*=", content, flags=re.MULTILINE):
            continue
        value = signal_data.get(payload_key, defaults.get(payload_key))
        to_add.append(f"{config_key} = {_py_inline_literal(value)}")

    if not to_add:
        return content

    block = "\n".join(
        ["", "", "# ============ Signal chart settings (auto-added) ============"] + to_add + [""]
    )
    return content.rstrip() + block


def ensure_payload_fields(
    content: str,
    payload: dict,
    *,
    skip_keys: set[str],
    header: str,
) -> str:
    """
    Back-compat: append payload keys that are missing from the config template.
    Only simple scalar/list values are appended to avoid breaking complex formats.
    """
    if not isinstance(payload, dict):
        return content

    import re

    to_add = []
    for key, value in payload.items():
        if key in skip_keys:
            continue
        if isinstance(value, dict):
            continue
        if isinstance(value, (list, tuple)) and any(
            isinstance(item, (list, tuple, dict)) for item in value
        ):
            continue
        config_key = str(key).upper()
        if re.search(rf"^{re.escape(config_key)}\b\s*=", content, flags=re.MULTILINE):
            continue
        to_add.append(f"{config_key} = {_py_inline_literal(value)}")

    if not to_add:
        return content

    block = "\n".join(["", "", f"# ============ {header} (auto-added) ============"] + to_add + [""])
    return content.rstrip() + block


def ensure_signal_chart_defaults(signal: dict) -> dict:
    if not isinstance(signal, dict):
        return signal

    defaults = {
        "enable_pro_chart": True,
        "enable_tradingview_chart": True,
        "auto_delete_charts": True,
        "chart_img_api_key": "",
        "chart_img_layout_id": "",
        "chart_img_width": 800,
        "chart_img_height": 600,
        "chart_img_timeout": 90,
        "language": "zh",
        "enable_ai_key_levels": False,
        "enable_ai_overlays": False,
        "enable_ai_signal_analysis": True,
        "ai_brief_wait_timeout_seconds": 90,
        "bull_bear_signal_ttl_seconds": 86400,
        "valuescan_key_levels_days": 7,
        "valuescan_ai_analysis_days": 15,
    }

    for key, value in defaults.items():
        if key not in signal or signal[key] is None:
            signal[key] = value

    return signal


def _check_process_running(process_keywords: list) -> bool:
    """Check if a process is running by searching for keywords in command line."""
    try:
        import psutil
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = proc.info.get('cmdline') or []
                cmdline_str = ' '.join(cmdline).lower()
                for keyword in process_keywords:
                    if keyword.lower() in cmdline_str:
                        return True
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
    except ImportError:
        pass
    return False


def get_service_status(service_name: str) -> str:
    """获取服务状态，支持 systemd 和进程检测回退"""
    aliases = {
        # Backward/forward compatibility across deployments
        'valuescan-signal': ['valuescan-signal', 'valuescan-monitor'],
        'valuescan-monitor': ['valuescan-monitor', 'valuescan-signal'],
        'valuescan-trader': ['valuescan-trader'],
        'valuescan-api': ['valuescan-api'],
        'valuescan-keepalive': ['valuescan-keepalive'],
        'valuescan-copytrade': ['valuescan-copytrade', 'valuescan-copytrade.service'],
    }
    
    # Process keywords for fallback detection
    process_keywords_map = {
        'valuescan-signal': ['signal_monitor', 'api_monitor', 'polling_monitor', 'valuescan.py'],
        'valuescan-monitor': ['signal_monitor', 'api_monitor', 'polling_monitor', 'valuescan.py'],
        'valuescan-trader': ['futures_main', 'futures_trader', 'binance_trader'],
        'valuescan-api': ['server.py', 'gunicorn', 'flask'],
        'valuescan-keepalive': ['keepalive_main', 'keepalive/service'],
        'valuescan-copytrade': ['copytrade_main', 'telegram_copytrade'],
    }
    
    candidates = aliases.get(service_name, [service_name])
    
    # Try systemctl first (Linux with systemd)
    try:
        for cand in candidates:
            result = subprocess.run(
                ['systemctl', 'is-active', cand],
                capture_output=True, text=True, timeout=5
            )
            status = (result.stdout or '').strip()
            if status in ('', 'unknown'):
                continue
            if status == 'active':
                return 'running'
            if status == 'failed':
                return 'error'
            return 'stopped'
    except (FileNotFoundError, subprocess.TimeoutExpired, OSError):
        # systemctl not available (Windows or no systemd)
        pass
    except Exception:
        pass
    
    # Fallback: check if process is running by keywords
    keywords = process_keywords_map.get(service_name, [service_name])
    if _check_process_running(keywords):
        return 'running'
    
    return 'stopped'

def control_service(service_name: str, action: str) -> bool:
    """控制 systemd 服务"""
    try:
        aliases = {
            'valuescan-signal': ['valuescan-signal', 'valuescan-monitor'],
            'valuescan-monitor': ['valuescan-monitor', 'valuescan-signal'],
            'valuescan-trader': ['valuescan-trader'],
            'valuescan-api': ['valuescan-api'],
            'valuescan-keepalive': ['valuescan-keepalive'],
            'valuescan-copytrade': ['valuescan-copytrade', 'valuescan-copytrade.service'],
        }
        candidates = aliases.get(service_name, [service_name])
        for cand in candidates:
            try:
                subprocess.run(
                    ['systemctl', action, cand],
                    check=True, timeout=30
                )
                return True
            except Exception:
                continue
        return False
    except Exception:
        return False

@app.route('/')
def index():
    api_origin = (os.environ.get("VALUESCAN_API_ORIGIN") or "").strip()
    if not api_origin:
        return send_from_directory(app.static_folder, 'index.html')

    index_path = Path(app.static_folder) / "index.html"
    try:
        html = index_path.read_text(encoding="utf-8", errors="ignore")
    except Exception:
        return send_from_directory(app.static_folder, 'index.html')

    snippet = (
        "<script>"
        f"window.__VALUESCAN_API_ORIGIN__ = {json.dumps(api_origin)};"
        "</script>"
    )
    if "</head>" in html:
        html = html.replace("</head>", snippet + "</head>", 1)
    else:
        html = snippet + html

    return Response(html, mimetype="text/html")


@app.route('/api/config', methods=['GET'])
def get_config():
    """获取配置"""
    # Merge current config with template defaults so the UI can always display all keys.
    signal_defaults = parse_config(SIGNAL_TEMPLATE)
    trader_defaults = parse_config(TRADER_TEMPLATE)
    copytrade_defaults = parse_config(COPYTRADE_TEMPLATE)

    signal_current = parse_config(SIGNAL_CONFIG)
    trader_current = parse_config(TRADER_CONFIG)
    copytrade_current = parse_config(COPYTRADE_CONFIG)

    signal = {**signal_defaults, **signal_current}
    signal = ensure_signal_chart_defaults(signal)
    trader = {**trader_defaults, **trader_current}
    copytrade = {**copytrade_defaults, **copytrade_current}
    
    # Merge AI summary config into signal config
    try:
        ai_defaults = _default_ai_summary_config()
        ai_current = {}
        if AI_SUMMARY_CONFIG_FILE.exists():
            ai_current = json.loads(AI_SUMMARY_CONFIG_FILE.read_text(encoding='utf-8'))
        if isinstance(ai_current, dict):
            ai_cfg = {**ai_defaults, **ai_current}
            signal['ai_summary_enabled'] = ai_cfg.get('enabled', False)
            signal['ai_summary_api_key'] = ai_cfg.get('api_key', '')
            signal['ai_summary_api_url'] = ai_cfg.get('api_url', 'https://api.openai.com/v1/chat/completions')
            signal['ai_summary_model'] = ai_cfg.get('model', 'gpt-4o-mini')
            signal['ai_summary_interval_hours'] = ai_cfg.get('interval_hours', 1)
            signal['ai_summary_lookback_hours'] = ai_cfg.get('lookback_hours', 1)
    except Exception as e:
        print(f"[API] Failed to merge AI summary config: {e}")

    # Normalize major coins list so both "BTC" and "BTCUSDT" inputs can work.
    try:
        major_coins = trader.get("major_coins")
        if isinstance(major_coins, list):
            normalized = []
            for item in major_coins:
                if not isinstance(item, str):
                    continue
                base = _normalize_coin_base_symbol(item)
                if base:
                    normalized.append(base)
            trader["major_coins"] = sorted(set(normalized))
    except Exception:
        pass

    # Back-compat/UI: the frontend uses "position_side" (BOTH/LONG/SHORT) dropdown,
    # while the trader uses USE_HEDGE_MODE for hedge vs one-way mode.
    try:
        use_hedge_mode = trader.get("use_hedge_mode")
        if isinstance(use_hedge_mode, bool) and use_hedge_mode:
            trader["position_side"] = "BOTH"
    except Exception:
        pass

    # 若启用金字塔分批止盈，则用 PYRAMIDING_EXIT_LEVELS 的百分比覆盖前端展示
    try:
        levels = extract_pyramiding_exit_levels(TRADER_CONFIG)
        if levels:
            trader["pyramiding_exit_levels"] = levels
            if trader.get("enable_pyramiding_exit"):
                tp_keys = [
                    "take_profit_1_percent",
                    "take_profit_2_percent",
                    "take_profit_3_percent",
                ]
                for idx, key in enumerate(tp_keys):
                    if idx < len(levels):
                        trader[key] = levels[idx][0]
    except Exception:
        pass
    
    # 提取主流币金字塔止盈配置
    try:
        major_levels = extract_major_coin_pyramiding_exit_levels(TRADER_CONFIG)
        if major_levels:
            trader["major_coin_pyramiding_exit_levels"] = major_levels
    except Exception:
        pass
    return jsonify({
        # Frontend expects these keys from GET /api/config (extra keys are ignored).
        'beta_mode': False,
        'registration_enabled': True,
        'signal': signal,
        'trader': trader,
        'copytrade': copytrade,
    })

@app.route('/api/config', methods=['POST'])
def save_config():
    """保存配置"""
    data = request.json
    print(f"[API] Saving config: {list(data.keys())}")

    saved = {'signal': False, 'trader': False, 'copytrade': False}
    errors = []
    validation_errors = {}
    restart_results = {}
    restart_errors = []

    # Validate all configs before saving
    if 'signal' in data:
        is_valid, val_errors = validate_config('signal', data['signal'])
        if not is_valid:
            validation_errors['signal'] = val_errors
            errors.extend([f"Signal validation: {e}" for e in val_errors])

    if 'trader' in data:
        is_valid, val_errors = validate_config('trader', data['trader'])
        if not is_valid:
            validation_errors['trader'] = val_errors
            errors.extend([f"Trader validation: {e}" for e in val_errors])

    if 'copytrade' in data:
        is_valid, val_errors = validate_config('copytrade', data['copytrade'])
        if not is_valid:
            validation_errors['copytrade'] = val_errors
            errors.extend([f"Copytrade validation: {e}" for e in val_errors])

    # If validation failed, return errors immediately
    if validation_errors:
        return jsonify({
            'success': False,
            'saved': saved,
            'errors': errors,
            'validation_errors': validation_errors,
            'restart_results': restart_results,
            'restart_errors': restart_errors
        }), 400

    if 'signal' in data:
        signal_data = data['signal']
        signal_template = BASE_DIR / 'signal_monitor' / 'config.example.py'
        content = generate_config(signal_data, signal_template)
        if content:
            try:
                content = ensure_signal_chart_fields(content, signal_data)
                content = ensure_payload_fields(
                    content,
                    signal_data,
                    skip_keys={
                        "ai_signal_config",
                        "ai_levels_config",
                        "ai_overlays_config",
                        "ai_market_config",
                    },
                    header="Signal config extras",
                )
                with open(SIGNAL_CONFIG, 'w', encoding='utf-8') as f:
                    f.write(content)
                saved['signal'] = True
                print(f"[API] Signal config saved successfully")
            except Exception as e:
                errors.append(f"Signal config error: {e}")
                print(f"[API] Signal config error: {e}")
        else:
            errors.append("Signal config template not found")
        
        # Also save AI summary config if present in signal data
        try:
            ai_keys = ['ai_summary_enabled', 'ai_summary_api_key', 'ai_summary_api_url', 
                       'ai_summary_model', 'ai_summary_interval_hours', 'ai_summary_lookback_hours']
            if any(k in signal_data for k in ai_keys):
                ai_defaults = _default_ai_summary_config()
                ai_cfg = {
                    'enabled': signal_data.get('ai_summary_enabled', ai_defaults['enabled']),
                    'api_key': signal_data.get('ai_summary_api_key', ai_defaults['api_key']),
                    'api_url': signal_data.get('ai_summary_api_url', ai_defaults['api_url']),
                    'model': signal_data.get('ai_summary_model', ai_defaults['model']),
                    'interval_hours': signal_data.get('ai_summary_interval_hours', ai_defaults['interval_hours']),
                    'lookback_hours': signal_data.get('ai_summary_lookback_hours', ai_defaults['lookback_hours']),
                }
                AI_SUMMARY_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
                AI_SUMMARY_CONFIG_FILE.write_text(json.dumps(ai_cfg, ensure_ascii=False, indent=2), encoding='utf-8')
                print(f"[API] AI summary config saved: enabled={ai_cfg['enabled']}")
        except Exception as e:
            print(f"[API] Failed to save AI summary config: {e}")
    
    if 'trader' in data:
        trader_template = BASE_DIR / 'binance_trader' / 'config.example.py'
        trader_payload = dict(data.get('trader') or {})

        # Map UI "position_side" dropdown to trader's USE_HEDGE_MODE.
        # - BOTH  -> hedge mode
        # - LONG/SHORT -> one-way mode (direction is still controlled by long/short toggles)
        try:
            pos = trader_payload.get("position_side")
            if isinstance(pos, str):
                pos = pos.strip().upper()
                if pos in ("BOTH", "LONG", "SHORT"):
                    trader_payload["use_hedge_mode"] = (pos == "BOTH")
        except Exception:
            pass

        try:
            major_coins = trader_payload.get("major_coins")
            if isinstance(major_coins, list):
                normalized = []
                for item in major_coins:
                    if not isinstance(item, str):
                        continue
                    base = _normalize_coin_base_symbol(item)
                    if base:
                        normalized.append(base)
                trader_payload["major_coins"] = sorted(set(normalized))
        except Exception:
            pass

        content = generate_config(trader_payload, trader_template)
        if content:
            try:
                content = apply_pyramiding_exit_levels(content, trader_payload)
                content = apply_short_pyramiding_exit_levels(content, trader_payload)
                content = apply_major_coin_pyramiding_exit_levels(content, trader_payload)
                content = ensure_major_coin_strategy_fields(content, trader_payload)
                content = ensure_payload_fields(
                    content,
                    trader_payload,
                    skip_keys=set(),
                    header="Trader config extras",
                )
                with open(TRADER_CONFIG, 'w', encoding='utf-8') as f:
                    f.write(content)
                saved['trader'] = True
                print(f"[API] Trader config saved successfully")
            except Exception as e:
                errors.append(f"Trader config error: {e}")
                print(f"[API] Trader config error: {e}")
        else:
            errors.append("Trader config template not found")
    
    if 'copytrade' in data:
        copytrade_template = BASE_DIR / 'telegram_copytrade' / 'config.example.py'
        copytrade_payload = normalize_copytrade_config(data.get('copytrade') or {})
        content = generate_config(copytrade_payload, copytrade_template)
        if content:
            try:
                content = ensure_payload_fields(
                    content,
                    copytrade_payload,
                    skip_keys=set(),
                    header="CopyTrade config extras",
                )
                with open(COPYTRADE_CONFIG, 'w', encoding='utf-8') as f:
                    f.write(content)
                saved['copytrade'] = True
                print(f"[API] CopyTrade config saved successfully")
            except Exception as e:
                errors.append(f"CopyTrade config error: {e}")
                print(f"[API] CopyTrade config error: {e}")
        else:
            errors.append("CopyTrade config template not found")

    # Try to restart services so config changes take effect immediately.
    try:
        import shutil

        if shutil.which('systemctl'):
            service_targets = []
            if saved['signal']:
                service_targets.append(('signal', 'valuescan-signal'))
            if saved['trader']:
                trader_auto_enabled = None
                try:
                    trader_auto_enabled = data.get('trader', {}).get('auto_trading_enabled')
                except Exception:
                    trader_auto_enabled = None
                if trader_auto_enabled is None:
                    try:
                        trader_auto_enabled = parse_config(TRADER_CONFIG).get('auto_trading_enabled')
                    except Exception:
                        trader_auto_enabled = None
                if trader_auto_enabled is not False:
                    service_targets.append(('trader', 'valuescan-trader'))
            if saved['copytrade']:
                service_targets.append(('copytrade', 'valuescan-copytrade'))

            for key, unit in service_targets:
                ok = control_service(unit, 'restart')
                restart_results[key] = ok
                if not ok:
                    restart_errors.append(f"Failed to restart {unit}")
    except Exception as e:
        restart_errors.append(str(e))

    # Return saved config for verification
    result = {
        'success': len(errors) == 0,
        'saved': saved,
        'errors': errors,
        'restarted': restart_results,
        'restart_errors': restart_errors,
    }
    
    # Include the saved config for frontend verification
    if result['success']:
        result['config'] = {
            'signal': parse_config(SIGNAL_CONFIG) if saved['signal'] else None,
            'trader': parse_config(TRADER_CONFIG) if saved['trader'] else None,
            'copytrade': parse_config(COPYTRADE_CONFIG) if saved['copytrade'] else None
        }
    
    print(f"[API] Save result: success={result['success']}, saved={saved}")
    return jsonify(result)

@app.route('/api/valuescan/status', methods=['GET'])
def get_valuescan_status():
    """获取服务状态"""
    return jsonify({
        'signal_monitor': get_service_status('valuescan-signal'),
        'trader': get_service_status('valuescan-trader'),
        'copytrade': get_service_status('valuescan-copytrade'),
        'keepalive': get_service_status('valuescan-keepalive')
    })

@app.route('/api/service/<service>/<action>', methods=['POST'])
def service_control(service: str, action: str):
    """控制服务"""
    service_map = {
        'signal': 'valuescan-signal',
        'trader': 'valuescan-trader',
        'copytrade': 'valuescan-copytrade',
        'keepalive': 'valuescan-keepalive'
    }
    
    if service not in service_map:
        return jsonify({'error': 'Invalid service'}), 400
    
    if action not in ['start', 'stop', 'restart']:
        return jsonify({'error': 'Invalid action'}), 400
    
    success = control_service(service_map[service], action)
    return jsonify({'success': success})

@app.route('/api/valuescan/login/status', methods=['GET'])
def valuescan_login_status():
    """检查 valuescan 登录状态"""
    cookies_count = 0
    token_present = False

    cookies_file = VALUESCAN_COOKIES_FILE
    if cookies_file and Path(cookies_file).exists():
        try:
            payload = json.loads(Path(cookies_file).read_text(encoding='utf-8'))
            cookies = payload.get('cookies') if isinstance(payload, dict) else payload
            if isinstance(cookies, list):
                cookies_count = len(cookies)
        except Exception:
            cookies_count = 0

    token_file = VALUESCAN_TOKEN_FILE
    if token_file and Path(token_file).exists():
        try:
            payload = json.loads(Path(token_file).read_text(encoding='utf-8'))
            if isinstance(payload, dict):
                account_token = (payload.get('account_token') or '').strip()
                refresh_token = (payload.get('refresh_token') or '').strip()
                token_present = bool(account_token or refresh_token)
        except Exception:
            token_present = False

    logged_in = cookies_count > 0 or token_present
    return jsonify({'logged_in': logged_in, 'cookies_count': cookies_count, 'token_present': token_present})


@app.route('/api/valuescan/artifacts', methods=['GET'])
def valuescan_get_artifacts():
    """Read ValueScan login artifacts (cookies/localStorage/sessionStorage) from local JSON files."""
    cookies = _read_json_file(VALUESCAN_COOKIES_FILE, default=[])
    localstorage = _read_json_file(VALUESCAN_TOKEN_FILE, default={})
    sessionstorage = _read_json_file(VALUESCAN_SESSION_FILE, default={})

    cookie_list = (
        cookies
        if isinstance(cookies, list)
        else (cookies.get("cookies") if isinstance(cookies, dict) else [])
    )
    cookie_count = len(cookie_list) if isinstance(cookie_list, list) else 0

    return jsonify(
        {
            "paths": {
                "cookies_file": str(VALUESCAN_COOKIES_FILE),
                "localstorage_file": str(VALUESCAN_TOKEN_FILE),
                "sessionstorage_file": str(VALUESCAN_SESSION_FILE),
            },
            "cookies": cookies,
            "localstorage": localstorage,
            "sessionstorage": sessionstorage,
            "cookies_count": cookie_count,
            "has_account_token": bool(
                isinstance(localstorage, dict)
                and (localstorage.get("account_token") or "").strip()
            ),
            "has_refresh_token": bool(
                isinstance(localstorage, dict)
                and (localstorage.get("refresh_token") or "").strip()
            ),
        }
    )


@app.route('/api/valuescan/artifacts', methods=['POST'])
def valuescan_save_artifacts():
    """Save ValueScan login artifacts (cookies/localStorage/sessionStorage) to local JSON files."""
    payload = request.json or {}
    if not isinstance(payload, dict):
        return jsonify({"success": False, "error": "Invalid payload"}), 400

    errors = []
    saved = {}

    def _maybe_remove(path: Path):
        try:
            if path.exists():
                path.unlink()
        except Exception:
            pass

    if "cookies" in payload:
        cookies = payload.get("cookies")
        try:
            if cookies is None:
                _maybe_remove(VALUESCAN_COOKIES_FILE)
                saved["cookies"] = False
            elif isinstance(cookies, (list, dict)):
                _write_json_file(VALUESCAN_COOKIES_FILE, cookies)
                saved["cookies"] = True
            else:
                raise ValueError("cookies must be a list/object JSON")
        except Exception as exc:
            errors.append(f"cookies: {exc}")

    if "localstorage" in payload:
        localstorage = payload.get("localstorage")
        try:
            if localstorage is None:
                _maybe_remove(VALUESCAN_TOKEN_FILE)
                saved["localstorage"] = False
            elif isinstance(localstorage, dict):
                _write_json_file(VALUESCAN_TOKEN_FILE, localstorage)
                saved["localstorage"] = True
            else:
                raise ValueError("localstorage must be a JSON object")
        except Exception as exc:
            errors.append(f"localstorage: {exc}")

    if "sessionstorage" in payload:
        sessionstorage = payload.get("sessionstorage")
        try:
            if sessionstorage is None:
                _maybe_remove(VALUESCAN_SESSION_FILE)
                saved["sessionstorage"] = False
            elif isinstance(sessionstorage, dict):
                _write_json_file(VALUESCAN_SESSION_FILE, sessionstorage)
                saved["sessionstorage"] = True
            else:
                raise ValueError("sessionstorage must be a JSON object")
        except Exception as exc:
            errors.append(f"sessionstorage: {exc}")

    ok = len(errors) == 0
    return jsonify({"success": ok, "saved": saved, "errors": errors})


class _ValuescanProxyError(RuntimeError):
    pass


class _ValuescanAuthError(RuntimeError):
    pass


def _valuescan_load_localstorage() -> Dict[str, Any]:
    localstorage = _read_json_file(VALUESCAN_TOKEN_FILE, default={})
    return localstorage if isinstance(localstorage, dict) else {}


def _valuescan_load_sessionstorage() -> Dict[str, Any]:
    sessionstorage = _read_json_file(VALUESCAN_SESSION_FILE, default={})
    return sessionstorage if isinstance(sessionstorage, dict) else {}


def _valuescan_pick_token(store: Dict[str, Any], keys: List[str]) -> str:
    for key in keys:
        value = store.get(key)
        if isinstance(value, str) and value.strip():
            return value.strip()
    return ""


def _valuescan_get_tokens() -> Tuple[str, str, Dict[str, Any], Dict[str, Any]]:
    localstorage = _valuescan_load_localstorage()
    account_token = _valuescan_pick_token(
        localstorage,
        ["account_token", "accountToken", "access_token", "accessToken", "token"],
    )
    refresh_token = _valuescan_pick_token(
        localstorage,
        ["refresh_token", "refreshToken", "refresh"],
    )

    sessionstorage = {}
    if not account_token or not refresh_token:
        sessionstorage = _valuescan_load_sessionstorage()
        if not account_token:
            account_token = _valuescan_pick_token(
                sessionstorage,
                ["account_token", "accountToken", "access_token", "accessToken", "token"],
            )
        if not refresh_token:
            refresh_token = _valuescan_pick_token(
                sessionstorage,
                ["refresh_token", "refreshToken", "refresh"],
            )
    return account_token, refresh_token, localstorage, sessionstorage


def _valuescan_access_ticket(localstorage: Dict[str, Any], sessionstorage: Dict[str, Any]) -> str:
    keys = ["access_ticket", "accessTicket", "access-ticket", "accessTicketValue"]
    ticket = _valuescan_pick_token(localstorage, keys)
    if ticket:
        return ticket
    ticket = _valuescan_pick_token(sessionstorage, keys)
    if ticket:
        return ticket
    env_ticket = (os.getenv("VALUESCAN_ACCESS_TICKET") or "").strip()
    if env_ticket:
        return env_ticket
    return VALUESCAN_ACCESS_TICKET_FALLBACK


def _valuescan_decode_jwt_exp(token: str) -> Optional[datetime]:
    parts = (token or "").split(".")
    if len(parts) < 2:
        return None
    payload_b64 = parts[1]
    padding = "=" * (-len(payload_b64) % 4)
    try:
        payload_json = base64.urlsafe_b64decode((payload_b64 + padding).encode("utf-8")).decode("utf-8")
        payload = json.loads(payload_json)
    except Exception:
        return None
    exp = payload.get("exp")
    if not isinstance(exp, (int, float)):
        return None
    if exp > 1e12:
        exp = exp / 1000
    return datetime.fromtimestamp(exp, tz=timezone.utc)


def _valuescan_extract_tokens_from_payload(payload: Any) -> Dict[str, str]:
    if not isinstance(payload, dict):
        return {}

    token_keys = ["account_token", "token", "access_token", "accessToken", "jwt"]
    refresh_keys = ["refresh_token", "refreshToken", "refresh"]

    def _pick(dct: Dict[str, Any], keys: List[str]) -> str:
        for key in keys:
            val = dct.get(key)
            if isinstance(val, str) and val.strip():
                return val.strip()
        return ""

    def _scan(obj: Any, depth: int) -> Dict[str, str]:
        if depth <= 0:
            return {}
        if isinstance(obj, dict):
            account_token = _pick(obj, token_keys)
            refresh_token = _pick(obj, refresh_keys)
            if account_token or refresh_token:
                return {"account_token": account_token, "refresh_token": refresh_token}
            for value in obj.values():
                found = _scan(value, depth - 1)
                if found:
                    return found
        elif isinstance(obj, list):
            for value in obj:
                found = _scan(value, depth - 1)
                if found:
                    return found
        return {}

    return _scan(payload, depth=4)


def _valuescan_build_headers(
    account_token: str,
    localstorage: Dict[str, Any],
    sessionstorage: Dict[str, Any],
) -> Dict[str, str]:
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Origin": "https://www.valuescan.io",
        "Referer": "https://www.valuescan.io/",
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ),
    }
    if account_token:
        headers["Authorization"] = f"Bearer {account_token}"
    access_ticket = _valuescan_access_ticket(localstorage, sessionstorage)
    if access_ticket:
        headers["Access-Ticket"] = access_ticket
    return headers


def _valuescan_response_expired(resp) -> bool:
    if resp.status_code in (401, 403):
        return True
    try:
        payload = resp.json()
    except ValueError:
        return False
    if not isinstance(payload, dict):
        return False
    code = payload.get("code")
    return code in (4000, 4002, 401, 403)


def _valuescan_api_base_candidates() -> list[str]:
    bases: list[str] = []
    env_bases = (os.getenv("VALUESCAN_API_BASES") or "").strip()
    if env_bases:
        for item in env_bases.split(","):
            base = item.strip().rstrip("/")
            if base:
                bases.append(base)

    if VALUESCAN_API_BASE:
        bases.append(VALUESCAN_API_BASE.rstrip("/"))

    for base in _VALUESCAN_DEFAULT_BASES:
        clean = base.rstrip("/")
        bases.append(clean)

    seen = set()
    unique: list[str] = []
    for base in bases:
        if base in seen:
            continue
        seen.add(base)
        unique.append(base)
    return unique


def _valuescan_normalize_url(path: str, base: Optional[str] = None) -> str:
    if not path:
        raise _ValuescanProxyError("Missing ValueScan API path")
    if path.startswith("http://") or path.startswith("https://"):
        return path
    if not path.startswith("/"):
        path = f"/{path}"
    base = (base or VALUESCAN_API_BASE).rstrip("/")
    return f"{base}{path}"


def _valuescan_send_request(
    method: str,
    path: str,
    params: Optional[Dict[str, Any]] = None,
    json_body: Optional[dict] = None,
    allow_anonymous: bool = False,
):
    import requests

    account_token, _refresh_token, localstorage, sessionstorage = _valuescan_get_tokens()
    if not account_token and not allow_anonymous:
        raise _ValuescanAuthError("ValueScan token missing. Please login first.")

    headers = _valuescan_build_headers(account_token, localstorage, sessionstorage)

    session = requests.Session()
    session.trust_env = False
    proxies = _get_requests_proxies_from_config()

    is_full_url = path.startswith("http://") or path.startswith("https://")
    bases = [None] if is_full_url else _valuescan_api_base_candidates()
    last_exc: Optional[Exception] = None
    for idx, base in enumerate(bases):
        url = _valuescan_normalize_url(path, base)
        try:
            resp = session.request(
                method,
                url,
                headers=headers,
                params=params,
                json=json_body,
                timeout=VALUESCAN_API_TIMEOUT,
                proxies=proxies,
                verify=True,
            )
        except requests.exceptions.SSLError as exc:
            last_exc = exc
            try:
                resp = session.request(
                    method,
                    url,
                    headers=headers,
                    params=params,
                    json=json_body,
                    timeout=VALUESCAN_API_TIMEOUT,
                    proxies=proxies,
                    verify=False,
                )
            except requests.exceptions.RequestException as retry_exc:
                last_exc = retry_exc
                continue
        except requests.exceptions.RequestException as exc:
            last_exc = exc
            continue

        if resp.status_code in (404, 405) and idx < len(bases) - 1:
            continue
        if resp.status_code >= 500 and idx < len(bases) - 1:
            continue
        return resp

    if last_exc:
        raise last_exc
    raise _ValuescanProxyError("Failed to connect to ValueScan API.")


def _valuescan_proxy_response(resp):
    if _valuescan_response_expired(resp):
        try:
            payload = resp.json()
        except ValueError:
            payload = None
        return jsonify({"error": "ValueScan token expired", "details": payload}), 401

    content_type = resp.headers.get("content-type", "application/json")
    return Response(resp.content, status=resp.status_code, content_type=content_type)


def _valuescan_get_int(value, default: int, min_value: int = 1, max_value: Optional[int] = None) -> int:
    try:
        value = int(value)
    except (TypeError, ValueError):
        return default
    if value < min_value:
        return min_value
    if max_value is not None and value > max_value:
        return max_value
    return value


@app.route('/api/valuescan/overview', methods=['GET'])
def valuescan_overview():
    """Proxy ValueScan overview data."""
    try:
        resp = _valuescan_send_request("GET", "/api/index/overview", allow_anonymous=True)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/account', methods=['GET'])
def valuescan_account():
    """Proxy ValueScan account profile."""
    try:
        resp = _valuescan_send_request("GET", "/api/account/getAccount")
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/notices', methods=['GET'])
def valuescan_notices():
    """Proxy maintenance notices."""
    try:
        resp = _valuescan_send_request(
            "GET", "/api/system/config/status/getMaintenanceNotices"
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/announcements', methods=['POST'])
def valuescan_announcements():
    """Proxy system announcements page."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    payload.setdefault("pageNum", 1)
    payload.setdefault("pageSize", 20)
    try:
        resp = _valuescan_send_request(
            "POST", "/api/system/announcements/pageSystemAnnouncements", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/signals/warn', methods=['GET'])
def valuescan_signals_warn():
    """Proxy ValueScan warn messages."""
    try:
        resp = _valuescan_send_request("GET", VALUESCAN_WARN_PATH)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/signals/ai', methods=['POST'])
def valuescan_signals_ai():
    """Proxy ValueScan AI signal messages."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    payload.setdefault("pageNum", 1)
    payload.setdefault("pageSize", 50)
    try:
        resp = _valuescan_send_request(
            "POST", VALUESCAN_AI_MESSAGE_PATH, json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/coin-rank', methods=['POST'])
def valuescan_coin_rank():
    """Proxy ValueScan top lists (gainers/losers)."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400

    payload = dict(payload)
    rank = (request.args.get("rank") or "").strip().lower()
    if rank in {"gainers", "up", "rise", "top"}:
        payload.setdefault("type", 1)
    elif rank in {"losers", "down", "fall"}:
        payload.setdefault("type", 2)

    payload["page"] = _valuescan_get_int(payload.get("page"), 1)
    payload["pageSize"] = _valuescan_get_int(payload.get("pageSize"), 20, min_value=1, max_value=100)
    if "type" in request.args:
        payload["type"] = _valuescan_get_int(request.args.get("type"), payload.get("type", 1), min_value=1, max_value=2)
    payload.setdefault("type", 1)

    if "order" not in payload:
        if payload.get("type") == 2:
            payload["order"] = [
                {"column": "percentChange24h", "asc": True},
                {"column": "marketCap", "asc": False},
            ]
        else:
            payload["order"] = [
                {"column": "percentChange24h", "asc": False},
                {"column": "marketCap", "asc": False},
            ]

    try:
        resp = _valuescan_send_request(
            "POST", "/api/analysis/crypto/coin-rank", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/movement/list', methods=['POST'])
def valuescan_movement_list():
    """Proxy ValueScan funds movement list."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    try:
        resp = _valuescan_send_request(
            "POST", VALUESCAN_MOVEMENT_LIST_PATH, json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/movement/update', methods=['GET'])
def valuescan_movement_update():
    """Proxy ValueScan funds movement updates."""
    try:
        resp = _valuescan_send_request(
            "GET", VALUESCAN_MOVEMENT_UPDATE_PATH, params=request.args
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/coins/list', methods=['POST'])
def valuescan_coins_list():
    """Proxy ValueScan coin search/list."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 50)
    try:
        resp = _valuescan_send_request(
            "POST", "/api/vs-token/queryCoin", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/coins/prices', methods=['POST'])
def valuescan_coins_prices():
    """Proxy ValueScan coin prices."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    try:
        resp = _valuescan_send_request(
            "POST", "/api/vs-token/listPrice", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/info', methods=['GET'])
def valuescan_token_info():
    """Proxy ValueScan token info by keyword."""
    keyword = (request.args.get("keyword") or "").strip()
    if not keyword:
        return jsonify({"error": "Missing keyword"}), 400
    path = f"/api/track/judge/getExchangeCoinInfo?keyword={keyword}"
    try:
        resp = _valuescan_send_request("GET", path)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/flows', methods=['GET'])
def valuescan_token_flows():
    """Proxy ValueScan main funds inflow/outflow by keyword."""
    keyword = (request.args.get("keyword") or "").strip()
    if not keyword:
        return jsonify({"error": "Missing keyword"}), 400
    path = f"/api/trade/getCoinTradeInflow?keyword={keyword}"
    try:
        resp = _valuescan_send_request("GET", path)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/exchange-flow-detail', methods=['GET', 'POST'])
def valuescan_token_exchange_flow_detail():
    """Proxy ValueScan exchange flow detail by keyword."""
    payload = request.get_json(silent=True) or {}
    if payload and not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    keyword_raw = request.args.get("keyword") or payload.get("keyword") or payload.get("vsTokenId") or ""
    keyword = str(keyword_raw).strip()
    if not keyword:
        return jsonify({"error": "Missing keyword"}), 400
    path = f"/api/analysis/coin/exchange-flow-detail?keyword={keyword}"
    try:
        resp = _valuescan_send_request("POST", path, json_body={})
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/fund-history', methods=['POST'])
def valuescan_token_fund_history():
    """Proxy ValueScan fund flow/volume history."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    try:
        resp = _valuescan_send_request("POST", "/api/trade/fundTradeHistoryTotal", json_body=payload)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/holders', methods=['POST'])
def valuescan_token_holders():
    """Proxy ValueScan holder page data."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 20)
    if not payload.get("coinKey"):
        symbol = payload.get("symbol") or (request.args.get("symbol") or "").strip()
        chain = payload.get("chain") or (request.args.get("chain") or "").strip()
        if symbol:
            base = symbol.upper().replace("$", "").replace("USDT", "").strip()
            chain_name = (chain or base).upper().strip()
            if base and chain_name:
                payload["coinKey"] = f"{base}_{chain_name}"
    try:
        resp = _valuescan_send_request("POST", "/api/track/judge/holder-page", json_body=payload)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/chains', methods=['POST'])
def valuescan_token_chains():
    """Proxy ValueScan chain list data."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 20)
    try:
        resp = _valuescan_send_request("POST", "/api/cmc/coin/chain/page", json_body=payload)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/ai-summary', methods=['GET'])
def valuescan_token_ai_summary():
    """Proxy ValueScan AI coin summary."""
    vs_token_id = (request.args.get("vsTokenId") or request.args.get("keyword") or "").strip()
    if not vs_token_id:
        return jsonify({"error": "Missing vsTokenId"}), 400
    path = f"/api/ai/getAiCoinSummarize?vsTokenId={vs_token_id}"
    try:
        resp = _valuescan_send_request("GET", path)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/kline/types', methods=['GET'])
def valuescan_token_kline_types():
    """Proxy ValueScan supported kline types."""
    keyword = (request.args.get("keyword") or "").strip()
    if not keyword:
        return jsonify({"error": "Missing keyword"}), 400
    path = f"/api/track/judge/getTradeCoinKline?keyword={keyword}"
    try:
        resp = _valuescan_send_request("GET", path)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/kline/time', methods=['GET'])
def valuescan_token_kline_time():
    """Proxy ValueScan kline time reference."""
    try:
        resp = _valuescan_send_request("GET", "/api/kline/time")
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/kline/history', methods=['POST'])
def valuescan_token_kline_history():
    """Proxy ValueScan kline history."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    try:
        resp = _valuescan_send_request("POST", "/api/kline/history", json_body=payload)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/kline/miss', methods=['POST'])
def valuescan_token_kline_miss():
    """Proxy ValueScan kline missing ranges."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    try:
        resp = _valuescan_send_request("POST", "/api/kline/missQuery", json_body=payload)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/dense-areas', methods=['GET', 'POST'])
def valuescan_token_dense_areas():
    """Proxy ValueScan key levels (dense area / 主力位) data - green horizontal lines on chart."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    try:
        resp = _valuescan_send_request(
            "POST",
            "/api/dense/getDenseAreaKLineHistory",
            json_body=payload,
            allow_anonymous=True,
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token/hold-cost', methods=['GET', 'POST'])
def valuescan_token_hold_cost():
    """Proxy ValueScan hold cost (主力成本/持仓成本) data."""
    payload = request.get_json(silent=True) or {}
    if not isinstance(payload, dict):
        return jsonify({"error": "Invalid payload"}), 400
    # Expect: { keyword: int, begin: int (ms), end: int (ms) }
    try:
        resp = _valuescan_send_request(
            "POST",
            "/api/track/judge/coin/getHoldCost",
            json_body=payload,
            allow_anonymous=True,
        )
        if resp.status_code == 405:
            resp = _valuescan_send_request(
                "GET",
                "/api/track/judge/coin/getHoldCost",
                params=payload,
                allow_anonymous=True,
            )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/rankings/gainers', methods=['GET', 'POST'])
def valuescan_rankings_gainers():
    """Get top gainers from ValuScan."""
    payload = request.get_json(silent=True) or {}
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 20)
    payload.setdefault("order", [{"column": "percentChange24h", "asc": False}])
    payload.setdefault("type", 1)
    try:
        resp = _valuescan_send_request(
            "POST", "/api/analysis/crypto/coin-rank", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/rankings/losers', methods=['GET', 'POST'])
def valuescan_rankings_losers():
    """Get top losers from ValuScan."""
    payload = request.get_json(silent=True) or {}
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 20)
    payload.setdefault("order", [{"column": "percentChange24h", "asc": True}])
    payload.setdefault("type", 2)
    try:
        resp = _valuescan_send_request(
            "POST", "/api/analysis/crypto/coin-rank", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/rankings/main-cost', methods=['GET', 'POST'])
def valuescan_rankings_main_cost():
    """Get main cost rankings (主力成本排行) from ValuScan."""
    payload = request.get_json(silent=True) or {}
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 20)
    payload.setdefault("order", [{"column": "marketCap", "asc": False}])
    payload.setdefault("filters", [])
    try:
        resp = _valuescan_send_request(
            "POST", "/api/analysis/coin/quality-rank", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/signals/opportunity', methods=['GET', 'POST'])
def valuescan_signals_opportunity():
    """Get opportunity bullish signals (机会看涨) from ValuScan."""
    payload = request.get_json(silent=True) or {}
    page_num = payload.pop("pageNum", None)
    page_size = payload.pop("pageSize", None)
    payload.setdefault("page", page_num or 1)
    payload.setdefault("pageSize", page_size or 20)
    payload.setdefault("order", {"column": "date", "asc": False})
    payload.setdefault("volumes", [])
    payload.setdefault("inflows", [])
    payload.setdefault("marketCap", True)
    payload.setdefault("circulationRate", True)
    try:
        resp = _valuescan_send_request(
            "POST", "/api/chance/getChangeCoinPage", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/signals/risk', methods=['GET', 'POST'])
def valuescan_signals_risk():
    """Get risk bearish signals (风险看跌) from ValuScan."""
    payload = request.get_json(silent=True) or {}
    page_num = payload.pop("pageNum", None)
    page_size = payload.pop("pageSize", None)
    payload.setdefault("page", page_num or 1)
    payload.setdefault("pageSize", page_size or 20)
    payload.setdefault("order", {"column": "date", "asc": False})
    payload.setdefault("volumes", [])
    payload.setdefault("inflows", [])
    payload.setdefault("marketCap", True)
    payload.setdefault("circulationRate", True)
    try:
        resp = _valuescan_send_request(
            "POST", "/api/chance/getChangeCoinRiskPage", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/whale-flow', methods=['GET', 'POST'])
def valuescan_whale_flow():
    """Get whale flow / main funds flow from ValuScan."""
    payload = request.get_json(silent=True) or {}
    trade_type = payload.pop("tradeType", None)
    time_period = payload.pop("timePeriod", None)
    page_num = payload.pop("pageNum", None)
    page_size = payload.pop("pageSize", None)
    payload.setdefault("page", page_num or 1)
    payload.setdefault("pageSize", page_size or 20)
    payload.setdefault("type", trade_type or 1)
    payload.setdefault("time", time_period or "m5")
    try:
        resp = _valuescan_send_request(
            "POST", "/api/trade/getTimeTradePage", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/token-flow', methods=['GET', 'POST'])
def valuescan_token_flow():
    """Get token exchange flow from ValuScan."""
    payload = request.get_json(silent=True) or {}
    time_enum = payload.pop("timeParticleEnum", None)
    payload.setdefault("page", 1)
    payload.setdefault("pageSize", 20)
    payload.setdefault("time", time_enum or payload.get("time") or "H12")
    try:
        resp = _valuescan_send_request(
            "POST", "/api/analysis/coin/getCoinExchangeFlowPage", json_body=payload
        )
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


@app.route('/api/valuescan/symbol-map', methods=['GET'])
def valuescan_symbol_map():
    """Get symbol to keyword mapping table for all coins."""
    cache_path = BASE_DIR / "valuescan_api" / "data" / "symbol_cache.json"
    if cache_path.exists():
        try:
            data = json.loads(cache_path.read_text(encoding="utf-8"))
            return jsonify({"code": 200, "data": data})
        except Exception as exc:
            return jsonify({"code": 500, "error": str(exc)}), 500
    return jsonify({"code": 404, "error": "Symbol cache not found", "data": {}})


@app.route('/api/valuescan/symbol-to-keyword', methods=['GET'])
def valuescan_symbol_to_keyword():
    """Convert symbol to keyword (coin ID)."""
    symbol = (request.args.get("symbol") or "").strip().upper()
    if not symbol:
        return jsonify({"code": 400, "error": "Symbol required", "keyword": None}), 400
    
    cache_path = BASE_DIR / "valuescan_api" / "data" / "symbol_cache.json"
    if cache_path.exists():
        try:
            data = json.loads(cache_path.read_text(encoding="utf-8"))
            keyword = data.get(symbol)
            if keyword:
                return jsonify({"code": 200, "symbol": symbol, "keyword": keyword})
            return jsonify({"code": 404, "error": f"Symbol {symbol} not found", "keyword": None})
        except Exception as exc:
            return jsonify({"code": 500, "error": str(exc), "keyword": None}), 500
    return jsonify({"code": 404, "error": "Symbol cache not found", "keyword": None})


@app.route('/api/valuescan/coin-detail', methods=['GET'])
def valuescan_coin_detail():
    """Get complete coin detail by symbol or keyword."""
    symbol = (request.args.get("symbol") or "").strip().upper()
    keyword = request.args.get("keyword")
    days = int(request.args.get("days") or 90)
    
    if not keyword and not symbol:
        return jsonify({"code": 400, "error": "Symbol or keyword required"}), 400
    
    # Resolve symbol to keyword if needed
    if not keyword and symbol:
        cache_path = BASE_DIR / "valuescan_api" / "data" / "symbol_cache.json"
        if cache_path.exists():
            try:
                data = json.loads(cache_path.read_text(encoding="utf-8"))
                keyword = data.get(symbol)
            except Exception:
                pass
        if not keyword:
            return jsonify({"code": 404, "error": f"Symbol {symbol} not found"}), 404
    
    keyword = int(keyword)
    end_time = int(time.time() * 1000)
    begin_time = end_time - (days * 24 * 60 * 60 * 1000)
    
    result = {"code": 200, "symbol": symbol, "keyword": keyword, "data": {}}
    info_data: Dict[str, Any] = {}
    
    try:
        # Get token info
        info_resp = _valuescan_send_request("GET", f"/api/track/judge/getExchangeCoinInfo?keyword={keyword}")
        if info_resp.status_code == 200:
            info_data = info_resp.json()
            if info_data.get("code") == 200:
                info_payload = info_data.get("data", {}) or {}
                result["data"]["info"] = info_payload
                if not symbol:
                    symbol = (info_payload.get("symbol") or "").strip().upper()
                    result["symbol"] = symbol
        
        # Get dense areas (主力位)
        dense_resp = _valuescan_send_request("POST", "/api/dense/getDenseAreaKLineHistory", json_body={
            "vsTokenId": str(keyword),
            "beginTime": begin_time,
            "endTime": end_time
        })
        if dense_resp.status_code == 200:
            dense_data = dense_resp.json()
            if dense_data.get("code") == 200:
                areas = dense_data.get("data", [])
                result["data"]["denseAreas"] = areas
                if areas:
                    result["data"]["currentDensePrice"] = float(areas[-1].get("price", 0))
        
        # Get hold cost (主力成本)
        cost_resp = _valuescan_send_request("POST", "/api/track/judge/coin/getHoldCost", json_body={
            "keyword": keyword,
            "begin": begin_time,
            "end": end_time
        })
        if cost_resp.status_code == 200:
            cost_data = cost_resp.json()
            if cost_data.get("code") == 200:
                result["data"]["holdCost"] = cost_data.get("data", {})
                holding = cost_data.get("data", {}).get("holdingPrice", [])
                if holding:
                    result["data"]["currentHoldCost"] = float(holding[-1].get("val", 0))
        
        # Get trade inflow (资金流入)
        inflow_resp = _valuescan_send_request("GET", f"/api/trade/getCoinTradeInflow?keyword={keyword}")
        if inflow_resp.status_code == 200:
            inflow_data = inflow_resp.json()
            if inflow_data.get("code") == 200:
                result["data"]["tradeInflow"] = inflow_data.get("data", {})

        flow_resp = _valuescan_send_request(
            "POST",
            f"/api/analysis/coin/exchange-flow-detail?keyword={keyword}",
            json_body={},
        )
        if flow_resp.status_code == 200:
            flow_data = flow_resp.json()
            if flow_data.get("code") == 200:
                result["data"]["exchangeFlowDetail"] = flow_data.get("data", {})

        flow_history_resp = _valuescan_send_request("POST", "/api/trade/fundTradeHistoryTotal", json_body={
            "timeParticle": "12h",
            "limitSize": 60,
            "flow": True,
            "keyword": keyword,
            "type": 2,
        })
        if flow_history_resp.status_code == 200:
            flow_history = flow_history_resp.json()
            if flow_history.get("code") == 200:
                result["data"]["fundFlowHistory"] = flow_history.get("data", [])

        volume_history_resp = _valuescan_send_request("POST", "/api/trade/fundTradeHistoryTotal", json_body={
            "timeParticle": "12h",
            "limitSize": 60,
            "flow": False,
            "keyword": keyword,
            "type": 2,
        })
        if volume_history_resp.status_code == 200:
            volume_history = volume_history_resp.json()
            if volume_history.get("code") == 200:
                result["data"]["fundVolumeHistory"] = volume_history.get("data", [])

        info_payload = info_data.get("data", {}) if isinstance(info_data, dict) else {}
        base_symbol = (symbol or info_payload.get("symbol") or "").replace("$", "").replace("USDT", "").strip().upper()
        chain_name = (info_payload.get("chainName") or base_symbol).strip().upper()
        coin_key = info_payload.get("coinKey") or (f"{base_symbol}_{chain_name}" if base_symbol else "")

        if coin_key:
            holders_resp = _valuescan_send_request("POST", "/api/track/judge/holder-page", json_body={
                "page": 1,
                "pageSize": 10,
                "address": "",
                "coinKey": coin_key,
                "keyword": keyword,
            })
            if holders_resp.status_code == 200:
                holders_data = holders_resp.json()
                if holders_data.get("code") == 200:
                    result["data"]["holders"] = holders_data.get("data", {})

        if base_symbol:
            chains_resp = _valuescan_send_request("POST", "/api/cmc/coin/chain/page", json_body={
                "symbol": base_symbol,
                "page": 1,
                "pageSize": 10,
            })
            if chains_resp.status_code == 200:
                chains_data = chains_resp.json()
                if chains_data.get("code") == 200:
                    result["data"]["chains"] = chains_data.get("data", {})
        
        return jsonify(result)
    except _ValuescanAuthError as exc:
        return jsonify({"code": 401, "error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"code": 502, "error": str(exc)}), 502


@app.route('/api/valuescan/proxy/<path:subpath>', methods=['GET', 'POST'])
def valuescan_proxy_generic(subpath: str):
    """Proxy ValueScan endpoints under /api/*."""
    if "://" in subpath or ".." in subpath:
        return jsonify({"error": "Invalid path"}), 400
    if not subpath.startswith("api/"):
        return jsonify({"error": "Only /api/* paths are allowed"}), 400
    allowed_prefixes = (
        "api/index/",
        "api/analysis/",
        "api/account/message/",
        "api/chance/",
        "api/vs-token/",
        "api/track/",
        "api/trade/",
        "api/kline/",
        "api/dense/",
        "api/system/",
        "api/ai/",
    )
    if not subpath.startswith(allowed_prefixes):
        return jsonify({"error": "Path not allowlisted"}), 400

    path = f"/{subpath}"
    params = request.args if request.method == "GET" else None
    json_body = None
    if request.method == "POST":
        json_body = request.get_json(silent=True)
        if json_body is not None and not isinstance(json_body, dict):
            return jsonify({"error": "Invalid payload"}), 400

    try:
        resp = _valuescan_send_request(request.method, path, params=params, json_body=json_body)
        return _valuescan_proxy_response(resp)
    except _ValuescanAuthError as exc:
        return jsonify({"error": str(exc)}), 401
    except Exception as exc:
        return jsonify({"error": str(exc)}), 502


def _default_coinpool_config() -> dict:
    return {
        "host": "127.0.0.1",
        "port": 30006,
        "tab": "机会监控",
        "url": "https://www.valuescan.io/GEMs/signals",
        "headless": True,
        "chrome_debug_port": 9222,
        "user_data_path": str(BASE_DIR / "signal_monitor" / "chrome-debug-profile"),
        "max_pages": 1,
        "limit": 200,
        "cache_ttl_s": 15,
    }


@app.route('/api/valuescan/coinpool/config', methods=['GET'])
def valuescan_get_coinpool_config():
    """Get local ValueScan->AI500 coinpool server config (stored as JSON)."""
    defaults = _default_coinpool_config()
    current = _read_json_file(VALUESCAN_COINPOOL_CONFIG_FILE, default={})
    if not isinstance(current, dict):
        current = {}
    return jsonify(
        {"config": {**defaults, **current}, "path": str(VALUESCAN_COINPOOL_CONFIG_FILE)}
    )


@app.route('/api/valuescan/coinpool/config', methods=['POST'])
def valuescan_save_coinpool_config():
    """Save local ValueScan->AI500 coinpool server config (stored as JSON)."""
    payload = request.json or {}
    if not isinstance(payload, dict):
        return jsonify({"success": False, "error": "Invalid payload"}), 400

    raw_cfg = payload.get("config")
    if not isinstance(raw_cfg, dict):
        return jsonify({"success": False, "error": "Missing config"}), 400

    defaults = _default_coinpool_config()
    allowed_keys = set(defaults.keys())
    cfg = {k: v for k, v in raw_cfg.items() if k in allowed_keys}

    errors = []

    def _as_int(name: str, min_value: int = 0):
        val = cfg.get(name, defaults.get(name))
        try:
            val = int(val)
        except Exception:
            errors.append(f"{name} must be an integer")
            return defaults.get(name)
        if val < min_value:
            errors.append(f"{name} must be >= {min_value}")
            return defaults.get(name)
        return val

    def _as_bool(name: str):
        val = cfg.get(name, defaults.get(name))
        if isinstance(val, bool):
            return val
        if isinstance(val, str):
            return val.strip().lower() in ("1", "true", "yes", "on")
        return bool(val)

    def _as_str(name: str):
        val = cfg.get(name, defaults.get(name))
        if val is None:
            return ""
        return str(val)

    normalized = {
        "host": _as_str("host") or "127.0.0.1",
        "port": _as_int("port", min_value=1),
        "tab": _as_str("tab") or defaults["tab"],
        "url": _as_str("url") or defaults["url"],
        "headless": _as_bool("headless"),
        "chrome_debug_port": _as_int("chrome_debug_port", min_value=1),
        "user_data_path": _as_str("user_data_path") or defaults["user_data_path"],
        "max_pages": _as_int("max_pages", min_value=1),
        "limit": _as_int("limit", min_value=1),
        "cache_ttl_s": _as_int("cache_ttl_s", min_value=1),
    }

    if errors:
        return jsonify({"success": False, "errors": errors}), 400

    try:
        _write_json_file(VALUESCAN_COINPOOL_CONFIG_FILE, normalized)
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500

    return jsonify(
        {
            "success": True,
            "config": normalized,
            "path": str(VALUESCAN_COINPOOL_CONFIG_FILE),
        }
    )


# AI Market Summary Config
AI_SIGNAL_CONFIG_FILE = BASE_DIR / 'signal_monitor' / 'ai_signal_config.json'
AI_LEVELS_CONFIG_FILE = BASE_DIR / 'signal_monitor' / 'ai_key_levels_config.json'
AI_OVERLAYS_CONFIG_FILE = BASE_DIR / 'signal_monitor' / 'ai_overlays_config.json'
AI_MARKET_CONFIG_FILE = BASE_DIR / 'signal_monitor' / 'ai_market_summary_config.json'
AI_SUMMARY_CONFIG_FILE = AI_MARKET_CONFIG_FILE


def _default_ai_summary_config():
    return {
        "enabled": False,
        "interval_hours": 1.0,
        "api_key": "",
        "api_url": "https://api.openai.com/v1/chat/completions",
        "model": "gpt-4o-mini",
        "lookback_hours": 1.0,
    }


@app.route('/api/valuescan/ai-summary/config', methods=['GET'])
def valuescan_get_ai_summary_config():
    """Get AI market summary configuration."""
    defaults = _default_ai_summary_config()
    current = {}
    if AI_SUMMARY_CONFIG_FILE.exists():
        try:
            current = json.loads(AI_SUMMARY_CONFIG_FILE.read_text(encoding='utf-8'))
        except Exception:
            pass
    if not isinstance(current, dict):
        current = {}
    return jsonify({"config": {**defaults, **current}})


@app.route('/api/valuescan/ai-summary/config', methods=['POST'])
def valuescan_save_ai_summary_config():
    """Save AI market summary configuration."""
    payload = request.json or {}
    raw_cfg = payload.get("config", payload)
    if not isinstance(raw_cfg, dict):
        return jsonify({"success": False, "error": "Invalid config"}), 400

    defaults = _default_ai_summary_config()
    
    def _as_bool(val):
        if isinstance(val, bool):
            return val
        if isinstance(val, str):
            return val.strip().lower() in ("1", "true", "yes", "on")
        return bool(val)
    
    def _as_float(val, default):
        try:
            return float(val)
        except Exception:
            return default
    
    normalized = {
        "enabled": _as_bool(raw_cfg.get("enabled", defaults["enabled"])),
        "interval_hours": max(0.5, _as_float(raw_cfg.get("interval_hours"), defaults["interval_hours"])),
        "api_key": str(raw_cfg.get("api_key", defaults["api_key"])).strip(),
        "api_url": str(raw_cfg.get("api_url", defaults["api_url"])).strip() or defaults["api_url"],
        "model": str(raw_cfg.get("model", defaults["model"])).strip() or defaults["model"],
        "lookback_hours": max(0.5, _as_float(raw_cfg.get("lookback_hours"), defaults["lookback_hours"])),
    }
    
    try:
        AI_SUMMARY_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        AI_SUMMARY_CONFIG_FILE.write_text(json.dumps(normalized, ensure_ascii=False, indent=2), encoding='utf-8')
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500
    
    return jsonify({"success": True, "config": normalized})


@app.route('/api/valuescan/ai-summary/trigger', methods=['POST'])
def valuescan_trigger_ai_summary():
    """Manually trigger AI market summary generation (async)."""
    try:
        import sys
        import threading
        sys.path.insert(0, str(BASE_DIR / 'signal_monitor'))
        from ai_market_summary import generate_market_summary

        # 异步执行 AI 简评生成
        def run_async():
            try:
                print("[AI-Summary] Starting async generation...")
                summary = generate_market_summary(force=True)
                if summary:
                    print(f"[AI-Summary] Generated successfully: {len(summary)} chars")
                else:
                    print("[AI-Summary] Generation failed")
            except Exception as e:
                print(f"[AI-Summary] Error in async generation: {e}")
                import traceback
                traceback.print_exc()

        thread = threading.Thread(target=run_async, daemon=True)
        thread.start()

        return jsonify({
            "success": True,
            "message": "AI market summary generation started in background",
            "status": "processing"
        })
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500


# ============================================================================
# AI Signal Analysis Config (AI简评配置)
# ============================================================================

def _default_ai_signal_config():
    return {
        "enabled": True,
        "api_key": "sk-chat2api",
        "api_url": "https://chat.cornna.xyz/chatgpt/v1/chat/completions",
        "model": "gpt-5.2",
        "interval_hours": 1.0,
        "lookback_hours": 1.0,
    }


@app.route('/api/valuescan/ai-signal/config', methods=['GET'])
def valuescan_get_ai_signal_config():
    """Get AI signal analysis configuration."""
    defaults = _default_ai_signal_config()
    current = {}
    if AI_SIGNAL_CONFIG_FILE.exists():
        try:
            current = json.loads(AI_SIGNAL_CONFIG_FILE.read_text(encoding='utf-8'))
        except Exception:
            pass
    if not isinstance(current, dict):
        current = {}
    return jsonify({"config": {**defaults, **current}})


@app.route('/api/valuescan/ai-signal/config', methods=['POST'])
def valuescan_save_ai_signal_config():
    """Save AI signal analysis configuration."""
    payload = request.json or {}
    raw_cfg = payload.get("config", payload)
    if not isinstance(raw_cfg, dict):
        return jsonify({"success": False, "error": "Invalid config"}), 400

    defaults = _default_ai_signal_config()

    def _as_bool(val):
        if isinstance(val, bool):
            return val
        if isinstance(val, str):
            return val.strip().lower() in ("1", "true", "yes", "on")
        return bool(val)

    def _as_float(val, default):
        try:
            return float(val)
        except (TypeError, ValueError):
            return default

    normalized = {
        "enabled": _as_bool(raw_cfg.get("enabled", defaults["enabled"])),
        "api_key": str(raw_cfg.get("api_key", defaults["api_key"])).strip(),
        "api_url": str(raw_cfg.get("api_url", defaults["api_url"])).strip() or defaults["api_url"],
        "model": str(raw_cfg.get("model", defaults["model"])).strip() or defaults["model"],
        "interval_hours": _as_float(raw_cfg.get("interval_hours"), defaults["interval_hours"]),
        "lookback_hours": _as_float(raw_cfg.get("lookback_hours"), defaults["lookback_hours"]),
    }

    try:
        AI_SIGNAL_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        AI_SIGNAL_CONFIG_FILE.write_text(json.dumps(normalized, ensure_ascii=False, indent=2), encoding='utf-8')
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500

    return jsonify({"success": True, "config": normalized})


@app.route('/api/valuescan/ai-signal/test', methods=['POST'])
def valuescan_test_ai_signal_connection():
    """Test AI signal analysis API connection."""
    payload = request.json or {}
    api_key = payload.get("api_key", "").strip()
    api_url = payload.get("api_url", "").strip()
    model = payload.get("model", "").strip()

    if not api_key or not api_url or not model:
        return jsonify({"success": False, "error": "Missing required fields"}), 400

    try:
        import requests as req
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        test_payload = {
            "model": model,
            "messages": [{"role": "user", "content": "test"}],
            "max_tokens": 10
        }
        response = req.post(api_url, headers=headers, json=test_payload, timeout=10)

        if response.status_code == 200:
            return jsonify({"success": True, "message": "连接成功"})
        else:
            return jsonify({"success": False, "error": f"API返回错误: {response.status_code}"}), 400
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500


# ============================================================================
# AI Key Levels Config (AI主力位配置)
# ============================================================================

def _default_ai_levels_config():
    return {
        "enabled": True,
        "api_key": "Qq159741",
        "api_url": "https://chat.cornna.xyz/gemini/v1/chat/completions",
        "model": "gemini-3-flash-preview-search",
    }


@app.route('/api/valuescan/ai-levels/config', methods=['GET'])
def valuescan_get_ai_levels_config():
    """Get AI key levels configuration."""
    defaults = _default_ai_levels_config()
    current = {}
    if AI_LEVELS_CONFIG_FILE.exists():
        try:
            current = json.loads(AI_LEVELS_CONFIG_FILE.read_text(encoding='utf-8'))
        except Exception:
            pass
    if not isinstance(current, dict):
        current = {}
    return jsonify({"config": {**defaults, **current}})


@app.route('/api/valuescan/ai-levels/config', methods=['POST'])
def valuescan_save_ai_levels_config():
    """Save AI key levels configuration."""
    payload = request.json or {}
    raw_cfg = payload.get("config", payload)
    if not isinstance(raw_cfg, dict):
        return jsonify({"success": False, "error": "Invalid config"}), 400

    defaults = _default_ai_levels_config()

    def _as_bool(val):
        if isinstance(val, bool):
            return val
        if isinstance(val, str):
            return val.strip().lower() in ("1", "true", "yes", "on")
        return bool(val)

    normalized = {
        "enabled": _as_bool(raw_cfg.get("enabled", defaults["enabled"])),
        "api_key": str(raw_cfg.get("api_key", defaults["api_key"])).strip(),
        "api_url": str(raw_cfg.get("api_url", defaults["api_url"])).strip() or defaults["api_url"],
        "model": str(raw_cfg.get("model", defaults["model"])).strip() or defaults["model"],
    }

    try:
        AI_LEVELS_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        AI_LEVELS_CONFIG_FILE.write_text(json.dumps(normalized, ensure_ascii=False, indent=2), encoding='utf-8')
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500

    return jsonify({"success": True, "config": normalized})


@app.route('/api/valuescan/ai-levels/test', methods=['POST'])
def valuescan_test_ai_levels_connection():
    """Test AI key levels API connection."""
    payload = request.json or {}
    api_key = payload.get("api_key", "").strip()
    api_url = payload.get("api_url", "").strip()
    model = payload.get("model", "").strip()

    if not api_key or not api_url or not model:
        return jsonify({"success": False, "error": "Missing required fields"}), 400

    try:
        import requests as req
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        test_payload = {
            "model": model,
            "messages": [{"role": "user", "content": "test"}],
            "max_tokens": 10
        }
        response = req.post(api_url, headers=headers, json=test_payload, timeout=10)

        if response.status_code == 200:
            return jsonify({"success": True, "message": "连接成功"})
        else:
            return jsonify({"success": False, "error": f"API返回错误: {response.status_code}"}), 400
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500


# ============================================================================
# AI Overlays Config (AI辅助线/叠加层配置)
# ============================================================================

def _default_ai_overlays_config():
    return {
        "enabled": True,
        "api_key": "Qq159741",
        "api_url": "https://chat.cornna.xyz/gemini/v1/chat/completions",
        "model": "gemini-3-flash-preview-search",
    }


@app.route('/api/valuescan/ai-overlays/config', methods=['GET'])
def valuescan_get_ai_overlays_config():
    """Get AI overlays configuration."""
    defaults = _default_ai_overlays_config()
    current = {}
    if AI_OVERLAYS_CONFIG_FILE.exists():
        try:
            current = json.loads(AI_OVERLAYS_CONFIG_FILE.read_text(encoding='utf-8'))
        except Exception:
            pass
    if not isinstance(current, dict):
        current = {}
    return jsonify({"success": True, "config": {**defaults, **current}})


@app.route('/api/valuescan/ai-overlays/config', methods=['POST'])
def valuescan_save_ai_overlays_config():
    """Save AI overlays configuration."""
    payload = request.json or {}
    raw_cfg = payload.get("config", payload)
    if not isinstance(raw_cfg, dict):
        return jsonify({"success": False, "error": "Invalid config"}), 400

    defaults = _default_ai_overlays_config()

    def _as_bool(val):
        if isinstance(val, bool):
            return val
        if isinstance(val, str):
            return val.strip().lower() in ("1", "true", "yes", "on")
        return bool(val)

    normalized = {
        "enabled": _as_bool(raw_cfg.get("enabled", defaults["enabled"])),
        "api_key": str(raw_cfg.get("api_key", defaults["api_key"])).strip(),
        "api_url": str(raw_cfg.get("api_url", defaults["api_url"])).strip() or defaults["api_url"],
        "model": str(raw_cfg.get("model", defaults["model"])).strip() or defaults["model"],
    }

    try:
        AI_OVERLAYS_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        AI_OVERLAYS_CONFIG_FILE.write_text(json.dumps(normalized, ensure_ascii=False, indent=2), encoding='utf-8')
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500

    return jsonify({"success": True, "config": normalized})


@app.route('/api/valuescan/ai-overlays/test', methods=['POST'])
def valuescan_test_ai_overlays_connection():
    """Test AI overlays API connection."""
    payload = request.json or {}
    api_key = payload.get("api_key", "").strip()
    api_url = payload.get("api_url", "").strip()
    model = payload.get("model", "").strip()

    if not api_key or not api_url or not model:
        return jsonify({"success": False, "error": "Missing required fields"}), 400

    try:
        import requests as req
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        test_payload = {
            "model": model,
            "messages": [{"role": "user", "content": "test"}],
            "max_tokens": 10
        }
        response = req.post(api_url, headers=headers, json=test_payload, timeout=10)

        if response.status_code == 200:
            return jsonify({"success": True, "message": "连接成功"})
        else:
            return jsonify({"success": False, "error": f"API返回错误: {response.status_code}"}), 400
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500


# ============================================================================
# AI Market Analysis Config (AI市场宏观分析配置)
# ============================================================================

def _default_ai_market_config():
    return {
        "enabled": True,
        "interval_hours": 1.0,
        "api_key": "Qq159741",
        "api_url": "https://chat.cornna.xyz/gemini/v1/chat/completions",
        "model": "gemini-3-pro-preview-search",
        "lookback_hours": 48.0,
    }


@app.route('/api/valuescan/ai-market/config', methods=['GET'])
def valuescan_get_ai_market_config():
    """Get AI market analysis configuration."""
    defaults = _default_ai_market_config()
    current = {}
    if AI_MARKET_CONFIG_FILE.exists():
        try:
            current = json.loads(AI_MARKET_CONFIG_FILE.read_text(encoding='utf-8'))
        except Exception:
            pass
    if not isinstance(current, dict):
        current = {}
    return jsonify({"config": {**defaults, **current}})


@app.route('/api/valuescan/ai-market/config', methods=['POST'])
def valuescan_save_ai_market_config():
    """Save AI market analysis configuration."""
    payload = request.json or {}
    raw_cfg = payload.get("config", payload)
    if not isinstance(raw_cfg, dict):
        return jsonify({"success": False, "error": "Invalid config"}), 400

    defaults = _default_ai_market_config()

    def _as_bool(val):
        if isinstance(val, bool):
            return val
        if isinstance(val, str):
            return val.strip().lower() in ("1", "true", "yes", "on")
        return bool(val)

    def _as_float(val, default):
        try:
            return float(val)
        except Exception:
            return default

    normalized = {
        "enabled": _as_bool(raw_cfg.get("enabled", defaults["enabled"])),
        "interval_hours": max(0.5, _as_float(raw_cfg.get("interval_hours"), defaults["interval_hours"])),
        "api_key": str(raw_cfg.get("api_key", defaults["api_key"])).strip(),
        "api_url": str(raw_cfg.get("api_url", defaults["api_url"])).strip() or defaults["api_url"],
        "model": str(raw_cfg.get("model", defaults["model"])).strip() or defaults["model"],
        "lookback_hours": max(0.5, _as_float(raw_cfg.get("lookback_hours"), defaults["lookback_hours"])),
    }

    try:
        AI_MARKET_CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        AI_MARKET_CONFIG_FILE.write_text(json.dumps(normalized, ensure_ascii=False, indent=2), encoding='utf-8')
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500

    return jsonify({"success": True, "config": normalized})


@app.route('/api/valuescan/ai-market/test', methods=['POST'])
def valuescan_test_ai_market_connection():
    """Test AI market analysis API connection."""
    payload = request.json or {}
    api_key = payload.get("api_key", "").strip()
    api_url = payload.get("api_url", "").strip()
    model = payload.get("model", "").strip()

    if not api_key or not api_url or not model:
        return jsonify({"success": False, "error": "Missing required fields"}), 400

    try:
        import requests as req
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        test_payload = {
            "model": model,
            "messages": [{"role": "user", "content": "test"}],
            "max_tokens": 10
        }
        response = req.post(api_url, headers=headers, json=test_payload, timeout=10)

        if response.status_code == 200:
            return jsonify({"success": True, "message": "连接成功"})
        else:
            return jsonify({"success": False, "error": f"API返回错误: {response.status_code}"}), 400
    except Exception as exc:
        return jsonify({"success": False, "error": str(exc)}), 500


@app.route('/api/valuescan/login', methods=['POST'])
def valuescan_do_login():
    """Auto login disabled; use manual token upload."""
    return jsonify({
        'success': False,
        'error': 'Auto login disabled. Please use the ValuScan Token page to upload a token.',
    }), 410


@app.route('/api/valuescan/login/browser/prepare', methods=['POST'])
def valuescan_prepare_browser_login():
    """Deprecated browser login flow."""
    return jsonify({
        'success': False,
        'error': 'Browser login flow is disabled. Use the ValuScan Token page to upload a token.',
        'deprecated': True,
        'alternative': '/valuescan-token'
    }), 410


@app.route('/api/valuescan/login/browser/import', methods=['POST'])
def valuescan_import_browser_login():
    """Deprecated browser import flow."""
    return jsonify({
        'success': False,
        'error': 'Browser import flow is disabled. Use the ValuScan Token page to upload a token.',
        'deprecated': True,
        'alternative': '/valuescan-token'
    }), 410


@app.route('/api/valuescan/credentials', methods=['POST'])
def save_valuescan_credentials():
    """Credentials saving disabled to avoid auto refresh."""
    return jsonify({
        'success': False,
        'error': 'Credentials storage is disabled. Please use manual token upload.',
    }), 410


@app.route('/api/valuescan/login/auto', methods=['POST'])
def valuescan_auto_login():
    """Auto login disabled; manual token only."""
    return jsonify({
        'success': False,
        'error': 'Auto login is disabled. Please upload token manually.',
    }), 410


@app.route('/api/valuescan/token/status', methods=['GET'])
def valuescan_token_status():
    """Get token status from local storage."""
    try:
        token_data = _read_json_file(VALUESCAN_TOKEN_FILE, default={})
        token_data = token_data if isinstance(token_data, dict) else {}
        account_token = _valuescan_pick_token(
            token_data,
            ["account_token", "accountToken", "access_token", "accessToken", "token"],
        )
        valid: Optional[bool] = False
        status_error = None
        if account_token:
            try:
                results = []
                for _ in range(3):
                    resp = _valuescan_send_request("GET", "/api/account/getAccount")
                    results.append(not _valuescan_response_expired(resp))
                    time.sleep(0.2)
                if results and all(results):
                    valid = True
                elif results and all(not item for item in results):
                    valid = False
                else:
                    valid = None
                    status_error = "Token check inconsistent. Please retry."
            except _ValuescanAuthError:
                valid = False
            except Exception as exc:
                status_error = str(exc)
                valid = None
        last_updated = token_data.get("last_updated") or token_data.get("imported_at")

        return jsonify({
            'success': True,
            'token_valid': valid,
            'valid': valid,
            'last_updated': last_updated,
            'status_error': status_error,
            'has_credentials': False,
            'email': ''
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/valuescan/env', methods=['GET'])
def valuescan_env_get():
    try:
        env = _parse_env_file(VALUESCAN_ENV_FILE)
        return jsonify({
            'success': True,
            'env': env,
            'path': str(VALUESCAN_ENV_FILE),
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/valuescan/env', methods=['POST'])
def valuescan_env_save():
    try:
        data = request.get_json() or {}
        payload = data.get('env', data)
        if not isinstance(payload, dict):
            return jsonify({
                'success': False,
                'error': 'Invalid payload'
            }), 400

        existing = _parse_env_file(VALUESCAN_ENV_FILE)
        extras = {
            k: v for k, v in existing.items()
            if k not in VALUESCAN_ENV_ALLOWED_KEYS
        }
        merged = {
            k: v for k, v in existing.items()
            if k in VALUESCAN_ENV_ALLOWED_KEYS
        }

        for key in VALUESCAN_ENV_ALLOWED_KEYS:
            if key not in payload:
                continue
            normalized = _normalize_env_value(key, payload.get(key))
            if normalized is None:
                merged.pop(key, None)
            else:
                merged[key] = normalized

        _write_env_file(VALUESCAN_ENV_FILE, merged, extras)

        dropin_results = {}
        restart_results = {}
        errors = []

        if shutil.which('systemctl'):
            for svc in VALUESCAN_ENV_TARGET_SERVICES:
                dropin_results[svc] = _write_systemd_env_dropin(svc, VALUESCAN_ENV_FILE)
                if not dropin_results[svc]:
                    errors.append(f"Failed to write drop-in for {svc}")

            try:
                subprocess.run(['systemctl', 'daemon-reload'], timeout=20, check=False)
            except Exception as exc:
                errors.append(f"Failed to reload systemd: {exc}")

            for svc in VALUESCAN_ENV_TARGET_SERVICES:
                restart_results[svc] = control_service(svc, 'restart')

        return jsonify({
            'success': True,
            'env': merged,
            'path': str(VALUESCAN_ENV_FILE),
            'dropins': dropin_results,
            'restarted': restart_results,
            'errors': errors,
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/valuescan/token/update', methods=['POST'])
def update_valuescan_token():
    """
    Manual ValuScan token update from browser console output.
    Supports:
    1. localStorage dict with account_token/refresh_token
    2. accessToken/refreshToken aliases
    """
    try:
        data = request.get_json() or {}
        token_data = data.get('token', {})

        if not token_data:
            return jsonify({
                'success': False,
                'error': 'Token payload is required'
            }), 400

        if not isinstance(token_data, dict):
            return jsonify({
                'success': False,
                'error': 'Token payload must be a JSON object'
            }), 400

        normalized = {}
        if 'account_token' in token_data:
            normalized['account_token'] = token_data['account_token']
        if 'refresh_token' in token_data:
            normalized['refresh_token'] = token_data['refresh_token']
        if 'accessToken' in token_data:
            normalized['account_token'] = token_data['accessToken']
        if 'refreshToken' in token_data:
            normalized['refresh_token'] = token_data['refreshToken']

        if not normalized.get('account_token'):
            return jsonify({
                'success': False,
                'error': 'Missing account_token/accessToken'
            }), 400

        token_file = VALUESCAN_TOKEN_FILE
        existing = _read_json_file(token_file, default={})
        existing = existing if isinstance(existing, dict) else {}

        merged = dict(existing)
        merged.update(token_data)
        merged.update(normalized)
        merged['accessToken'] = normalized.get('account_token')
        merged['refreshToken'] = normalized.get('refresh_token')
        merged['last_updated'] = datetime.utcnow().isoformat()

        token_file.parent.mkdir(parents=True, exist_ok=True)
        token_file.write_text(json.dumps(merged, indent=2, ensure_ascii=False), encoding='utf-8')

        valid = bool(normalized.get('account_token'))
        message = "Token updated"

        return jsonify({
            'success': True,
            'message': message,
            'valid': valid,
            'last_updated': merged.get('last_updated'),
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/logs/<service>', methods=['GET'])
def get_logs(service: str):
    """获取服务日志"""
    service_map = {
        'signal': 'valuescan-signal',
        'trader': 'valuescan-trader',
        'proxy': 'proxy-checker',
        'xray': 'xray',
        'api': 'valuescan-api',
    }

    if service not in service_map:
        return jsonify({'error': 'Invalid service'}), 400

    lines = request.args.get('lines', 100, type=int)
    lines = min(lines, 2000)  # 最多2000行，与前端日志限制一致

    try:
        result = subprocess.run(
            ['journalctl', '-u', service_map[service], '--no-pager', '-n', str(lines), '--output=json'],
            capture_output=True, text=True, timeout=10
        )

        if result.returncode != 0:
            return jsonify({'error': result.stderr or '获取日志失败'}), 500

        # 解析 JSON 格式的日志
        log_entries = []
        for line in result.stdout.strip().split('\n'):
            if not line:
                continue
            try:
                entry = json.loads(line)
                log_entries.append({
                    'timestamp': int(entry.get('__REALTIME_TIMESTAMP', 0)) // 1000,  # 转换为毫秒
                    'level': entry.get('PRIORITY', '6'),  # syslog priority
                    'component': service,
                    'message': entry.get('MESSAGE', ''),
                    'data': {
                        'unit': entry.get('_SYSTEMD_UNIT', ''),
                        'pid': entry.get('_PID', '')
                    }
                })
            except json.JSONDecodeError:
                continue

        return jsonify({'logs': log_entries, 'service': service, 'count': len(log_entries)})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/tickers', methods=['GET'])
def get_tickers():
    """获取行情数据"""
    try:
        import time
        import requests

        symbols_param = request.args.get('symbols')
        limit = request.args.get('limit', type=int) or 12
        limit = max(1, min(limit, 200))

        def _format_volume_usd(volume: float) -> str:
            if volume >= 1e12:
                return f"${volume / 1e12:.2f}T"
            if volume >= 1e9:
                return f"${volume / 1e9:.1f}B"
            if volume >= 1e6:
                return f"${volume / 1e6:.1f}M"
            if volume >= 1e3:
                return f"${volume / 1e3:.1f}K"
            return f"${volume:.0f}"

        global _public_tickers_cache
        now = time.time()
        cache_ttl = 4.0
        cached = _public_tickers_cache.get('data')
        cached_ok = cached and (now - float(_public_tickers_cache.get('ts', 0)) < cache_ttl)

        error = None
        tickers_data = cached if cached_ok else None

        if tickers_data is None:
            try:
                proxy = parse_config(TRADER_CONFIG).get('socks5_proxy') or parse_config(SIGNAL_CONFIG).get('socks5_proxy')
                proxies = {'http': proxy, 'https': proxy} if proxy else None

                endpoints = [
                    'https://fapi.binance.com/fapi/v1/ticker/24hr',
                    'https://data-api.binance.vision/fapi/v1/ticker/24hr',
                    'https://api.binance.com/api/v3/ticker/24hr',
                    'https://data-api.binance.vision/api/v3/ticker/24hr',
                ]

                raw = None
                last_error = None
                for url in endpoints:
                    try:
                        resp = requests.get(url, timeout=12, proxies=proxies)
                        if resp.status_code == 451:
                            last_error = (
                                f"Binance API blocked (HTTP 451). "
                                f"Please configure a SOCKS5 proxy in settings (socks5_proxy). "
                                f"Blocked URL: {url}"
                            )
                            continue
                        resp.raise_for_status()
                        raw = resp.json()
                        break
                    except requests.RequestException as ex:
                        last_error = str(ex)

                if raw is None:
                    raise RuntimeError(last_error or "Failed to fetch tickers")
                if isinstance(raw, dict):
                    raw = [raw]

                tickers_data = []
                for item in raw:
                    symbol = (item.get('symbol') or '').upper()
                    if not symbol.endswith('USDT'):
                        continue

                    try:
                        last_price = float(item.get('lastPrice') or 0)
                    except Exception:
                        continue

                    try:
                        change_pct = float(item.get('priceChangePercent') or 0)
                    except Exception:
                        change_pct = 0.0

                    try:
                        quote_volume = float(item.get('quoteVolume') or 0)
                    except Exception:
                        quote_volume = 0.0

                    tickers_data.append({
                        'symbol': symbol[:-4],
                        'price': last_price,
                        'change24h': change_pct,
                        'volume': _format_volume_usd(quote_volume),
                        '_quote_volume': quote_volume,
                    })

                tickers_data.sort(key=lambda x: x.get('_quote_volume', 0), reverse=True)
                _public_tickers_cache = {'ts': now, 'data': tickers_data, 'error': None}
            except Exception as e:
                error = str(e)
                tickers_data = _public_tickers_cache.get('data') or []
                _public_tickers_cache = {'ts': now, 'data': tickers_data, 'error': error}
        else:
            error = _public_tickers_cache.get('error')

        if symbols_param:
            requested = []
            for s in symbols_param.split(','):
                s = s.strip().upper()
                if not s:
                    continue
                requested.append(s[:-4] if s.endswith('USDT') else s)

            by_symbol = {t.get('symbol'): t for t in tickers_data}
            result = [by_symbol[s] for s in requested if s in by_symbol]
        else:
            result = tickers_data[:limit]

        # Remove internal fields
        for t in result:
            if '_quote_volume' in t:
                t.pop('_quote_volume', None)

        if not result:
            return jsonify({
                'tickers': [
                    {'symbol': 'BTC', 'price': 0, 'change24h': 0, 'volume': '--'},
                    {'symbol': 'ETH', 'price': 0, 'change24h': 0, 'volume': '--'},
                    {'symbol': 'SOL', 'price': 0, 'change24h': 0, 'volume': '--'},
                ],
                'error': error or '无法获取币安行情数据',
            })

        payload = {'tickers': result}
        if error:
            payload['error'] = error
        return jsonify(payload)
    except Exception as e:
        return jsonify({'tickers': [], 'error': str(e)})


def _get_requests_proxies_from_config():
    """
    Return requests proxies dict based on socks5_proxy in configs (if present).

    Note: requests only supports socks5 if PySocks is installed; otherwise it will error.
    """
    try:
        proxy = (
            parse_config(TRADER_CONFIG).get('socks5_proxy')
            or parse_config(SIGNAL_CONFIG).get('socks5_proxy')
        )
        proxy = str(proxy).strip() if proxy else ''
        if proxy:
            return {'http': proxy, 'https': proxy}
    except Exception:
        return None
    return None


def _proxy_binance_get(path: str, params: dict):
    """Fetch Binance public endpoint with fallback domains and optional proxy."""
    import requests

    proxies = _get_requests_proxies_from_config()
    endpoints = [
        'https://api.binance.com',
        'https://data-api.binance.vision',
    ]

    last_error = None
    for base in endpoints:
        url = f"{base}{path}"
        try:
            resp = requests.get(url, params=params, timeout=12, proxies=proxies)
            if resp.status_code == 451:
                last_error = (
                    f"Binance API blocked (HTTP 451). Please configure a SOCKS5 proxy in settings "
                    f"(socks5_proxy). Blocked URL: {url}"
                )
                continue
            return resp
        except requests.RequestException as exc:
            last_error = str(exc)

    raise RuntimeError(last_error or "Failed to fetch Binance public API")


@app.route('/api/binance/api/v3/ticker/24hr', methods=['GET'])
def proxy_binance_ticker_24hr():
    """Proxy Binance spot 24hr ticker (fixes CORS and regional blocks)."""
    symbol = (request.args.get('symbol') or '').strip().upper()
    if not symbol:
        return jsonify({'error': 'Missing symbol'}), 400

    try:
        resp = _proxy_binance_get('/api/v3/ticker/24hr', params={'symbol': symbol})
        content_type = resp.headers.get('content-type', 'application/json')
        return Response(resp.content, status=resp.status_code, content_type=content_type)
    except Exception as e:
        return jsonify({'error': str(e)}), 502


@app.route('/api/binance/api/v3/klines', methods=['GET'])
def proxy_binance_klines():
    """Proxy Binance spot klines (fixes CORS and regional blocks)."""
    symbol = (request.args.get('symbol') or '').strip().upper()
    if not symbol:
        return jsonify({'error': 'Missing symbol'}), 400

    interval = (request.args.get('interval') or '1h').strip() or '1h'
    limit = request.args.get('limit', type=int) or 24
    limit = max(1, min(limit, 1000))

    try:
        resp = _proxy_binance_get(
            '/api/v3/klines',
            params={'symbol': symbol, 'interval': interval, 'limit': limit},
        )
        content_type = resp.headers.get('content-type', 'application/json')
        return Response(resp.content, status=resp.status_code, content_type=content_type)
    except Exception as e:
        return jsonify({'error': str(e)}), 502

@app.route('/api/stats', methods=['GET'])
def get_stats():
    """获取交易统计"""
    config = parse_config(TRADER_CONFIG)
    is_testnet = config.get('use_testnet', True)
    
    # 测试网模式下返回模拟数据
    if is_testnet:
        return jsonify({
            'total_pnl': 0,
            'win_rate': 0,
            'total_trades': 0,
            'available': True,
            'testnet': True,
            'message': '测试网模式 - 无真实交易数据'
        })
    
    client = get_binance_client()
    if not client:
        return jsonify({
            'total_pnl': 0,
            'win_rate': 0,
            'total_trades': 0,
            'available': False,
            'error': '请先配置币安 API'
        })
    
    try:
        account = client.futures_account()
        total_unrealized_pnl = float(account.get('totalUnrealizedProfit', 0))
        
        trades = client.futures_account_trades(limit=500)
        total_trades = len(trades)
        winning_trades = sum(1 for t in trades if float(t.get('realizedPnl', 0)) > 0)
        total_pnl = total_unrealized_pnl + sum(float(t.get('realizedPnl', 0)) for t in trades)
        
        win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
        
        return jsonify({
            'total_pnl': round(total_pnl, 2),
            'win_rate': round(win_rate, 1),
            'total_trades': total_trades,
            'available': True
        })
    except Exception as e:
        return jsonify({
            'total_pnl': 0,
            'win_rate': 0,
            'total_trades': 0,
            'available': False,
            'error': str(e)
        })

@app.route('/api/signals', methods=['GET'])
def get_signals():
    """获取交易信号列表（Type 110 Alpha, Type 113 FOMO）"""
    if not get_database:
        return jsonify({'signals': [], 'error': 'Database not available'})
    
    try:
        db = get_database()
        limit = request.args.get('limit', 5, type=int)
        # 获取更多消息然后过滤
        messages = db.get_recent_messages(limit * 3)
        
        signals = []
        type_map = {110: 'ALPHA', 113: 'FOMO'}
        for msg in messages:
            msg_type = msg[1]
            if msg_type in [110, 113]:  # 只返回交易信号
                signals.append({
                    'id': msg[0],
                    'type': type_map.get(msg_type, 'SIGNAL'),
                    'symbol': msg[2] or 'UNKNOWN',
                    'title': msg[3],
                    'timestamp': msg[5] or msg[4],
                })
                if len(signals) >= limit:
                    break
        
        return jsonify({'signals': signals})
    except Exception as e:
        return jsonify({'signals': [], 'error': str(e)})

@app.route('/api/alerts', methods=['GET'])
def get_alerts():
    """获取风险警报列表（Type 112 FOMO加剧）"""
    if not get_database:
        return jsonify({'alerts': [], 'error': 'Database not available'})
    
    try:
        db = get_database()
        limit = request.args.get('limit', 5, type=int)
        # 获取更多消息然后过滤
        messages = db.get_recent_messages(limit * 5)
        
        alerts = []
        for msg in messages:
            msg_type = msg[1]
            if msg_type == 112:  # 只返回风险信号
                alerts.append({
                    'id': msg[0],
                    'type': 'RISK',
                    'symbol': msg[2] or 'UNKNOWN',
                    'title': msg[3],
                    'timestamp': msg[5] or msg[4],
                })
                if len(alerts) >= limit:
                    break
        
        return jsonify({'alerts': alerts})
    except Exception as e:
        return jsonify({'alerts': [], 'error': str(e)})


@app.route('/api/db/status', methods=['GET'])
def get_db_status():
    """获取信号数据库状态（用于排查信号/面板数据是否同步）。"""
    if not get_database:
        return jsonify({'available': False, 'error': 'Database not available'}), 500

    try:
        db = get_database()
        db_path = getattr(db, 'db_path', None)
        stats = {}
        if hasattr(db, 'get_statistics'):
            stats = db.get_statistics()
        return jsonify({
            'available': True,
            'db_path': db_path,
            'stats': stats,
        })
    except Exception as e:
        return jsonify({'available': False, 'error': str(e)}), 500

@app.route('/<path:path>')
def static_files(path):
    return send_from_directory(app.static_folder, path)


# ============================================================================
# WebSocket Events for Real-time Updates
# Requirements: 4.2 - Frontend updates within 2 seconds
# ============================================================================

@socketio.on('connect')
def handle_connect():
    """Handle client connection."""
    print(f"Client connected: {request.sid}")
    emit('connected', {'status': 'connected', 'sid': request.sid})


@socketio.on('disconnect')
def handle_disconnect():
    """Handle client disconnection."""
    print(f"Client disconnected: {request.sid}")


@socketio.on('subscribe')
def handle_subscribe(data):
    """
    Subscribe to specific update channels.
    
    Channels:
    - 'ai_analysis': AI analysis updates
    - 'decisions': Trading decision updates
    - 'learning': Learning status updates
    - 'trades': Trade execution updates
    """
    channels = data.get('channels', [])
    for channel in channels:
        socketio.server.enter_room(request.sid, channel)
    emit('subscribed', {'channels': channels})


@socketio.on('unsubscribe')
def handle_unsubscribe(data):
    """Unsubscribe from channels."""
    channels = data.get('channels', [])
    for channel in channels:
        socketio.server.leave_room(request.sid, channel)
    emit('unsubscribed', {'channels': channels})


def broadcast_ai_analysis(symbol: str, analysis: dict):
    """
    Broadcast AI analysis update to subscribed clients.
    
    Requirements: 4.2 - Update within 2 seconds
    """
    socketio.emit('ai_analysis_update', {
        'symbol': symbol,
        'analysis': analysis
    }, room='ai_analysis')


def broadcast_decision(decision: dict):
    """
    Broadcast new trading decision to subscribed clients.
    
    Requirements: 4.2 - Update within 2 seconds
    """
    socketio.emit('decision_update', {
        'decision': decision
    }, room='decisions')


def broadcast_learning_update(status: dict):
    """
    Broadcast learning status update to subscribed clients.
    
    Requirements: 11.4 - Notify user of model updates
    """
    socketio.emit('learning_update', {
        'status': status
    }, room='learning')


def broadcast_trade_update(trade: dict):
    """
    Broadcast trade execution update to subscribed clients.
    """
    socketio.emit('trade_update', {
        'trade': trade
    }, room='trades')


# Export broadcast functions for use by AI trading engine
__all__ = [
    'socketio',
    'broadcast_ai_analysis',
    'broadcast_decision',
    'broadcast_learning_update',
    'broadcast_trade_update'
]


@app.route('/api/ai/status', methods=['GET'])
def get_ai_status():
    """Check if AI trading module is available."""
    return jsonify({
        'available': AI_TRADING_AVAILABLE,
        'websocket_enabled': True
    })


# ============================================================================
# Performance API Endpoints
# Requirements: 6.1, 6.2
# ============================================================================

@app.route('/api/performance/chart', methods=['GET'])
def get_performance_chart():
    """
    Get time series data for performance chart.
    
    Query Parameters:
        range: Time range ('24h', '7d', '30d', 'all')
        trader_id: Optional trader ID filter
        
    Returns:
        JSON with time series data points
        
    Requirements: 6.1
    """
    if not PERFORMANCE_DB_AVAILABLE:
        return jsonify({'error': True, 'message': 'Performance module not available', 'code': 'MODULE_UNAVAILABLE'}), 500
    
    time_range = request.args.get('range', '7d')
    trader_id = request.args.get('trader_id')
    
    try:
        db = get_performance_db()
        
        # Get time range bounds
        start_time, end_time = MetricsCalculator.get_time_range_bounds(time_range)
        
        # Get trades within range
        if trader_id:
            trades = db.get_trades_by_range(start_time, end_time, trader_id)
        else:
            trades = db.get_trades_by_range(start_time, end_time)
        
        # Calculate cumulative PnL
        cumulative_data = MetricsCalculator.calculate_cumulative_pnl(
            trades, 
            trader_id or 'all'
        )
        
        return jsonify({
            'data': [point.to_dict() for point in cumulative_data],
            'range': time_range
        })
    except Exception as e:
        return jsonify({'error': True, 'message': str(e), 'code': 'INTERNAL_ERROR'}), 500


@app.route('/api/performance/rankings', methods=['GET'])
def get_performance_rankings():
    """
    Get trader leaderboard sorted by total PnL.
    
    Returns:
        JSON with sorted list of traders and their metrics
        
    Requirements: 6.2
    """
    if not PERFORMANCE_DB_AVAILABLE:
        return jsonify({'error': True, 'message': 'Performance module not available', 'code': 'MODULE_UNAVAILABLE'}), 500
    
    try:
        db = get_performance_db()
        
        # Get all traders with trades
        trader_ids = db.get_trader_ids_with_trades()
        
        rankings = []
        for tid in trader_ids:
            trades = db.get_trades(trader_id=tid)
            summary = MetricsCalculator.calculate_summary(trades)
            
            # Get trader name
            trader = db.get_trader(tid)
            name = trader.name if trader else tid
            
            rankings.append(TraderRanking(
                trader_id=tid,
                name=name,
                total_pnl=summary.total_pnl,
                win_rate=summary.win_rate,
                total_trades=summary.total_trades,
                avg_trade_size=summary.avg_trade_size
            ))
        
        # Sort by total PnL descending
        sorted_rankings = sort_rankings_by_pnl(rankings)
        
        return jsonify({
            'rankings': [r.to_dict() for r in sorted_rankings]
        })
    except Exception as e:
        return jsonify({'error': True, 'message': str(e), 'code': 'INTERNAL_ERROR'}), 500


@app.route('/api/performance/summary', methods=['GET'])
def get_performance_summary():
    """
    Get aggregated performance metrics.
    
    Query Parameters:
        trader_id: Optional trader ID filter
        
    Returns:
        JSON with summary metrics
        
    Requirements: 6.1
    """
    if not PERFORMANCE_DB_AVAILABLE:
        return jsonify({'error': True, 'message': 'Performance module not available', 'code': 'MODULE_UNAVAILABLE'}), 500
    
    trader_id = request.args.get('trader_id')
    
    try:
        db = get_performance_db()
        
        # Get trades
        if trader_id:
            trades = db.get_trades(trader_id=trader_id)
        else:
            trades = db.get_trades()
        
        # Calculate summary
        summary = MetricsCalculator.calculate_summary(trades)
        
        return jsonify(summary.to_dict())
    except Exception as e:
        return jsonify({'error': True, 'message': str(e), 'code': 'INTERNAL_ERROR'}), 500


@app.route('/api/performance/status', methods=['GET'])
def get_performance_status():
    """Check if performance module is available."""
    return jsonify({
        'available': PERFORMANCE_DB_AVAILABLE
    })


# ==================== Keepalive Configuration API ====================

def _validate_keepalive_config(data: dict) -> tuple[bool, list[str]]:
    """Validate keepalive configuration data.
    
    Returns:
        Tuple of (is_valid, error_messages)
    """
    errors = []
    
    # Validate global config
    global_cfg = data.get('global', {})
    check_interval = global_cfg.get('check_interval', KEEPALIVE_DEFAULT_CHECK_INTERVAL)
    if not isinstance(check_interval, (int, float)):
        errors.append("global.check_interval must be a number")
    elif check_interval < KEEPALIVE_MIN_CHECK_INTERVAL or check_interval > KEEPALIVE_MAX_CHECK_INTERVAL:
        errors.append(f"global.check_interval must be between {KEEPALIVE_MIN_CHECK_INTERVAL} and {KEEPALIVE_MAX_CHECK_INTERVAL}")
    
    # Validate telegram config
    telegram_cfg = data.get('telegram', {})
    if telegram_cfg.get('enabled'):
        if not telegram_cfg.get('bot_token', '').strip():
            errors.append("telegram.bot_token is required when telegram is enabled")
        if not telegram_cfg.get('chat_id', '').strip():
            errors.append("telegram.chat_id is required when telegram is enabled")
    
    # Validate services
    services = data.get('services', [])
    if not isinstance(services, list):
        errors.append("services must be an array")
    else:
        for i, svc in enumerate(services):
            if not isinstance(svc, dict):
                errors.append(f"services[{i}] must be an object")
                continue
            if not svc.get('name', '').strip():
                errors.append(f"services[{i}].name is required")
            if not svc.get('display_name', '').strip():
                errors.append(f"services[{i}].display_name is required")
            
            svc_check_interval = svc.get('check_interval')
            if svc_check_interval is not None:
                if not isinstance(svc_check_interval, (int, float)):
                    errors.append(f"services[{i}].check_interval must be a number")
                elif svc_check_interval < KEEPALIVE_MIN_CHECK_INTERVAL or svc_check_interval > KEEPALIVE_MAX_CHECK_INTERVAL:
                    errors.append(f"services[{i}].check_interval must be between {KEEPALIVE_MIN_CHECK_INTERVAL} and {KEEPALIVE_MAX_CHECK_INTERVAL}")
    
    return len(errors) == 0, errors


def _clamp_check_interval(value) -> int:
    """Clamp check_interval to valid bounds."""
    if not isinstance(value, (int, float)):
        return KEEPALIVE_DEFAULT_CHECK_INTERVAL
    value = int(value)
    if value < KEEPALIVE_MIN_CHECK_INTERVAL:
        return KEEPALIVE_MIN_CHECK_INTERVAL
    if value > KEEPALIVE_MAX_CHECK_INTERVAL:
        return KEEPALIVE_MAX_CHECK_INTERVAL
    return value


@app.route('/api/keepalive/config', methods=['GET'])
def get_keepalive_config():
    """Get keepalive configuration."""
    try:
        config = _read_json_file(KEEPALIVE_CONFIG_FILE, default={
            'global': {
                'check_interval': KEEPALIVE_DEFAULT_CHECK_INTERVAL,
                'restart_cooldown': KEEPALIVE_DEFAULT_RESTART_COOLDOWN,
                'log_file': '/var/log/valuescan-keepalive.log'
            },
            'telegram': {
                'enabled': False,
                'bot_token': '',
                'chat_id': ''
            },
            'services': []
        })
        return jsonify({'success': True, 'config': config})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/my-traders', methods=['GET'])
def get_my_traders():
    """
    获取当前用户的所有交易者
    """
    try:
        # 从数据库获取所有交易者
        db_traders = performance_db.get_all_traders()
        traders = []
        for t in db_traders:
            traders.append({
                'trader_id': t.id,
                'trader_name': t.name,
                'ai_model': 'claude-3-opus',
                'exchange_id': 'binance',
                'is_running': True,
                'initial_balance': 10000.0,
                'strategy_id': 'balanced_day',
                'strategy_name': t.description or '平衡日内策略'
            })
        return jsonify(traders)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/account', methods=['GET'])
def get_account():
    """
    获取账户信息
    """
    try:
        trader_id = request.args.get('trader_id', '')

        # 从数据库获取该交易者的所有交易记录
        trades = performance_db.get_trades(trader_id=trader_id) if trader_id else []

        # 计算账户信息
        total_pnl = sum(t.realized_pnl for t in trades)
        initial_balance = 10000.0
        total_equity = initial_balance + total_pnl

        account = {
            'total_equity': total_equity,
            'available_balance': total_equity * 0.8,
            'total_pnl': total_pnl,
            'total_pnl_pct': (total_pnl / initial_balance * 100) if initial_balance > 0 else 0,
            'wallet_balance': initial_balance,
            'position_count': 0,
            'margin_used_pct': 20.0
        }
        return jsonify(account)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/positions', methods=['GET'])
def get_positions():
    """
    获取当前持仓
    """
    try:
        trader_id = request.args.get('trader_id', '')
        positions = []
        return jsonify(positions)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/decisions', methods=['GET'])
def get_decisions():
    """
    获取交易决策历史
    """
    try:
        trader_id = request.args.get('trader_id', '')

        # 从数据库获取交易记录
        trades = performance_db.get_trades(trader_id=trader_id) if trader_id else []

        # 转换为决策格式
        decisions = []
        for trade in trades:
            decisions.append({
                'id': trade.id,
                'trader_id': trade.trader_id,
                'timestamp': trade.timestamp,
                'action': 'OPEN' if trade.side == 'BUY' else 'CLOSE',
                'symbol': trade.symbol,
                'reason': f'{trade.side} {trade.quantity} @ ${trade.price}',
                'price': trade.price,
                'size': trade.quantity,
                'pnl': trade.realized_pnl,
                'pnl_pct': (trade.realized_pnl / (trade.price * trade.quantity) * 100) if (trade.price * trade.quantity) > 0 else 0
            })

        return jsonify(decisions)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/decisions/latest', methods=['GET'])
def get_latest_decisions():
    """
    Get latest trade decisions.
    """
    try:
        trader_id = request.args.get('trader_id', '')
        limit = request.args.get('limit', 5, type=int)
        if limit < 1:
            limit = 1
        if limit > 50:
            limit = 50

        total = performance_db.get_trade_count(trader_id=trader_id) if trader_id else performance_db.get_trade_count()
        offset = max(0, total - limit)
        trades = performance_db.get_trades(trader_id=trader_id, limit=limit, offset=offset) if trader_id else performance_db.get_trades(limit=limit, offset=offset)

        decisions = []
        for trade in trades:
            decisions.append({
                'id': trade.id,
                'trader_id': trade.trader_id,
                'timestamp': trade.timestamp,
                'action': 'OPEN' if trade.side == 'BUY' else 'CLOSE',
                'symbol': trade.symbol,
                'reason': f'{trade.side} {trade.quantity} @ ${trade.price}',
                'price': trade.price,
                'size': trade.quantity,
                'pnl': trade.realized_pnl,
                'pnl_pct': (trade.realized_pnl / (trade.price * trade.quantity) * 100) if (trade.price * trade.quantity) > 0 else 0
            })

        decisions.sort(key=lambda item: item.get('timestamp', 0), reverse=True)
        return jsonify(decisions)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/statistics', methods=['GET'])
def get_statistics():
    """
    获取性能统计
    """
    try:
        trader_id = request.args.get('trader_id', '')

        # 从数据库获取交易记录
        trades = performance_db.get_trades(trader_id=trader_id) if trader_id else []

        if not trades:
            return jsonify({
                'total_trades': 0,
                'winning_trades': 0,
                'losing_trades': 0,
                'win_rate': 0.0,
                'total_pnl': 0.0,
                'total_pnl_pct': 0.0,
                'avg_win': 0.0,
                'avg_loss': 0.0,
                'profit_factor': 0.0
            })

        # 计算统计数据
        winning_trades = [t for t in trades if t.realized_pnl > 0]
        losing_trades = [t for t in trades if t.realized_pnl < 0]

        total_pnl = sum(t.realized_pnl for t in trades)
        total_wins = sum(t.realized_pnl for t in winning_trades)
        total_losses = abs(sum(t.realized_pnl for t in losing_trades))

        stats = {
            'total_trades': len(trades),
            'winning_trades': len(winning_trades),
            'losing_trades': len(losing_trades),
            'win_rate': len(winning_trades) / len(trades) if trades else 0.0,
            'total_pnl': total_pnl,
            'total_pnl_pct': (total_pnl / 10000.0 * 100) if total_pnl else 0.0,
            'avg_win': total_wins / len(winning_trades) if winning_trades else 0.0,
            'avg_loss': total_losses / len(losing_trades) if losing_trades else 0.0,
            'profit_factor': total_wins / total_losses if total_losses > 0 else 0.0
        }
        return jsonify(stats)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== Clash Proxy API Routes ====================

@app.route('/api/clash/config', methods=['GET'])
def get_clash_config():
    """
    获取 Clash 配置
    """
    try:
        from api.clash_store import ClashStore
        store = ClashStore()
        config = store.get_config()
        return jsonify(config)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/config', methods=['POST'])
def save_clash_config():
    """
    保存 Clash 配置
    """
    try:
        from api.clash_store import ClashStore
        store = ClashStore()
        config = request.get_json()
        store.save_config(config)
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/nodes', methods=['GET'])
def get_clash_nodes():
    """
    获取代理节点列表
    """
    try:
        from api.clash_store import ClashStore
        store = ClashStore()
        nodes = store.get_nodes()
        return jsonify(nodes)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/nodes', methods=['POST'])
def save_clash_nodes():
    """
    保存代理节点列表
    """
    try:
        from api.clash_store import ClashStore
        store = ClashStore()
        nodes = request.get_json()
        store.save_nodes(nodes)
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/subscription/update', methods=['POST'])
def update_clash_subscription():
    """
    更新订阅并解析节点
    """
    try:
        import requests
        from api.clash_parser import parse_clash_subscription, parse_base64_subscription
        from api.clash_store import ClashStore

        data = request.get_json()
        url = data.get('url')
        sub_type = data.get('type', 'clash')

        # 配置代理
        proxies = {}
        http_proxy = os.getenv('HTTP_PROXY') or os.getenv('http_proxy')
        https_proxy = os.getenv('HTTPS_PROXY') or os.getenv('https_proxy')

        if http_proxy:
            proxies['http'] = http_proxy
        if https_proxy:
            proxies['https'] = https_proxy

        # 如果没有配置环境变量,尝试使用本地Clash代理
        if not proxies:
            proxies = {
                'http': 'http://127.0.0.1:7890',
                'https': 'http://127.0.0.1:7890'
            }

        # 获取订阅内容
        try:
            resp = requests.get(url, timeout=30, proxies=proxies)
            resp.raise_for_status()
        except Exception as proxy_error:
            # 如果代理失败,尝试直连
            print(f"代理请求失败,尝试直连: {proxy_error}")
            resp = requests.get(url, timeout=30)
            resp.raise_for_status()

        content = resp.text

        # 解析节点和策略组
        if sub_type == 'clash':
            nodes, groups, rules, proxy_providers, rule_providers = parse_clash_subscription(content)
        else:
            nodes = parse_base64_subscription(content)
            groups = []
            rules = None
            proxy_providers = None
            rule_providers = None

        store = ClashStore()
        store.save_nodes(nodes)
        config = store.get_config()
        if sub_type == 'clash':
            config['proxyGroups'] = groups
            if rules is not None:
                config['rules'] = rules
            if proxy_providers is not None:
                config['proxyProviders'] = proxy_providers
            if rule_providers is not None:
                config['ruleProviders'] = rule_providers
        store.save_config(config)

        apply_error = None
        try:
            from api.clash_exporter import generate_clash_yaml

            clash_config_path = os.getenv(
                "VALUESCAN_CLASH_CONFIG_PATH",
                "/root/.config/clash/config.yaml",
            )
            yaml_content = generate_clash_yaml(config, nodes)
            Path(clash_config_path).parent.mkdir(parents=True, exist_ok=True)
            Path(clash_config_path).write_text(yaml_content, encoding="utf-8")

            clash_api = os.getenv("VALUESCAN_CLASH_API_URL", "http://127.0.0.1:9090")
            try:
                resp = requests.put(
                    f"{clash_api.rstrip('/')}/configs",
                    json={"path": clash_config_path},
                    timeout=10,
                )
                if resp.status_code >= 400:
                    apply_error = f"Clash reload failed: {resp.status_code}"
            except Exception as e:
                apply_error = f"Clash reload failed: {e}"
        except Exception as e:
            apply_error = f"Clash config apply failed: {e}"

        try:
            iptables_script = os.getenv(
                "VALUESCAN_CLASH_IPTABLES_SCRIPT", "/usr/local/bin/clash-iptables.py"
            )
            if os.path.exists(iptables_script):
                import subprocess

                subprocess.run([iptables_script], check=False, timeout=20)
        except Exception:
            pass

        return jsonify({
            'nodes': nodes,
            'groups': groups,
            'rules': rules or [],
            'count': len(nodes),
            'applied': apply_error is None,
            'applyError': apply_error,
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/test-node', methods=['POST'])
def test_clash_node():
    """
    测试单个节点延迟
    """
    try:
        import requests
        import time

        data = request.get_json()
        node_id = data.get('nodeId')

        if not node_id:
            return jsonify({'error': '缺少节点ID'}), 400

        # 模拟测速 - 实际应该通过Clash API测试
        # 这里返回模拟数据
        start_time = time.time()

        # TODO: 实际应该调用Clash API进行测速
        # 目前返回随机延迟
        import random
        delay = random.randint(50, 300)

        result = {
            'nodeId': node_id,
            'delay': delay,
            'success': True,
            'timestamp': int(time.time() * 1000)
        }

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'nodeId': data.get('nodeId', ''),
            'delay': -1,
            'success': False,
            'error': str(e),
            'timestamp': int(time.time() * 1000)
        }), 500


@app.route('/api/clash/stats', methods=['GET'])
def get_clash_stats():
    """
    ?? Clash ????
    """
    try:
        import requests

        controller = os.getenv('VALUESCAN_CLASH_API_URL') or os.getenv(
            'VALUESCAN_CLASH_EXTERNAL_CONTROLLER', '127.0.0.1:9090'
        )
        if controller.startswith('http://') or controller.startswith('https://'):
            base_url = controller
        else:
            base_url = f"http://{controller}"

        secret = (os.getenv('VALUESCAN_CLASH_SECRET') or '').strip()
        headers = {}
        if secret:
            headers['Authorization'] = f"Bearer {secret}"

        session = requests.Session()
        session.trust_env = False

        traffic = {}
        connections_payload = {}
        try:
            traffic_resp = session.get(f"{base_url}/traffic", headers=headers, timeout=2)
            if traffic_resp.ok:
                traffic = traffic_resp.json()
        except Exception:
            traffic = {}

        try:
            connections_resp = session.get(f"{base_url}/connections", headers=headers, timeout=2)
            if connections_resp.ok:
                connections_payload = connections_resp.json()
        except Exception:
            connections_payload = {}

        connections_list = connections_payload.get('connections') or []
        stats = {
            'uploadTotal': connections_payload.get('uploadTotal', 0),
            'downloadTotal': connections_payload.get('downloadTotal', 0),
            'connections': len(connections_list),
            'uploadSpeed': traffic.get('up', 0),
            'downloadSpeed': traffic.get('down', 0)
        }
        return jsonify(stats)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


        store = ClashStore()
        config = store.get_config()
        controller = config.get('externalController', '127.0.0.1:9090')
        if controller.startswith('http://') or controller.startswith('https://'):
            base_url = controller
        else:
            base_url = f"http://{controller}"

        secret = (config.get('secret') or '').strip()
        headers = {}
        if secret:
            headers['Authorization'] = f"Bearer {secret}"

        session = requests.Session()
        session.trust_env = False

        traffic = {}
        connections_payload = {}
        try:
            traffic_resp = session.get(f"{base_url}/traffic", headers=headers, timeout=2)
            if traffic_resp.ok:
                traffic = traffic_resp.json()
        except Exception:
            traffic = {}

        try:
            connections_resp = session.get(f"{base_url}/connections", headers=headers, timeout=2)
            if connections_resp.ok:
                connections_payload = connections_resp.json()
        except Exception:
            connections_payload = {}

        connections_list = connections_payload.get('connections') or []
        stats = {
            'uploadTotal': connections_payload.get('uploadTotal', 0),
            'downloadTotal': connections_payload.get('downloadTotal', 0),
            'connections': len(connections_list),
            'uploadSpeed': traffic.get('up', 0),
            'downloadSpeed': traffic.get('down', 0)
        }
        return jsonify(stats)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


        store = ClashStore()
        config = store.get_config()
        controller = config.get('externalController', '127.0.0.1:9090')
        if controller.startswith('http://') or controller.startswith('https://'):
            base_url = controller
        else:
            base_url = f"http://{controller}"

        secret = (config.get('secret') or '').strip()
        headers = {}
        if secret:
            headers['Authorization'] = f"Bearer {secret}"

        traffic = {}
        connections_payload = {}
        try:
            traffic_resp = requests.get(f"{base_url}/traffic", headers=headers, timeout=5)
            if traffic_resp.ok:
                traffic = traffic_resp.json()
        except Exception:
            traffic = {}

        try:
            connections_resp = requests.get(f"{base_url}/connections", headers=headers, timeout=5)
            if connections_resp.ok:
                connections_payload = connections_resp.json()
        except Exception:
            connections_payload = {}

        connections_list = connections_payload.get('connections') or []
        stats = {
            'uploadTotal': connections_payload.get('uploadTotal', 0),
            'downloadTotal': connections_payload.get('downloadTotal', 0),
            'connections': len(connections_list),
            'uploadSpeed': traffic.get('up', 0),
            'downloadSpeed': traffic.get('down', 0)
        }
        return jsonify(stats)
    except Exception as e:
        return jsonify({'error': str(e)}), 500



@app.route('/api/clash/groups', methods=['GET'])
def get_clash_proxy_groups():
    """
    获取策略组列表
    """
    try:
        from api.clash_store import ClashStore
        store = ClashStore()
        groups = store.get_proxy_groups()
        return jsonify(groups)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/groups', methods=['POST'])
def save_clash_proxy_groups():
    """
    保存策略组列表
    """
    try:
        from api.clash_store import ClashStore
        data = request.get_json()
        groups = data.get('groups', [])

        store = ClashStore()
        store.save_proxy_groups(groups)

        return jsonify({'message': 'Proxy groups saved successfully', 'count': len(groups)})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/groups/generate', methods=['POST'])
def generate_clash_proxy_groups():
    """
    根据节点自动生成策略组
    """
    try:
        from api.clash_store import ClashStore
        from api.clash_exporter import generate_proxy_groups_from_nodes

        store = ClashStore()
        nodes = store.get_nodes()
        groups = generate_proxy_groups_from_nodes(nodes)

        return jsonify({'groups': groups, 'count': len(groups)})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/export', methods=['GET'])
def export_clash_config():
    """
    导出 Clash YAML 配置
    """
    try:
        from api.clash_store import ClashStore
        from api.clash_exporter import generate_clash_yaml

        store = ClashStore()
        config = store.get_config()
        nodes = store.get_nodes()

        yaml_content = generate_clash_yaml(config, nodes)

        response = make_response(yaml_content)
        response.headers['Content-Type'] = 'text/yaml'
        response.headers['Content-Disposition'] = 'attachment; filename=clash-config.yaml'
        return response
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/service/status', methods=['GET'])
def get_clash_service_status():
    """
    获取 Clash 服务状态
    """
    try:
        import socket

        # 检查 9090 端口是否可访问
        def check_port(host, port):
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(1)
                result = sock.connect_ex((host, port))
                sock.close()
                return result == 0
            except Exception:
                return False

        is_running = check_port('127.0.0.1', 9090)

        return jsonify({
            'running': is_running,
            'port': 9090,
            'api_url': 'http://127.0.0.1:9090'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clash/service/start', methods=['POST'])
def start_clash_service():
    """
    启动 Clash 服务
    """
    try:
        import platform

        # 检查是否已经在运行
        status_response = get_clash_service_status()
        status_data = status_response.get_json()

        if status_data.get('running'):
            return jsonify({'error': 'Clash 服务已经在运行'}), 400

        is_windows = platform.system() == 'Windows'

        if is_windows:
            return jsonify({
                'error': 'Windows 系统请手动启动 Clash 服务',
                'hint': '请运行 Clash/Mihomo 并确保 external-controller 配置为 127.0.0.1:9090'
            }), 400
        else:
            # Linux: 尝试启动 clash 或 mihomo 服务
            for service_name in ['clash', 'mihomo', 'clash-meta']:
                try:
                    result = subprocess.run(
                        ['systemctl', 'start', service_name],
                        capture_output=True,
                        text=True,
                        timeout=10
                    )
                    if result.returncode == 0:
                        return jsonify({
                            'message': f'Clash 服务启动成功 ({service_name})',
                            'service': service_name
                        })
                except Exception:
                    continue

            return jsonify({
                'error': '未找到 Clash 服务，请手动启动',
                'hint': '请确保已安装 clash/mihomo 并配置为系统服务'
            }), 500
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ============================================================================
# 服务管理 API
# ============================================================================

@app.route('/api/services/status', methods=['GET'])
def get_services_status():
    """
    获取所有服务状态 (支持 Windows 和 Linux)
    """
    try:
        import platform
        import psutil

        services = {
            'valuescan-monitor': 'polling_monitor.py',
            'valuescan-trader': 'futures_main.py',
            'valuescan-api': 'api/server.py',
        }

        status_map = {}

        # 检测操作系统
        is_windows = platform.system() == 'Windows'

        for service_name, process_name in services.items():
            is_running = False

            if is_windows:
                # Windows: 检查进程列表
                for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                    try:
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any(process_name in cmd for cmd in cmdline):
                            is_running = True
                            break
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
            else:
                # Linux: 使用 systemctl
                try:
                    result = subprocess.run(
                        ['systemctl', 'is-active', service_name],
                        capture_output=True,
                        text=True,
                        timeout=5
                    )
                    is_running = result.stdout.strip() == 'active'
                except Exception:
                    # 如果 systemctl 失败,回退到进程检查
                    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                        try:
                            cmdline = proc.info.get('cmdline', [])
                            if cmdline and any(process_name in cmd for cmd in cmdline):
                                is_running = True
                                break
                        except (psutil.NoSuchProcess, psutil.AccessDenied):
                            continue

            status_map[service_name] = 'running' if is_running else 'stopped'

        return jsonify(status_map)
    except Exception as e:
        print(f"Error getting service status: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/services/start', methods=['POST'])
def start_service():
    """
    启动服务 (支持 Windows 和 Linux, 防止重复启动)
    """
    try:
        import platform
        import psutil

        data = request.get_json()
        service = data.get('service')

        if not service:
            return jsonify({'error': '缺少服务名称'}), 400

        # 服务到进程的映射
        service_process_map = {
            'valuescan-monitor': 'polling_monitor.py',
            'valuescan-trader': 'futures_main.py',
            'valuescan-api': 'api/server.py',
        }

        process_name = service_process_map.get(service)
        if not process_name:
            return jsonify({'error': f'未知服务: {service}'}), 400

        # 检查服务是否已经在运行
        is_running = False
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                cmdline = proc.info.get('cmdline', [])
                if cmdline and any(process_name in cmd for cmd in cmdline):
                    is_running = True
                    break
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue

        if is_running:
            return jsonify({'error': f'服务 {service} 已经在运行中'}), 400

        # 启动服务
        is_windows = platform.system() == 'Windows'

        if is_windows:
            # Windows: 使用 python 启动
            return jsonify({'error': 'Windows 系统请手动启动服务'}), 400
        else:
            # Linux: 使用 systemctl
            result = subprocess.run(
                ['systemctl', 'start', service],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                return jsonify({'message': f'服务 {service} 启动成功'})
            else:
                return jsonify({'error': result.stderr}), 500

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/services/stop', methods=['POST'])
def stop_service():
    """
    停止服务 (支持 Windows 和 Linux)
    """
    try:
        import platform
        import psutil
        import signal

        data = request.get_json()
        service = data.get('service')

        if not service:
            return jsonify({'error': '缺少服务名称'}), 400

        # 服务到进程的映射
        service_process_map = {
            'valuescan-monitor': 'polling_monitor.py',
            'valuescan-trader': 'futures_main.py',
            'valuescan-api': 'api/server.py',
        }

        process_name = service_process_map.get(service)
        if not process_name:
            return jsonify({'error': f'未知服务: {service}'}), 400

        is_windows = platform.system() == 'Windows'

        if is_windows:
            # Windows: 查找并终止进程
            killed = False
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline', [])
                    if cmdline and any(process_name in cmd for cmd in cmdline):
                        proc.terminate()
                        killed = True
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            if killed:
                return jsonify({'message': f'服务 {service} 停止成功'})
            else:
                return jsonify({'error': f'服务 {service} 未运行'}), 400
        else:
            # Linux: 使用 systemctl
            result = subprocess.run(
                ['systemctl', 'stop', service],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                return jsonify({'message': f'服务 {service} 停止成功'})
            else:
                return jsonify({'error': result.stderr}), 500

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/services/restart', methods=['POST'])
def restart_service():
    """
    重启服务 (支持 Windows 和 Linux)
    """
    try:
        import platform

        data = request.get_json()
        service = data.get('service')

        if not service:
            return jsonify({'error': '缺少服务名称'}), 400

        is_windows = platform.system() == 'Windows'

        if is_windows:
            # Windows: 先停止再启动
            stop_result = stop_service()
            if stop_result[1] != 200:
                return stop_result

            import time
            time.sleep(2)  # 等待进程完全停止

            return jsonify({'error': 'Windows 系统请手动重启服务'}), 400
        else:
            # Linux: 使用 systemctl
            result = subprocess.run(
                ['systemctl', 'restart', service],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                return jsonify({'message': f'服务 {service} 重启成功'})
            else:
                return jsonify({'error': result.stderr}), 500

    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # Use socketio.run instead of app.run for WebSocket support
    port = int(os.environ.get("PORT", "5000"))
    debug = os.environ.get("VALUESCAN_DEBUG", "").lower() in ("1", "true", "yes", "on")
    socketio.run(
        app,
        host='0.0.0.0',
        port=port,
        debug=debug,
        allow_unsafe_werkzeug=True,
    )
